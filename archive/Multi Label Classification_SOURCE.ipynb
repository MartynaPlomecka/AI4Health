{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "      <th>2646</th>\n",
       "      <th>2647</th>\n",
       "      <th>2648</th>\n",
       "      <th>2649</th>\n",
       "      <th>2650</th>\n",
       "      <th>2651</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.497571e-01</td>\n",
       "      <td>4.585819e-01</td>\n",
       "      <td>2.938905e-01</td>\n",
       "      <td>3.770603e-01</td>\n",
       "      <td>0.327764</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.462017</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.642190</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337358</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.364673</td>\n",
       "      <td>0.405482</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.428504</td>\n",
       "      <td>0.250803</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.464767e-01</td>\n",
       "      <td>9.048637e-01</td>\n",
       "      <td>5.054438e-01</td>\n",
       "      <td>7.021925e-01</td>\n",
       "      <td>0.498947</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.321952</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.478879</td>\n",
       "      <td>0.304577</td>\n",
       "      <td>0.360859</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.204578e-01</td>\n",
       "      <td>3.562272e-01</td>\n",
       "      <td>3.895027e-01</td>\n",
       "      <td>4.181956e-01</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446757</td>\n",
       "      <td>0.528172</td>\n",
       "      <td>0.409405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404292</td>\n",
       "      <td>0.339923</td>\n",
       "      <td>0.505282</td>\n",
       "      <td>0.340129</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.341549</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.346560e-02</td>\n",
       "      <td>1.204557e-01</td>\n",
       "      <td>1.650503e-01</td>\n",
       "      <td>7.631559e-01</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>0.399243</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.111156</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.758219e-01</td>\n",
       "      <td>2.255777e-01</td>\n",
       "      <td>4.828928e-01</td>\n",
       "      <td>4.704279e-01</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.284202</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164094</td>\n",
       "      <td>0.161737</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>3.394601e-01</td>\n",
       "      <td>4.781692e-01</td>\n",
       "      <td>5.423877e-01</td>\n",
       "      <td>4.137127e-01</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.538537</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268739</td>\n",
       "      <td>0.328251</td>\n",
       "      <td>0.327389</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.367808</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>NDARZN148PMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1.072605e-01</td>\n",
       "      <td>2.045245e-01</td>\n",
       "      <td>2.610531e-01</td>\n",
       "      <td>3.236518e-01</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.432447</td>\n",
       "      <td>0.412152</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451919</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.125819</td>\n",
       "      <td>0.083812</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.378008</td>\n",
       "      <td>0.264043</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2.801818e-01</td>\n",
       "      <td>3.838379e-01</td>\n",
       "      <td>3.575040e-01</td>\n",
       "      <td>3.295642e-01</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.263007</td>\n",
       "      <td>0.204378</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>0.319891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>0.543971</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>0.544979</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>0.589517</td>\n",
       "      <td>0.634712</td>\n",
       "      <td>0.549726</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>3.260273e-15</td>\n",
       "      <td>3.373362e-14</td>\n",
       "      <td>2.304057e-13</td>\n",
       "      <td>1.498324e-12</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.142998</td>\n",
       "      <td>0.689837</td>\n",
       "      <td>0.800874</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.132429</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>3.945258e-01</td>\n",
       "      <td>4.017071e-01</td>\n",
       "      <td>2.867999e-01</td>\n",
       "      <td>3.721533e-01</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299387</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.404021</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.437301</td>\n",
       "      <td>0.412550</td>\n",
       "      <td>0.745395</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows Ã— 2653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3         4  \\\n",
       "0     3.497571e-01  4.585819e-01  2.938905e-01  3.770603e-01  0.327764   \n",
       "1     7.464767e-01  9.048637e-01  5.054438e-01  7.021925e-01  0.498947   \n",
       "2     2.204578e-01  3.562272e-01  3.895027e-01  4.181956e-01  0.495129   \n",
       "3     6.346560e-02  1.204557e-01  1.650503e-01  7.631559e-01  0.523793   \n",
       "4     2.758219e-01  2.255777e-01  4.828928e-01  4.704279e-01  0.330692   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "2036  3.394601e-01  4.781692e-01  5.423877e-01  4.137127e-01  0.379793   \n",
       "2037  1.072605e-01  2.045245e-01  2.610531e-01  3.236518e-01  0.437417   \n",
       "2038  2.801818e-01  3.838379e-01  3.575040e-01  3.295642e-01  0.339077   \n",
       "2039  3.260273e-15  3.373362e-14  2.304057e-13  1.498324e-12  0.000009   \n",
       "2040  3.945258e-01  4.017071e-01  2.867999e-01  3.721533e-01  0.583645   \n",
       "\n",
       "             5         6         7         8         9  ...      2643  \\\n",
       "0     0.552059  0.462017  0.695207  0.642190  0.584085  ...  0.337358   \n",
       "1     0.342338  0.283478  0.221679  0.178758  0.178338  ...  0.430404   \n",
       "2     0.436858  0.392300  0.446757  0.528172  0.409405  ...  0.404292   \n",
       "3     0.399243  0.267432  0.301397  0.283535  0.363612  ...  0.108138   \n",
       "4     0.310594  0.284202  0.298111  0.245370  0.250187  ...  0.164094   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2036  0.413474  0.538537  0.457002  0.286496  0.222562  ...  0.268739   \n",
       "2037  0.432447  0.412152  0.445771  0.374603  0.386189  ...  0.451919   \n",
       "2038  0.263007  0.204378  0.308062  0.413562  0.319891  ...  0.386920   \n",
       "2039  0.142998  0.689837  0.800874  0.499946  0.248208  ...  0.213887   \n",
       "2040  0.497248  0.302516  0.193872  0.343920  0.500556  ...  0.299387   \n",
       "\n",
       "          2644      2645      2646      2647      2648      2649      2650  \\\n",
       "0     0.439658  0.437051  0.364673  0.405482  0.326733  0.428504  0.250803   \n",
       "1     0.296341  0.321952  0.131375  0.579138  0.478879  0.304577  0.360859   \n",
       "2     0.339923  0.505282  0.340129  0.203517  0.174711  0.341549  0.693619   \n",
       "3     0.049740  0.033945  0.304668  0.111156  0.008791  0.005297  0.266759   \n",
       "4     0.161737  0.123381  0.079693  0.069366  0.043857  0.029212  0.021894   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2036  0.328251  0.327389  0.292491  0.367808  0.346005  0.348895  0.399141   \n",
       "2037  0.240030  0.125819  0.083812  0.289439  0.378008  0.264043  0.502426   \n",
       "2038  0.543971  0.590438  0.544979  0.679570  0.616411  0.589517  0.634712   \n",
       "2039  0.230102  0.189709  0.132429  0.124579  0.085125  0.061278  0.049636   \n",
       "2040  0.416947  0.446031  0.404021  0.493188  0.437301  0.412550  0.745395   \n",
       "\n",
       "          2651           IDs  \n",
       "0     0.179322  NDARAA075AMK  \n",
       "1     0.448476  NDARAA112DMH  \n",
       "2     0.545169  NDARAA117NEJ  \n",
       "3     0.339304  NDARAA947ZG5  \n",
       "4     0.013197  NDARAA948VFH  \n",
       "...        ...           ...  \n",
       "2036  0.367943  NDARZN148PMN  \n",
       "2037  0.008403  NDARZN277NR6  \n",
       "2038  0.549726  NDARZN578YDP  \n",
       "2039  0.032335  NDARZN610GTY  \n",
       "2040  0.373653  NDARZN677EYE  \n",
       "\n",
       "[2041 rows x 2653 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mat73.loadmat(DATA_DIR+'x_source.mat')  \n",
    "df2 = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df2 = np.array(df2).reshape(data['x'].shape) \n",
    "df2_sparsed = np.concatenate([np.expand_dims(df2[:,:,i:i+10].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-10, 10)], axis = 2)\n",
    "df2 = pd.DataFrame(df2_sparsed.reshape((df2_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df2)\n",
    "df2 = norm.transform(df2)\n",
    "df2 = pd.DataFrame(df2.reshape((df2.shape[0], -1)))\n",
    "\n",
    "df2['IDs'] = foof['IDs']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2939, 177)\n",
      "Removing 137 patients as their evaluations was incomplete.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders',  'No Diagnosis Given', 'Other Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# removing patients with incomplete eval\n",
    "initial_size = beh.shape[0]\n",
    "beh = beh[beh.DX_01 != 'No Diagnosis Given: Incomplete Eval']\n",
    "beh = beh.reset_index(drop=True)\n",
    "new_size = beh.shape[0]\n",
    "\n",
    "print('After:'+str(beh.shape))\n",
    "print('Removing', initial_size - new_size,\n",
    "      'patients as their evaluations was incomplete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6,\n",
       " 'No Diagnosis Given': 7,\n",
       " 'Other Disorders': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        else:\n",
    "            if diagnoses_to_ids['Other Disorders'] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids['Other Disorders'])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "        \n",
    "    order_of_disorders.append(disorders_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_disorders = []\n",
    "no_diagnosis_given = []\n",
    "for i in order_of_disorders:\n",
    "    if 7 in i:\n",
    "        no_diagnosis_given.append(1)\n",
    "        i.remove(7)\n",
    "    else:\n",
    "        no_diagnosis_given.append(0)\n",
    "    if 8 in i:\n",
    "        other_disorders.append(1)\n",
    "        i.remove(8)\n",
    "    else:\n",
    "        other_disorders.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_908822/226828375.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[\"Other Disorders\"] = other_disorders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "      <th>Other Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2934  NDARZZ007YMP                                         0   \n",
       "2935  NDARZZ740MLM                                         1   \n",
       "2936  NDARZZ810LVF                                         0   \n",
       "2937  NDARZZ830JM7                                         0   \n",
       "2938  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2934                  0                           0                         1   \n",
       "2935                  0                           0                         0   \n",
       "2936                  0                           0                         1   \n",
       "2937                  0                           0                         1   \n",
       "2938                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \\\n",
       "0              0                       0                     0   \n",
       "1              1                       0                     0   \n",
       "2              1                       0                     0   \n",
       "3              0                       1                     0   \n",
       "4              0                       0                     0   \n",
       "...          ...                     ...                   ...   \n",
       "2934           0                       0                     0   \n",
       "2935           0                       0                     0   \n",
       "2936           0                       1                     0   \n",
       "2937           0                       0                     0   \n",
       "2938           0                       0                     0   \n",
       "\n",
       "      Other Disorders  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "...               ...  \n",
       "2934                1  \n",
       "2935                0  \n",
       "2936                1  \n",
       "2937                1  \n",
       "2938                0  \n",
       "\n",
       "[2939 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "labels=behaviour_data[[\"IDs\"]+list(common_disorders)]\n",
    "labels[\"Other Disorders\"] = other_disorders\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2651</th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "      <th>Other Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.497571e-01</td>\n",
       "      <td>4.585819e-01</td>\n",
       "      <td>2.938905e-01</td>\n",
       "      <td>3.770603e-01</td>\n",
       "      <td>0.327764</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.462017</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.642190</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.464767e-01</td>\n",
       "      <td>9.048637e-01</td>\n",
       "      <td>5.054438e-01</td>\n",
       "      <td>7.021925e-01</td>\n",
       "      <td>0.498947</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.204578e-01</td>\n",
       "      <td>3.562272e-01</td>\n",
       "      <td>3.895027e-01</td>\n",
       "      <td>4.181956e-01</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446757</td>\n",
       "      <td>0.528172</td>\n",
       "      <td>0.409405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.346560e-02</td>\n",
       "      <td>1.204557e-01</td>\n",
       "      <td>1.650503e-01</td>\n",
       "      <td>7.631559e-01</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>0.399243</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.758219e-01</td>\n",
       "      <td>2.255777e-01</td>\n",
       "      <td>4.828928e-01</td>\n",
       "      <td>4.704279e-01</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.284202</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.199443e-01</td>\n",
       "      <td>3.397615e-01</td>\n",
       "      <td>3.707636e-01</td>\n",
       "      <td>5.212714e-01</td>\n",
       "      <td>0.838115</td>\n",
       "      <td>0.603350</td>\n",
       "      <td>0.675639</td>\n",
       "      <td>0.628488</td>\n",
       "      <td>0.471081</td>\n",
       "      <td>0.321416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333760</td>\n",
       "      <td>NDARZM903TNL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>3.394601e-01</td>\n",
       "      <td>4.781692e-01</td>\n",
       "      <td>5.423877e-01</td>\n",
       "      <td>4.137127e-01</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.538537</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>NDARZN148PMN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1.072605e-01</td>\n",
       "      <td>2.045245e-01</td>\n",
       "      <td>2.610531e-01</td>\n",
       "      <td>3.236518e-01</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.432447</td>\n",
       "      <td>0.412152</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>3.260273e-15</td>\n",
       "      <td>3.373362e-14</td>\n",
       "      <td>2.304057e-13</td>\n",
       "      <td>1.498324e-12</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.142998</td>\n",
       "      <td>0.689837</td>\n",
       "      <td>0.800874</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>3.945258e-01</td>\n",
       "      <td>4.017071e-01</td>\n",
       "      <td>2.867999e-01</td>\n",
       "      <td>3.721533e-01</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows Ã— 2661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3         4  \\\n",
       "0     3.497571e-01  4.585819e-01  2.938905e-01  3.770603e-01  0.327764   \n",
       "1     7.464767e-01  9.048637e-01  5.054438e-01  7.021925e-01  0.498947   \n",
       "2     2.204578e-01  3.562272e-01  3.895027e-01  4.181956e-01  0.495129   \n",
       "3     6.346560e-02  1.204557e-01  1.650503e-01  7.631559e-01  0.523793   \n",
       "4     2.758219e-01  2.255777e-01  4.828928e-01  4.704279e-01  0.330692   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "1915  2.199443e-01  3.397615e-01  3.707636e-01  5.212714e-01  0.838115   \n",
       "1916  3.394601e-01  4.781692e-01  5.423877e-01  4.137127e-01  0.379793   \n",
       "1917  1.072605e-01  2.045245e-01  2.610531e-01  3.236518e-01  0.437417   \n",
       "1918  3.260273e-15  3.373362e-14  2.304057e-13  1.498324e-12  0.000009   \n",
       "1919  3.945258e-01  4.017071e-01  2.867999e-01  3.721533e-01  0.583645   \n",
       "\n",
       "             5         6         7         8         9  ...      2651  \\\n",
       "0     0.552059  0.462017  0.695207  0.642190  0.584085  ...  0.179322   \n",
       "1     0.342338  0.283478  0.221679  0.178758  0.178338  ...  0.448476   \n",
       "2     0.436858  0.392300  0.446757  0.528172  0.409405  ...  0.545169   \n",
       "3     0.399243  0.267432  0.301397  0.283535  0.363612  ...  0.339304   \n",
       "4     0.310594  0.284202  0.298111  0.245370  0.250187  ...  0.013197   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "1915  0.603350  0.675639  0.628488  0.471081  0.321416  ...  0.333760   \n",
       "1916  0.413474  0.538537  0.457002  0.286496  0.222562  ...  0.367943   \n",
       "1917  0.432447  0.412152  0.445771  0.374603  0.386189  ...  0.008403   \n",
       "1918  0.142998  0.689837  0.800874  0.499946  0.248208  ...  0.032335   \n",
       "1919  0.497248  0.302516  0.193872  0.343920  0.500556  ...  0.373653   \n",
       "\n",
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA947ZG5                                         1   \n",
       "4     NDARAA948VFH                                         1   \n",
       "...            ...                                       ...   \n",
       "1915  NDARZM903TNL                                         0   \n",
       "1916  NDARZN148PMN                                         0   \n",
       "1917  NDARZN277NR6                                         1   \n",
       "1918  NDARZN610GTY                                         0   \n",
       "1919  NDARZN677EYE                                         1   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     0                           1                         1   \n",
       "4                     0                           0                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "1915                  0                           0                         0   \n",
       "1916                  1                           0                         0   \n",
       "1917                  1                           0                         0   \n",
       "1918                  0                           0                         0   \n",
       "1919                  0                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \\\n",
       "0              0                       0                     0   \n",
       "1              1                       0                     0   \n",
       "2              1                       0                     0   \n",
       "3              0                       0                     0   \n",
       "4              0                       0                     0   \n",
       "...          ...                     ...                   ...   \n",
       "1915           0                       0                     0   \n",
       "1916           0                       0                     0   \n",
       "1917           0                       0                     1   \n",
       "1918           0                       0                     0   \n",
       "1919           0                       0                     0   \n",
       "\n",
       "      Other Disorders  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "...               ...  \n",
       "1915                0  \n",
       "1916                0  \n",
       "1917                0  \n",
       "1918                1  \n",
       "1919                0  \n",
       "\n",
       "[1920 rows x 2661 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df2, foof, on='IDs', how='inner')\n",
    "df = pd.merge(df2, labels, on='IDs', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2652) (1920, 8)\n"
     ]
    }
   ],
   "source": [
    "disorders_list = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders', 'Other Disorders']\n",
    "x = df[df.columns.difference(['IDs']+disorders_list)]\n",
    "y = df[disorders_list]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.95) # 95% variance retained\n",
    "pca.fit(x)\n",
    "\n",
    "# transform data\n",
    "x_pca = pca.transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "\n",
    "\n",
    "x_pca = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling features\n",
    "\n",
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x)\n",
    "\n",
    "# transform training data\n",
    "x_norm = norm.transform(x)\n",
    "x_norm = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention-Deficit/Hyperactivity Disorder    866\n",
       "Anxiety Disorders                           478\n",
       "Specific Learning Disorder                  326\n",
       "Autism Spectrum Disorder                    224\n",
       "Disruptive                                  227\n",
       "Communication Disorder                      206\n",
       "Depressive Disorders                        149\n",
       "Other Disorders                             562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention-Deficit/Hyperactivity Disorder    299\n",
       "Anxiety Disorders                           161\n",
       "Specific Learning Disorder                  113\n",
       "Autism Spectrum Disorder                     67\n",
       "Disruptive                                   70\n",
       "Communication Disorder                       66\n",
       "Depressive Disorders                         45\n",
       "Other Disorders                             194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 22:52:42.514731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 - 2s - loss: 8.0477\n",
      "Epoch 2/50\n",
      "90/90 - 2s - loss: 0.2293\n",
      "Epoch 3/50\n",
      "90/90 - 2s - loss: 0.2331\n",
      "Epoch 4/50\n",
      "90/90 - 2s - loss: 0.2468\n",
      "Epoch 5/50\n",
      "90/90 - 2s - loss: 0.2478\n",
      "Epoch 6/50\n",
      "90/90 - 2s - loss: 0.2730\n",
      "Epoch 7/50\n",
      "90/90 - 2s - loss: 0.2857\n",
      "Epoch 8/50\n",
      "90/90 - 2s - loss: 0.2685\n",
      "Epoch 9/50\n",
      "90/90 - 2s - loss: 0.2675\n",
      "Epoch 10/50\n",
      "90/90 - 2s - loss: 0.2953\n",
      "Epoch 11/50\n",
      "90/90 - 2s - loss: 0.2988\n",
      "Epoch 12/50\n",
      "90/90 - 2s - loss: 0.2637\n",
      "Epoch 13/50\n",
      "90/90 - 2s - loss: 0.2797\n",
      "Epoch 14/50\n",
      "90/90 - 2s - loss: 0.2756\n",
      "Epoch 15/50\n",
      "90/90 - 2s - loss: 0.3044\n",
      "Epoch 16/50\n",
      "90/90 - 2s - loss: 0.3169\n",
      "Epoch 17/50\n",
      "90/90 - 2s - loss: 0.3140\n",
      "Epoch 18/50\n",
      "90/90 - 2s - loss: 0.3291\n",
      "Epoch 19/50\n",
      "90/90 - 2s - loss: 0.3381\n",
      "Epoch 20/50\n",
      "90/90 - 2s - loss: 0.2861\n",
      "Epoch 21/50\n",
      "90/90 - 2s - loss: 0.2923\n",
      "Epoch 22/50\n",
      "90/90 - 2s - loss: 0.3024\n",
      "Epoch 23/50\n",
      "90/90 - 2s - loss: 0.2685\n",
      "Epoch 24/50\n",
      "90/90 - 2s - loss: 0.2852\n",
      "Epoch 25/50\n",
      "90/90 - 2s - loss: 0.3235\n",
      "Epoch 26/50\n",
      "90/90 - 2s - loss: 0.3431\n",
      "Epoch 27/50\n",
      "90/90 - 2s - loss: 0.2856\n",
      "Epoch 28/50\n",
      "90/90 - 2s - loss: 0.3212\n",
      "Epoch 29/50\n",
      "90/90 - 2s - loss: 0.3190\n",
      "Epoch 30/50\n",
      "90/90 - 2s - loss: 0.2894\n",
      "Epoch 31/50\n",
      "90/90 - 2s - loss: 0.2918\n",
      "Epoch 32/50\n",
      "90/90 - 2s - loss: 0.3065\n",
      "Epoch 33/50\n",
      "90/90 - 2s - loss: 0.2945\n",
      "Epoch 34/50\n",
      "90/90 - 2s - loss: 0.3151\n",
      "Epoch 35/50\n",
      "90/90 - 2s - loss: 0.3064\n",
      "Epoch 36/50\n",
      "90/90 - 2s - loss: 0.3535\n",
      "Epoch 37/50\n",
      "90/90 - 2s - loss: 0.2934\n",
      "Epoch 38/50\n",
      "90/90 - 2s - loss: 0.2820\n",
      "Epoch 39/50\n",
      "90/90 - 2s - loss: 0.2891\n",
      "Epoch 40/50\n",
      "90/90 - 2s - loss: 0.2966\n",
      "Epoch 41/50\n",
      "90/90 - 2s - loss: 0.2784\n",
      "Epoch 42/50\n",
      "90/90 - 2s - loss: 0.3093\n",
      "Epoch 43/50\n",
      "90/90 - 2s - loss: 0.2807\n",
      "Epoch 44/50\n",
      "90/90 - 2s - loss: 0.2857\n",
      "Epoch 45/50\n",
      "90/90 - 2s - loss: 0.2811\n",
      "Epoch 46/50\n",
      "90/90 - 2s - loss: 0.2849\n",
      "Epoch 47/50\n",
      "90/90 - 2s - loss: 0.2974\n",
      "Epoch 48/50\n",
      "90/90 - 2s - loss: 0.3008\n",
      "Epoch 49/50\n",
      "90/90 - 2s - loss: 0.2805\n",
      "Epoch 50/50\n",
      "90/90 - 2s - loss: 0.2762\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "n_inputs = train_features.shape[1]\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "output = Dense(8, activation='linear')(d)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=50, batch_size=16, verbose=2)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "encoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "encoder= load_model('autoencoder.h5', compile=False)\n",
    "\n",
    "train_features = encoder.predict(train_features)\n",
    "test_features = encoder.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))\n",
    "\n",
    "def evaluate(y_test, y_pred_prob, brier=True):\n",
    "    y_pred = y_pred_prob.round()\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    if brier:\n",
    "        print(\"Brier Score:\", brier_multi(y_test, y_pred_prob))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.052083333333333336\n",
      "Hamming Loss: 0.3026041666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       299\n",
      "           1       0.33      0.27      0.30       161\n",
      "           2       0.23      0.16      0.19       113\n",
      "           3       0.07      0.03      0.04        67\n",
      "           4       0.20      0.13      0.16        70\n",
      "           5       0.04      0.02      0.02        66\n",
      "           6       0.14      0.04      0.07        45\n",
      "           7       0.38      0.34      0.36       194\n",
      "\n",
      "   micro avg       0.41      0.33      0.36      1015\n",
      "   macro avg       0.25      0.20      0.22      1015\n",
      "weighted avg       0.36      0.33      0.34      1015\n",
      " samples avg       0.51      0.42      0.32      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 64 117]\n",
      "  [109 190]]\n",
      "\n",
      " [[229  90]\n",
      "  [117  44]]\n",
      "\n",
      " [[305  62]\n",
      "  [ 95  18]]\n",
      "\n",
      " [[385  28]\n",
      "  [ 65   2]]\n",
      "\n",
      " [[375  35]\n",
      "  [ 61   9]]\n",
      "\n",
      " [[387  27]\n",
      "  [ 65   1]]\n",
      "\n",
      " [[423  12]\n",
      "  [ 43   2]]\n",
      "\n",
      " [[179 107]\n",
      "  [129  65]]]\n",
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.12916666666666668\n",
      "Hamming Loss: 0.23802083333333332\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.74       299\n",
      "           1       0.44      0.02      0.05       161\n",
      "           2       0.00      0.00      0.00       113\n",
      "           3       0.00      0.00      0.00        67\n",
      "           4       1.00      0.01      0.03        70\n",
      "           5       1.00      0.02      0.03        66\n",
      "           6       1.00      0.00      0.00        45\n",
      "           7       0.39      0.04      0.07       194\n",
      "\n",
      "   micro avg       0.61      0.28      0.38      1015\n",
      "   macro avg       0.56      0.12      0.11      1015\n",
      "weighted avg       0.51      0.28      0.24      1015\n",
      " samples avg       0.65      0.37      0.37      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 19 162]\n",
      "  [ 31 268]]\n",
      "\n",
      " [[314   5]\n",
      "  [157   4]]\n",
      "\n",
      " [[366   1]\n",
      "  [113   0]]\n",
      "\n",
      " [[412   1]\n",
      "  [ 67   0]]\n",
      "\n",
      " [[410   0]\n",
      "  [ 69   1]]\n",
      "\n",
      " [[414   0]\n",
      "  [ 65   1]]\n",
      "\n",
      " [[435   0]\n",
      "  [ 45   0]]\n",
      "\n",
      " [[275  11]\n",
      "  [187   7]]]\n",
      "SVC():\n",
      "Accuracy: 0.13333333333333333\n",
      "Hamming Loss: 0.23359375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       299\n",
      "           1       1.00      0.00      0.00       161\n",
      "           2       1.00      0.00      0.00       113\n",
      "           3       1.00      0.00      0.00        67\n",
      "           4       1.00      0.00      0.00        70\n",
      "           5       1.00      0.00      0.00        66\n",
      "           6       1.00      0.00      0.00        45\n",
      "           7       1.00      0.00      0.00       194\n",
      "\n",
      "   micro avg       0.62      0.29      0.40      1015\n",
      "   macro avg       0.95      0.12      0.10      1015\n",
      "weighted avg       0.89      0.29      0.23      1015\n",
      " samples avg       0.62      0.39      0.39      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  1 180]\n",
      "  [  1 298]]\n",
      "\n",
      " [[319   0]\n",
      "  [161   0]]\n",
      "\n",
      " [[367   0]\n",
      "  [113   0]]\n",
      "\n",
      " [[413   0]\n",
      "  [ 67   0]]\n",
      "\n",
      " [[410   0]\n",
      "  [ 70   0]]\n",
      "\n",
      " [[414   0]\n",
      "  [ 66   0]]\n",
      "\n",
      " [[435   0]\n",
      "  [ 45   0]]\n",
      "\n",
      " [[286   0]\n",
      "  [194   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels, brier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 23:12:39.157673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-25 23:12:39.164137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.164430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-25 23:12:39.164568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-25 23:12:39.166014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-25 23:12:39.167650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-25 23:12:39.167867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-25 23:12:39.169513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-25 23:12:39.170479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-25 23:12:39.174095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-25 23:12:39.174253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.174622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.174867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-25 23:12:39.175286: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-11-25 23:12:39.182417: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-11-25 23:12:39.183109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c65889ff60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-25 23:12:39.183123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-25 23:12:39.183297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.183570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-25 23:12:39.183605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-25 23:12:39.183618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-25 23:12:39.183629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-25 23:12:39.183640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-25 23:12:39.183650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-25 23:12:39.183661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-25 23:12:39.183683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-25 23:12:39.183742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.184038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.184281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-25 23:12:39.184311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-25 23:12:39.241081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-25 23:12:39.241113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-25 23:12:39.241118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-25 23:12:39.241450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.241767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.242042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-25 23:12:39.242289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 379 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-11-25 23:12:39.244054: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c6588d6b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-25 23:12:39.244065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/45 [..............................] - ETA: 0s - loss: 0.6745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 23:12:39.987598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5678\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5223\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5155\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5126\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5061\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5047\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5025\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5029\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4990\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4946\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4924\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4909\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4872\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4842\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4830\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4810\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4793\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4797\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4740\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4726\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4699\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4719\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4689\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4639\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4623\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4593\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4540\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4517\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4468\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4483\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4482\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4430\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4420\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4346\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4371\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4295\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4293\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4272\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4212\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4173\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4179\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4175\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4125\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4114\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4028\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4019\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4030\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4011\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3972\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3910\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3912\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3891\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3861\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3877\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3836\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3776\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3734\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3775\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3724\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3715\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3722\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3623\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3628\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3636\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3601\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3559\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3542\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3527\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3474\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3455\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3497\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3400\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3387\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3384\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3391\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3355\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3338\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3305\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3305\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3279\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3243\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3222\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3198\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3179\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3136\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3188\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3119\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3092\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3079\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3052\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3094\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3055\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3000\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3008\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2969\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2989\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3018\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2903\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04e6b747f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = train_features.shape[1],train_labels.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10416666666666667\n",
      "Hamming Loss: 0.2677083333333333\n",
      "Brier Score: 1.5939197152667515\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       299\n",
      "           1       0.40      0.20      0.27       161\n",
      "           2       0.15      0.04      0.06       113\n",
      "           3       0.10      0.01      0.03        67\n",
      "           4       0.15      0.04      0.07        70\n",
      "           5       0.00      0.00      0.00        66\n",
      "           6       0.00      0.00      0.00        45\n",
      "           7       0.38      0.22      0.28       194\n",
      "\n",
      "   micro avg       0.49      0.31      0.38      1015\n",
      "   macro avg       0.22      0.16      0.17      1015\n",
      "weighted avg       0.35      0.31      0.31      1015\n",
      " samples avg       0.59      0.40      0.35      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 41 140]\n",
      "  [ 73 226]]\n",
      "\n",
      " [[270  49]\n",
      "  [128  33]]\n",
      "\n",
      " [[344  23]\n",
      "  [109   4]]\n",
      "\n",
      " [[404   9]\n",
      "  [ 66   1]]\n",
      "\n",
      " [[393  17]\n",
      "  [ 67   3]]\n",
      "\n",
      " [[407   7]\n",
      "  [ 66   0]]\n",
      "\n",
      " [[427   8]\n",
      "  [ 45   0]]\n",
      "\n",
      " [[216  70]\n",
      "  [151  43]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19375\n",
      "Hamming Loss: 0.17890625\n",
      "Brier Score: 1.3800143446430682\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81       299\n",
      "           1       0.54      0.67      0.60       161\n",
      "           2       0.59      0.88      0.71       113\n",
      "           3       0.59      0.73      0.65        67\n",
      "           4       0.35      0.81      0.49        70\n",
      "           5       0.55      0.91      0.68        66\n",
      "           6       0.52      0.84      0.64        45\n",
      "           7       0.77      0.79      0.78       194\n",
      "\n",
      "   micro avg       0.63      0.78      0.70      1015\n",
      "   macro avg       0.60      0.80      0.67      1015\n",
      "weighted avg       0.67      0.78      0.71      1015\n",
      " samples avg       0.63      0.82      0.65      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[143  38]\n",
      "  [ 68 231]]\n",
      "\n",
      " [[228  91]\n",
      "  [ 53 108]]\n",
      "\n",
      " [[299  68]\n",
      "  [ 14  99]]\n",
      "\n",
      " [[379  34]\n",
      "  [ 18  49]]\n",
      "\n",
      " [[305 105]\n",
      "  [ 13  57]]\n",
      "\n",
      " [[364  50]\n",
      "  [  6  60]]\n",
      "\n",
      " [[400  35]\n",
      "  [  7  38]]\n",
      "\n",
      " [[240  46]\n",
      "  [ 41 153]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_br.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06041666666666667\n",
      "Hamming Loss: 0.30390625\n",
      "Brier Score: 1.8725155156759457\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       299\n",
      "           1       0.31      0.26      0.28       161\n",
      "           2       0.21      0.15      0.18       113\n",
      "           3       0.10      0.04      0.06        67\n",
      "           4       0.16      0.11      0.13        70\n",
      "           5       0.04      0.02      0.02        66\n",
      "           6       0.19      0.07      0.10        45\n",
      "           7       0.38      0.29      0.33       194\n",
      "\n",
      "   micro avg       0.40      0.32      0.35      1015\n",
      "   macro avg       0.25      0.20      0.22      1015\n",
      "weighted avg       0.36      0.32      0.33      1015\n",
      " samples avg       0.52      0.41      0.31      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 64 117]\n",
      "  [109 190]]\n",
      "\n",
      " [[225  94]\n",
      "  [119  42]]\n",
      "\n",
      " [[304  63]\n",
      "  [ 96  17]]\n",
      "\n",
      " [[385  28]\n",
      "  [ 64   3]]\n",
      "\n",
      " [[369  41]\n",
      "  [ 62   8]]\n",
      "\n",
      " [[389  25]\n",
      "  [ 65   1]]\n",
      "\n",
      " [[422  13]\n",
      "  [ 42   3]]\n",
      "\n",
      " [[195  91]\n",
      "  [138  56]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11458333333333333\n",
      "Hamming Loss: 0.2526041666666667\n",
      "Brier Score: 1.4573849779656916\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       299\n",
      "           1       0.28      0.08      0.12       161\n",
      "           2       0.36      0.04      0.06       113\n",
      "           3       0.20      0.01      0.03        67\n",
      "           4       0.25      0.03      0.05        70\n",
      "           5       1.00      0.00      0.00        66\n",
      "           6       1.00      0.00      0.00        45\n",
      "           7       0.42      0.19      0.26       194\n",
      "\n",
      "   micro avg       0.54      0.27      0.36      1015\n",
      "   macro avg       0.52      0.14      0.15      1015\n",
      "weighted avg       0.49      0.27      0.28      1015\n",
      " samples avg       0.67      0.36      0.34      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 51 130]\n",
      "  [ 79 220]]\n",
      "\n",
      " [[285  34]\n",
      "  [148  13]]\n",
      "\n",
      " [[360   7]\n",
      "  [109   4]]\n",
      "\n",
      " [[409   4]\n",
      "  [ 66   1]]\n",
      "\n",
      " [[404   6]\n",
      "  [ 68   2]]\n",
      "\n",
      " [[414   0]\n",
      "  [ 66   0]]\n",
      "\n",
      " [[435   0]\n",
      "  [ 45   0]]\n",
      "\n",
      " [[235  51]\n",
      "  [157  37]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLkNN()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "mlknn = MLkNN(k=10)\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "\n",
    "mlknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08333333333333333\n",
      "Hamming Loss: 0.2643229166666667\n",
      "Brier Score: 1.8596905609591032\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       299\n",
      "           1       1.00      0.00      0.00       161\n",
      "           2       1.00      0.00      0.00       113\n",
      "           3       1.00      0.00      0.00        67\n",
      "           4       1.00      0.00      0.00        70\n",
      "           5       1.00      0.00      0.00        66\n",
      "           6       1.00      0.00      0.00        45\n",
      "           7       1.00      0.00      0.00       194\n",
      "\n",
      "   micro avg       1.00      0.00      0.00      1015\n",
      "   macro avg       1.00      0.00      0.00      1015\n",
      "weighted avg       1.00      0.00      0.00      1015\n",
      " samples avg       1.00      0.08      0.08      1015\n",
      "\n",
      "Confusion matrix:\n",
      " [[[181   0]\n",
      "  [299   0]]\n",
      "\n",
      " [[319   0]\n",
      "  [161   0]]\n",
      "\n",
      " [[367   0]\n",
      "  [113   0]]\n",
      "\n",
      " [[413   0]\n",
      "  [ 67   0]]\n",
      "\n",
      " [[410   0]\n",
      "  [ 70   0]]\n",
      "\n",
      " [[414   0]\n",
      "  [ 66   0]]\n",
      "\n",
      " [[435   0]\n",
      "  [ 45   0]]\n",
      "\n",
      " [[286   0]\n",
      "  [194   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlknn = mlknn.predict_proba(x_test)\n",
    "evaluate(test_labels, predicted_labels_mlknn.todense())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
