{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we use these columns nly to get the subject ID\n",
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Electrode 105 - 71/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 72/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 73/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 74/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 75/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 76/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 77/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 78/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 79/2 Hz,)</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.646692</td>\n",
       "      <td>21.409617</td>\n",
       "      <td>11.791191</td>\n",
       "      <td>7.654361</td>\n",
       "      <td>5.294041</td>\n",
       "      <td>4.281935</td>\n",
       "      <td>3.556075</td>\n",
       "      <td>2.891063</td>\n",
       "      <td>2.375165</td>\n",
       "      <td>2.321368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.803485</td>\n",
       "      <td>31.315928</td>\n",
       "      <td>20.393061</td>\n",
       "      <td>13.173540</td>\n",
       "      <td>6.198943</td>\n",
       "      <td>4.636760</td>\n",
       "      <td>4.205091</td>\n",
       "      <td>4.182367</td>\n",
       "      <td>3.032023</td>\n",
       "      <td>2.775398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.029361</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>0.021678</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.719575</td>\n",
       "      <td>13.953344</td>\n",
       "      <td>8.733713</td>\n",
       "      <td>5.339339</td>\n",
       "      <td>3.654114</td>\n",
       "      <td>3.280150</td>\n",
       "      <td>3.597552</td>\n",
       "      <td>3.324361</td>\n",
       "      <td>2.615713</td>\n",
       "      <td>1.973499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.016645</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.013120</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.091286</td>\n",
       "      <td>7.064044</td>\n",
       "      <td>3.388819</td>\n",
       "      <td>2.020668</td>\n",
       "      <td>1.283089</td>\n",
       "      <td>1.225795</td>\n",
       "      <td>1.391197</td>\n",
       "      <td>1.194422</td>\n",
       "      <td>1.073312</td>\n",
       "      <td>0.945446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.878377</td>\n",
       "      <td>9.354415</td>\n",
       "      <td>5.324718</td>\n",
       "      <td>3.351567</td>\n",
       "      <td>2.634583</td>\n",
       "      <td>2.559906</td>\n",
       "      <td>2.273353</td>\n",
       "      <td>1.941904</td>\n",
       "      <td>1.331602</td>\n",
       "      <td>0.881906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>2.089436</td>\n",
       "      <td>2.277007</td>\n",
       "      <td>1.587069</td>\n",
       "      <td>1.361913</td>\n",
       "      <td>1.177022</td>\n",
       "      <td>0.991350</td>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.536954</td>\n",
       "      <td>0.399566</td>\n",
       "      <td>0.340996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.014557</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.012685</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>10.152438</td>\n",
       "      <td>9.639543</td>\n",
       "      <td>5.917194</td>\n",
       "      <td>3.909757</td>\n",
       "      <td>2.970778</td>\n",
       "      <td>2.726462</td>\n",
       "      <td>2.339991</td>\n",
       "      <td>2.024998</td>\n",
       "      <td>1.875718</td>\n",
       "      <td>1.679626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>3.654829</td>\n",
       "      <td>3.047049</td>\n",
       "      <td>1.688567</td>\n",
       "      <td>1.394472</td>\n",
       "      <td>1.627901</td>\n",
       "      <td>1.574334</td>\n",
       "      <td>1.852648</td>\n",
       "      <td>1.315756</td>\n",
       "      <td>1.039766</td>\n",
       "      <td>1.150138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051279</td>\n",
       "      <td>0.052121</td>\n",
       "      <td>0.051111</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.052505</td>\n",
       "      <td>0.048095</td>\n",
       "      <td>0.049762</td>\n",
       "      <td>0.050901</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>4.242865</td>\n",
       "      <td>4.473603</td>\n",
       "      <td>3.151083</td>\n",
       "      <td>2.222441</td>\n",
       "      <td>1.890155</td>\n",
       "      <td>2.017281</td>\n",
       "      <td>2.327400</td>\n",
       "      <td>2.495586</td>\n",
       "      <td>2.321074</td>\n",
       "      <td>2.505722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027194</td>\n",
       "      <td>0.025103</td>\n",
       "      <td>0.022879</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>16.788109</td>\n",
       "      <td>13.935762</td>\n",
       "      <td>8.609984</td>\n",
       "      <td>6.263200</td>\n",
       "      <td>5.506578</td>\n",
       "      <td>4.999711</td>\n",
       "      <td>4.599550</td>\n",
       "      <td>3.712844</td>\n",
       "      <td>2.657539</td>\n",
       "      <td>2.406728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.009243</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.009178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2056 rows × 8296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                   22.646692                21.409617   \n",
       "1                   35.803485                31.315928   \n",
       "2                   13.719575                13.953344   \n",
       "3                    7.091286                 7.064044   \n",
       "4                    9.878377                 9.354415   \n",
       "...                       ...                      ...   \n",
       "2051                 2.089436                 2.277007   \n",
       "2052                10.152438                 9.639543   \n",
       "2053                 3.654829                 3.047049   \n",
       "2054                 4.242865                 4.473603   \n",
       "2055                16.788109                13.935762   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                   11.791191                 7.654361   \n",
       "1                   20.393061                13.173540   \n",
       "2                    8.733713                 5.339339   \n",
       "3                    3.388819                 2.020668   \n",
       "4                    5.324718                 3.351567   \n",
       "...                       ...                      ...   \n",
       "2051                 1.587069                 1.361913   \n",
       "2052                 5.917194                 3.909757   \n",
       "2053                 1.688567                 1.394472   \n",
       "2054                 3.151083                 2.222441   \n",
       "2055                 8.609984                 6.263200   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    5.294041                 4.281935   \n",
       "1                    6.198943                 4.636760   \n",
       "2                    3.654114                 3.280150   \n",
       "3                    1.283089                 1.225795   \n",
       "4                    2.634583                 2.559906   \n",
       "...                       ...                      ...   \n",
       "2051                 1.177022                 0.991350   \n",
       "2052                 2.970778                 2.726462   \n",
       "2053                 1.627901                 1.574334   \n",
       "2054                 1.890155                 2.017281   \n",
       "2055                 5.506578                 4.999711   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    3.556075                 2.891063   \n",
       "1                    4.205091                 4.182367   \n",
       "2                    3.597552                 3.324361   \n",
       "3                    1.391197                 1.194422   \n",
       "4                    2.273353                 1.941904   \n",
       "...                       ...                      ...   \n",
       "2051                 0.730675                 0.536954   \n",
       "2052                 2.339991                 2.024998   \n",
       "2053                 1.852648                 1.315756   \n",
       "2054                 2.327400                 2.495586   \n",
       "2055                 4.599550                 3.712844   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
       "0                    2.375165                  2.321368  ...   \n",
       "1                    3.032023                  2.775398  ...   \n",
       "2                    2.615713                  1.973499  ...   \n",
       "3                    1.073312                  0.945446  ...   \n",
       "4                    1.331602                  0.881906  ...   \n",
       "...                       ...                       ...  ...   \n",
       "2051                 0.399566                  0.340996  ...   \n",
       "2052                 1.875718                  1.679626  ...   \n",
       "2053                 1.039766                  1.150138  ...   \n",
       "2054                 2.321074                  2.505722  ...   \n",
       "2055                 2.657539                  2.406728  ...   \n",
       "\n",
       "      (Electrode 105 - 71/2 Hz,)  (Electrode 105 - 72/2 Hz,)  \\\n",
       "0                       0.014442                    0.013248   \n",
       "1                       0.029482                    0.035029   \n",
       "2                       0.021167                    0.019864   \n",
       "3                       0.012450                    0.014467   \n",
       "4                       0.009977                    0.010225   \n",
       "...                          ...                         ...   \n",
       "2051                    0.014905                    0.014557   \n",
       "2052                    0.014360                    0.012237   \n",
       "2053                    0.051279                    0.052121   \n",
       "2054                    0.027194                    0.025103   \n",
       "2055                    0.009580                    0.008987   \n",
       "\n",
       "      (Electrode 105 - 73/2 Hz,)  (Electrode 105 - 74/2 Hz,)  \\\n",
       "0                       0.011966                    0.011954   \n",
       "1                       0.032905                    0.029361   \n",
       "2                       0.018397                    0.016645   \n",
       "3                       0.014399                    0.014101   \n",
       "4                       0.009637                    0.009370   \n",
       "...                          ...                         ...   \n",
       "2051                    0.014418                    0.012811   \n",
       "2052                    0.011046                    0.011192   \n",
       "2053                    0.051111                    0.051777   \n",
       "2054                    0.022879                    0.021707   \n",
       "2055                    0.009243                    0.008483   \n",
       "\n",
       "      (Electrode 105 - 75/2 Hz,)  (Electrode 105 - 76/2 Hz,)  \\\n",
       "0                       0.011685                    0.012114   \n",
       "1                       0.025549                    0.021678   \n",
       "2                       0.015293                    0.015262   \n",
       "3                       0.012216                    0.012885   \n",
       "4                       0.008455                    0.008211   \n",
       "...                          ...                         ...   \n",
       "2051                    0.012592                    0.012685   \n",
       "2052                    0.011132                    0.011145   \n",
       "2053                    0.052505                    0.048095   \n",
       "2054                    0.020007                    0.021364   \n",
       "2055                    0.008499                    0.008845   \n",
       "\n",
       "      (Electrode 105 - 77/2 Hz,)  (Electrode 105 - 78/2 Hz,)  \\\n",
       "0                       0.011274                    0.011133   \n",
       "1                       0.023353                    0.021711   \n",
       "2                       0.013120                    0.013712   \n",
       "3                       0.011950                    0.011479   \n",
       "4                       0.008064                    0.008207   \n",
       "...                          ...                         ...   \n",
       "2051                    0.013041                    0.012496   \n",
       "2052                    0.010181                    0.010405   \n",
       "2053                    0.049762                    0.050901   \n",
       "2054                    0.020383                    0.018960   \n",
       "2055                    0.008806                    0.009432   \n",
       "\n",
       "      (Electrode 105 - 79/2 Hz,)           IDs  \n",
       "0                       0.009402  NDARAA075AMK  \n",
       "1                       0.023934  NDARAA112DMH  \n",
       "2                       0.014215  NDARAA117NEJ  \n",
       "3                       0.011285  NDARAA947ZG5  \n",
       "4                       0.008642  NDARAA948VFH  \n",
       "...                          ...           ...  \n",
       "2051                    0.011033           NaN  \n",
       "2052                    0.011229           NaN  \n",
       "2053                    0.049706           NaN  \n",
       "2054                    0.018877           NaN  \n",
       "2055                    0.009178           NaN  \n",
       "\n",
       "[2056 rows x 8296 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat(DATA_DIR+'x_nofoof.mat')  \n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(data['x'].shape[1]) for j in range(data['x'].shape[2])])\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['IDs']\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2813, 177)\n",
      "Removing 263 patients as their diagnoses were very uncommon.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'No Diagnosis Given', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "# most_common_disorders = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# find users that have no diagnosis within these top diseases\n",
    "# filtering should cahnge anything as this should also happen at a later stage\n",
    "mask = None\n",
    "for col in category_columns:\n",
    "    mask_col = beh[col].isin(most_common_disorders)\n",
    "    if mask is None:\n",
    "        mask = mask_col\n",
    "    else:\n",
    "        mask = mask | mask_col\n",
    "\n",
    "initial_size = beh.shape[0]\n",
    "beh = beh[mask]\n",
    "beh = beh.reset_index(drop=True)\n",
    "new_size = beh.shape[0]\n",
    "print('After:'+str(beh.shape))\n",
    "print('Removing', initial_size - new_size,\n",
    "      'patients as their diagnoses were very uncommon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "if no_diagnosis_given in most_common_disorders:\n",
    "    no_diag_index = most_common_disorders.index(no_diagnosis_given)\n",
    "    most_common_disorders = most_common_disorders[:no_diag_index] + \\\n",
    "        most_common_disorders[no_diag_index + 1:]\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while disorder != no_diagnosis_given and not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "    order_of_disorders.append(disorders_patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2813 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2808  NDARZZ007YMP                                         0   \n",
       "2809  NDARZZ740MLM                                         1   \n",
       "2810  NDARZZ810LVF                                         0   \n",
       "2811  NDARZZ830JM7                                         0   \n",
       "2812  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2808                  0                           0                         1   \n",
       "2809                  0                           0                         0   \n",
       "2810                  0                           0                         1   \n",
       "2811                  0                           0                         1   \n",
       "2812                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       1                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "2808           0                       0                     0  \n",
       "2809           0                       0                     0  \n",
       "2810           0                       1                     0  \n",
       "2811           0                       0                     0  \n",
       "2812           0                       0                     0  \n",
       "\n",
       "[2813 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=behaviour_data[[\"IDs\"]+list(most_common_disorders)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1836, 8303)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.merge(df, labels, on='IDs', how='inner')\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 8303)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#removing NaNs\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1823, 8295) (1823, 7)\n"
     ]
    }
   ],
   "source": [
    "x = df[df.columns.difference(['IDs']+most_common_disorders)]\n",
    "y = df[most_common_disorders]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#scaling features\n",
    "\n",
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x)\n",
    "\n",
    "# transform training data\n",
    "x_norm = norm.transform(x)\n",
    "x_norm = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.06946983546617916\n",
      "Hamming Loss: 0.306346304518151\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       341\n",
      "           1       0.34      0.30      0.32       186\n",
      "           2       0.21      0.17      0.19       133\n",
      "           3       0.19      0.17      0.18        81\n",
      "           4       0.17      0.15      0.16        74\n",
      "           5       0.10      0.12      0.11        72\n",
      "           6       0.19      0.17      0.18        69\n",
      "\n",
      "   micro avg       0.38      0.37      0.38       956\n",
      "   macro avg       0.26      0.25      0.26       956\n",
      "weighted avg       0.37      0.37      0.37       956\n",
      " samples avg       0.48      0.46      0.33       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 71 135]\n",
      "  [110 231]]\n",
      "\n",
      " [[254 107]\n",
      "  [131  55]]\n",
      "\n",
      " [[330  84]\n",
      "  [110  23]]\n",
      "\n",
      " [[406  60]\n",
      "  [ 67  14]]\n",
      "\n",
      " [[419  54]\n",
      "  [ 63  11]]\n",
      "\n",
      " [[394  81]\n",
      "  [ 63   9]]\n",
      "\n",
      " [[427  51]\n",
      "  [ 57  12]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.16270566727605118\n",
      "Hamming Loss: 0.2230347349177331\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       341\n",
      "           1       0.39      0.06      0.11       186\n",
      "           2       0.11      0.01      0.01       133\n",
      "           3       0.00      0.00      0.00        81\n",
      "           4       0.33      0.01      0.03        74\n",
      "           5       0.50      0.01      0.03        72\n",
      "           6       0.50      0.01      0.03        69\n",
      "\n",
      "   micro avg       0.59      0.34      0.44       956\n",
      "   macro avg       0.35      0.15      0.14       956\n",
      "weighted avg       0.41      0.34      0.29       956\n",
      " samples avg       0.64      0.45      0.41       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 15 191]\n",
      "  [ 28 313]]\n",
      "\n",
      " [[342  19]\n",
      "  [174  12]]\n",
      "\n",
      " [[406   8]\n",
      "  [132   1]]\n",
      "\n",
      " [[461   5]\n",
      "  [ 81   0]]\n",
      "\n",
      " [[471   2]\n",
      "  [ 73   1]]\n",
      "\n",
      " [[474   1]\n",
      "  [ 71   1]]\n",
      "\n",
      " [[477   1]\n",
      "  [ 68   1]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC():\n",
      "Accuracy: 0.17184643510054845\n",
      "Hamming Loss: 0.2144162966832071\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       341\n",
      "           1       1.00      0.00      0.00       186\n",
      "           2       1.00      0.00      0.00       133\n",
      "           3       1.00      0.00      0.00        81\n",
      "           4       1.00      0.00      0.00        74\n",
      "           5       1.00      0.00      0.00        72\n",
      "           6       1.00      0.00      0.00        69\n",
      "\n",
      "   micro avg       0.62      0.36      0.45       956\n",
      "   macro avg       0.95      0.14      0.11       956\n",
      "weighted avg       0.87      0.36      0.27       956\n",
      " samples avg       0.62      0.47      0.43       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  0 206]\n",
      "  [  0 341]]\n",
      "\n",
      " [[361   0]\n",
      "  [186   0]]\n",
      "\n",
      " [[414   0]\n",
      "  [133   0]]\n",
      "\n",
      " [[466   0]\n",
      "  [ 81   0]]\n",
      "\n",
      " [[473   0]\n",
      "  [ 74   0]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 72   0]]\n",
      "\n",
      " [[478   0]\n",
      "  [ 69   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 12:08:16.477558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-20 12:08:16.483762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.484054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-20 12:08:16.484209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-20 12:08:16.485310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-20 12:08:16.486648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-20 12:08:16.486834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-20 12:08:16.487987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-20 12:08:16.488653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-20 12:08:16.491199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-20 12:08:16.491346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.491710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.491955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-20 12:08:16.492544: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-11-20 12:08:16.498773: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-11-20 12:08:16.499358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55da2e8a0f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-20 12:08:16.499372: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-20 12:08:16.499523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.499797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-20 12:08:16.499838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-20 12:08:16.499851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-20 12:08:16.499862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-20 12:08:16.499872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-20 12:08:16.499883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-20 12:08:16.499894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-20 12:08:16.499904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-20 12:08:16.499961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.500255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.500495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-20 12:08:16.500525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-20 12:08:16.554209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-20 12:08:16.554238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-20 12:08:16.554244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-20 12:08:16.554564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.554876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.555151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-20 12:08:16.555400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 379 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-11-20 12:08:16.557162: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55da32fd93b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-20 12:08:16.557173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/40 [..............................] - ETA: 0s - loss: 2.6225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 12:08:17.286345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8767\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6815\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6719\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6624\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6519\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6427\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6328\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6244\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6197\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6123\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6022\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5888\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5891\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5775\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5618\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5439\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5331\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5166\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5123\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5101\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5315\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5039\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5012\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4967\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4965\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4957\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4932\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4914\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4938\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4947\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4942\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4941\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4956\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4940\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4933\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4937\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4925\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4924\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4991\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4924\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4879\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4879\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4881\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4889\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4880\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4950\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4877\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4868\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4863\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4929\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4840\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4862\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4847\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4864\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4888\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4833\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4827\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4815\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4828\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4822\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4814\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4808\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4861\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4837\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4809\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4798\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4821\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4823\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4797\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4815\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4902\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4780\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4775\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4792\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4920\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4817\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4787\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4769\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4837\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4763\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4805\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4815\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4758\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4819\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4838\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4789\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4809\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4813\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4743\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4733\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4737\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4775\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4741\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4767\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4737\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4804\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4727\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4728\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3c138f2af0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = x.shape[1], y.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.170018281535649\n",
      "Hamming Loss: 0.21467746147819275\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.99      0.77       341\n",
      "           1       1.00      0.00      0.00       186\n",
      "           2       1.00      0.00      0.00       133\n",
      "           3       1.00      0.00      0.00        81\n",
      "           4       1.00      0.00      0.00        74\n",
      "           5       1.00      0.00      0.00        72\n",
      "           6       1.00      0.00      0.00        69\n",
      "\n",
      "   micro avg       0.62      0.35      0.45       956\n",
      "   macro avg       0.95      0.14      0.11       956\n",
      "weighted avg       0.87      0.35      0.27       956\n",
      " samples avg       0.63      0.47      0.43       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  3 203]\n",
      "  [  4 337]]\n",
      "\n",
      " [[361   0]\n",
      "  [186   0]]\n",
      "\n",
      " [[414   0]\n",
      "  [133   0]]\n",
      "\n",
      " [[466   0]\n",
      "  [ 81   0]]\n",
      "\n",
      " [[473   0]\n",
      "  [ 74   0]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 72   0]]\n",
      "\n",
      " [[478   0]\n",
      "  [ 69   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08957952468007313\n",
      "Hamming Loss: 0.478453904413685\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.38      0.50       341\n",
      "           1       0.39      0.84      0.53       186\n",
      "           2       0.31      0.85      0.45       133\n",
      "           3       0.36      0.46      0.40        81\n",
      "           4       0.18      0.89      0.30        74\n",
      "           5       0.18      0.89      0.30        72\n",
      "           6       0.18      0.94      0.30        69\n",
      "\n",
      "   micro avg       0.30      0.66      0.41       956\n",
      "   macro avg       0.33      0.75      0.40       956\n",
      "weighted avg       0.45      0.66      0.45       956\n",
      " samples avg       0.35      0.68      0.40       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[156  50]\n",
      "  [210 131]]\n",
      "\n",
      " [[119 242]\n",
      "  [ 30 156]]\n",
      "\n",
      " [[160 254]\n",
      "  [ 20 113]]\n",
      "\n",
      " [[400  66]\n",
      "  [ 44  37]]\n",
      "\n",
      " [[171 302]\n",
      "  [  8  66]]\n",
      "\n",
      " [[185 290]\n",
      "  [  8  64]]\n",
      "\n",
      " [[174 304]\n",
      "  [  4  65]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07312614259597806\n",
      "Hamming Loss: 0.306346304518151\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65       341\n",
      "           1       0.34      0.30      0.32       186\n",
      "           2       0.22      0.19      0.20       133\n",
      "           3       0.18      0.15      0.16        81\n",
      "           4       0.17      0.18      0.17        74\n",
      "           5       0.14      0.17      0.15        72\n",
      "           6       0.18      0.16      0.17        69\n",
      "\n",
      "   micro avg       0.38      0.37      0.38       956\n",
      "   macro avg       0.27      0.26      0.26       956\n",
      "weighted avg       0.37      0.37      0.37       956\n",
      " samples avg       0.47      0.46      0.33       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 71 135]\n",
      "  [114 227]]\n",
      "\n",
      " [[254 107]\n",
      "  [131  55]]\n",
      "\n",
      " [[325  89]\n",
      "  [108  25]]\n",
      "\n",
      " [[411  55]\n",
      "  [ 69  12]]\n",
      "\n",
      " [[411  62]\n",
      "  [ 61  13]]\n",
      "\n",
      " [[400  75]\n",
      "  [ 60  12]]\n",
      "\n",
      " [[429  49]\n",
      "  [ 58  11]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06764168190127971\n",
      "Hamming Loss: 0.30373465656829457\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62       341\n",
      "           1       0.39      0.36      0.37       186\n",
      "           2       0.22      0.19      0.20       133\n",
      "           3       0.14      0.10      0.12        81\n",
      "           4       0.16      0.18      0.17        74\n",
      "           5       0.11      0.11      0.11        72\n",
      "           6       0.09      0.06      0.07        69\n",
      "\n",
      "   micro avg       0.38      0.35      0.37       956\n",
      "   macro avg       0.25      0.23      0.24       956\n",
      "weighted avg       0.37      0.35      0.36       956\n",
      " samples avg       0.49      0.43      0.31       956\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 80 126]\n",
      "  [130 211]]\n",
      "\n",
      " [[255 106]\n",
      "  [119  67]]\n",
      "\n",
      " [[327  87]\n",
      "  [108  25]]\n",
      "\n",
      " [[418  48]\n",
      "  [ 73   8]]\n",
      "\n",
      " [[406  67]\n",
      "  [ 61  13]]\n",
      "\n",
      " [[407  68]\n",
      "  [ 64   8]]\n",
      "\n",
      " [[437  41]\n",
      "  [ 65   4]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "mlknn = MLkNN(k=10)\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "# train\n",
    "mlknn.fit(x_train, y_train)\n",
    "# predict\n",
    "# predictions_new = classifier_new.predict(x_test)\n",
    "# # accuracy\n",
    "# print(\"Accuracy = \",accuracy_score(y_test,predictions_new))\n",
    "# print(\"\\n\")\n",
    "predicted_labels_mlknn = mlknn.predict(x_test)\n",
    "evaluate(test_labels, predicted_labels_mlknn)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
