{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YxOz-zNNlyy"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import uniform\n",
    "from numpy import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter,filterwarnings\n",
    "\n",
    "# ignore all future warnings1\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "#DATA_DIR = ''\n",
    "#if 'google.colab' not in str(get_ipython()):\n",
    "#    if \"anuja\" in os.environ.get('USER'):\n",
    "#        DATA_DIR = 'data/'\n",
    "#    elif \"martyna\" in os.environv.get('USER'):\n",
    "DATA_DIR = '/home/ubuntu/Martyna/repo/AI4Health/DATAfoof/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG data and foof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160123</td>\n",
       "      <td>1.362617</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>1.427172</td>\n",
       "      <td>0.810964</td>\n",
       "      <td>1.391837</td>\n",
       "      <td>0.745124</td>\n",
       "      <td>1.378194</td>\n",
       "      <td>0.527491</td>\n",
       "      <td>1.433532</td>\n",
       "      <td>...</td>\n",
       "      <td>1.519565</td>\n",
       "      <td>1.004265</td>\n",
       "      <td>1.450747</td>\n",
       "      <td>0.956578</td>\n",
       "      <td>1.456952</td>\n",
       "      <td>0.611944</td>\n",
       "      <td>1.503932</td>\n",
       "      <td>0.282555</td>\n",
       "      <td>1.441946</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988915</td>\n",
       "      <td>1.330636</td>\n",
       "      <td>1.151667</td>\n",
       "      <td>1.546990</td>\n",
       "      <td>1.479442</td>\n",
       "      <td>1.608810</td>\n",
       "      <td>1.342563</td>\n",
       "      <td>1.559859</td>\n",
       "      <td>0.460923</td>\n",
       "      <td>1.434832</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461904</td>\n",
       "      <td>1.449481</td>\n",
       "      <td>1.480738</td>\n",
       "      <td>0.889122</td>\n",
       "      <td>1.282076</td>\n",
       "      <td>0.950479</td>\n",
       "      <td>1.138697</td>\n",
       "      <td>1.372408</td>\n",
       "      <td>1.505823</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.455004</td>\n",
       "      <td>1.515717</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>1.367703</td>\n",
       "      <td>2.029333</td>\n",
       "      <td>1.763131</td>\n",
       "      <td>2.086803</td>\n",
       "      <td>1.763987</td>\n",
       "      <td>1.320758</td>\n",
       "      <td>1.585413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.502295</td>\n",
       "      <td>1.596192</td>\n",
       "      <td>1.448922</td>\n",
       "      <td>1.180667</td>\n",
       "      <td>1.199036</td>\n",
       "      <td>1.658822</td>\n",
       "      <td>1.619147</td>\n",
       "      <td>1.182087</td>\n",
       "      <td>1.395998</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796931</td>\n",
       "      <td>1.547997</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.956344</td>\n",
       "      <td>0.638462</td>\n",
       "      <td>1.222323</td>\n",
       "      <td>0.698921</td>\n",
       "      <td>1.395078</td>\n",
       "      <td>-0.130122</td>\n",
       "      <td>1.156477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.079507</td>\n",
       "      <td>1.285272</td>\n",
       "      <td>0.471817</td>\n",
       "      <td>1.175649</td>\n",
       "      <td>0.617125</td>\n",
       "      <td>1.418717</td>\n",
       "      <td>0.401675</td>\n",
       "      <td>1.222953</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.627481</td>\n",
       "      <td>1.123518</td>\n",
       "      <td>-0.255195</td>\n",
       "      <td>1.273727</td>\n",
       "      <td>0.197328</td>\n",
       "      <td>1.344738</td>\n",
       "      <td>0.282533</td>\n",
       "      <td>1.387126</td>\n",
       "      <td>-0.808075</td>\n",
       "      <td>1.077384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363285</td>\n",
       "      <td>0.049249</td>\n",
       "      <td>1.207528</td>\n",
       "      <td>-0.118998</td>\n",
       "      <td>1.296786</td>\n",
       "      <td>-0.253839</td>\n",
       "      <td>1.176320</td>\n",
       "      <td>-0.033039</td>\n",
       "      <td>1.318181</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>-0.124896</td>\n",
       "      <td>1.111637</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>1.109243</td>\n",
       "      <td>0.393830</td>\n",
       "      <td>0.864464</td>\n",
       "      <td>0.422308</td>\n",
       "      <td>0.871363</td>\n",
       "      <td>-0.311337</td>\n",
       "      <td>0.979262</td>\n",
       "      <td>...</td>\n",
       "      <td>1.104898</td>\n",
       "      <td>0.215057</td>\n",
       "      <td>0.976700</td>\n",
       "      <td>0.769451</td>\n",
       "      <td>1.101020</td>\n",
       "      <td>-0.013650</td>\n",
       "      <td>1.085802</td>\n",
       "      <td>0.159527</td>\n",
       "      <td>1.034021</td>\n",
       "      <td>NDARRY126FA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>0.259345</td>\n",
       "      <td>1.268732</td>\n",
       "      <td>0.532802</td>\n",
       "      <td>1.492400</td>\n",
       "      <td>0.722490</td>\n",
       "      <td>1.482126</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>1.432505</td>\n",
       "      <td>-0.205835</td>\n",
       "      <td>1.230099</td>\n",
       "      <td>...</td>\n",
       "      <td>1.508386</td>\n",
       "      <td>0.529724</td>\n",
       "      <td>1.352627</td>\n",
       "      <td>1.061175</td>\n",
       "      <td>1.606489</td>\n",
       "      <td>0.540497</td>\n",
       "      <td>1.275614</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.468853</td>\n",
       "      <td>NDARRY215CXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>0.396271</td>\n",
       "      <td>1.361393</td>\n",
       "      <td>0.176390</td>\n",
       "      <td>1.363488</td>\n",
       "      <td>0.753262</td>\n",
       "      <td>1.453320</td>\n",
       "      <td>0.707356</td>\n",
       "      <td>1.481902</td>\n",
       "      <td>-0.070967</td>\n",
       "      <td>1.338482</td>\n",
       "      <td>...</td>\n",
       "      <td>1.348029</td>\n",
       "      <td>0.901967</td>\n",
       "      <td>1.433662</td>\n",
       "      <td>0.392497</td>\n",
       "      <td>1.112497</td>\n",
       "      <td>0.585191</td>\n",
       "      <td>1.396128</td>\n",
       "      <td>0.307516</td>\n",
       "      <td>1.337915</td>\n",
       "      <td>NDARRY268AF2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>0.300712</td>\n",
       "      <td>1.325074</td>\n",
       "      <td>0.534767</td>\n",
       "      <td>1.416291</td>\n",
       "      <td>0.846201</td>\n",
       "      <td>1.590482</td>\n",
       "      <td>0.853024</td>\n",
       "      <td>1.632593</td>\n",
       "      <td>0.317269</td>\n",
       "      <td>1.416499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399847</td>\n",
       "      <td>0.863988</td>\n",
       "      <td>1.219525</td>\n",
       "      <td>1.119859</td>\n",
       "      <td>1.336477</td>\n",
       "      <td>0.667894</td>\n",
       "      <td>1.395374</td>\n",
       "      <td>0.618072</td>\n",
       "      <td>1.330237</td>\n",
       "      <td>NDARRY280KNW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>1.051434</td>\n",
       "      <td>1.550705</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>1.672055</td>\n",
       "      <td>1.661787</td>\n",
       "      <td>1.689536</td>\n",
       "      <td>1.554425</td>\n",
       "      <td>1.672472</td>\n",
       "      <td>0.777996</td>\n",
       "      <td>1.598291</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1412 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.160123  1.362617 -0.002037  1.427172  0.810964  1.391837  0.745124   \n",
       "1     0.988915  1.330636  1.151667  1.546990  1.479442  1.608810  1.342563   \n",
       "2     1.455004  1.515717  0.988018  1.367703  2.029333  1.763131  2.086803   \n",
       "3     0.796931  1.547997  0.016022  0.956344  0.638462  1.222323  0.698921   \n",
       "4    -0.627481  1.123518 -0.255195  1.273727  0.197328  1.344738  0.282533   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1407 -0.124896  1.111637  0.025096  1.109243  0.393830  0.864464  0.422308   \n",
       "1408  0.259345  1.268732  0.532802  1.492400  0.722490  1.482126  0.730926   \n",
       "1409  0.396271  1.361393  0.176390  1.363488  0.753262  1.453320  0.707356   \n",
       "1410  0.300712  1.325074  0.534767  1.416291  0.846201  1.590482  0.853024   \n",
       "1411  1.051434  1.550705  0.683616  1.672055  1.661787  1.689536  1.554425   \n",
       "\n",
       "             7         8         9  ...       127       128       129  \\\n",
       "0     1.378194  0.527491  1.433532  ...  1.519565  1.004265  1.450747   \n",
       "1     1.559859  0.460923  1.434832  ...  1.461904  1.449481  1.480738   \n",
       "2     1.763987  1.320758  1.585413  ...  1.502295  1.596192  1.448922   \n",
       "3     1.395078 -0.130122  1.156477  ...  0.998001  0.079507  1.285272   \n",
       "4     1.387126 -0.808075  1.077384  ...  1.363285  0.049249  1.207528   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1407  0.871363 -0.311337  0.979262  ...  1.104898  0.215057  0.976700   \n",
       "1408  1.432505 -0.205835  1.230099  ...  1.508386  0.529724  1.352627   \n",
       "1409  1.481902 -0.070967  1.338482  ...  1.348029  0.901967  1.433662   \n",
       "1410  1.632593  0.317269  1.416499  ...  1.399847  0.863988  1.219525   \n",
       "1411  1.672472  0.777996  1.598291  ...       NaN       NaN       NaN   \n",
       "\n",
       "           130       131       132       133       134       135           IDs  \n",
       "0     0.956578  1.456952  0.611944  1.503932  0.282555  1.441946  NDARAA075AMK  \n",
       "1     0.889122  1.282076  0.950479  1.138697  1.372408  1.505823  NDARAA112DMH  \n",
       "2     1.180667  1.199036  1.658822  1.619147  1.182087  1.395998  NDARAA117NEJ  \n",
       "3     0.471817  1.175649  0.617125  1.418717  0.401675  1.222953  NDARAA947ZG5  \n",
       "4    -0.118998  1.296786 -0.253839  1.176320 -0.033039  1.318181  NDARAA948VFH  \n",
       "...        ...       ...       ...       ...       ...       ...           ...  \n",
       "1407  0.769451  1.101020 -0.013650  1.085802  0.159527  1.034021  NDARRY126FA5  \n",
       "1408  1.061175  1.606489  0.540497  1.275614  0.835786  1.468853  NDARRY215CXQ  \n",
       "1409  0.392497  1.112497  0.585191  1.396128  0.307516  1.337915  NDARRY268AF2  \n",
       "1410  1.119859  1.336477  0.667894  1.395374  0.618072  1.330237  NDARRY280KNW  \n",
       "1411       NaN       NaN       NaN       NaN       NaN       NaN           NaN  \n",
       "\n",
       "[1412 rows x 137 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data loading\n",
    "data = mat73.loadmat(DATA_DIR+'x_source_new.mat')  \n",
    "foof = pd.read_csv(DATA_DIR+\"source_intercept_slope.csv\")\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([[[2.85210744e-12, 6.84395873e-11, 1.33448613e-09, ...,\n",
       "          6.40790987e-02, 4.29900039e-02, 2.21752327e-02],\n",
       "         [2.16919456e-01, 2.28965785e-01, 4.42665506e-03, ...,\n",
       "          7.77958670e-03, 3.80331201e-04, 5.71640022e-06],\n",
       "         [2.02453249e-08, 8.55537723e-07, 2.22058385e-05, ...,\n",
       "          4.21884749e-15, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [4.65705252e-12, 1.19924848e-10, 2.45344922e-09, ...,\n",
       "          1.10354007e-02, 2.80167345e-03, 5.12511030e-04],\n",
       "         [2.83217894e-13, 8.81272832e-12, 2.19235713e-10, ...,\n",
       "          8.71547487e-02, 8.17854504e-02, 5.69034798e-02],\n",
       "         [1.26797893e-08, 1.22521774e-07, 1.00365630e-06, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.83094547e-01, 2.74644661e-01, 2.61234403e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.17350757e-02, 1.89606919e-02, 1.06530517e-02],\n",
       "         [2.75566098e-02, 1.54723812e-01, 3.14819391e-01, ...,\n",
       "          2.15963792e-01, 1.83017534e-01, 1.42487613e-01],\n",
       "         ...,\n",
       "         [5.09208111e-01, 7.17001759e-01, 6.35137172e-01, ...,\n",
       "          1.90722531e-02, 5.61322620e-03, 1.39651236e-03],\n",
       "         [3.29182433e-01, 3.74830932e-01, 4.08440824e-01, ...,\n",
       "          9.53213990e-04, 3.84594082e-07, 1.41724978e-08],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.58858638e-04, 3.48194876e-05, 8.23329756e-07]],\n",
       " \n",
       "        [[1.87372686e-04, 3.70020320e-02, 1.33834148e-01, ...,\n",
       "          1.92610258e-03, 1.68208043e-04, 8.93361164e-06],\n",
       "         [1.03069269e-07, 2.50007246e-06, 9.76589368e-05, ...,\n",
       "          7.63456396e-08, 3.56185437e-09, 1.24962041e-10],\n",
       "         [4.61254149e-04, 8.20187260e-04, 1.41786418e-03, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [3.36695243e-01, 3.78727726e-01, 3.91769487e-01, ...,\n",
       "          3.33514464e-02, 2.93057611e-02, 2.55730397e-02],\n",
       "         [8.19344592e-14, 1.59028346e-12, 2.68838285e-11, ...,\n",
       "          2.32313243e-04, 8.44570142e-06, 1.59011735e-07],\n",
       "         [3.21091742e-07, 2.19446598e-06, 3.04417925e-05, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00000000e+00, 7.77156117e-16, 3.63042929e-14, ...,\n",
       "          2.07842841e-01, 2.25517276e-01, 2.26513334e-01],\n",
       "         [1.09635081e-01, 1.36632384e-01, 1.61052194e-01, ...,\n",
       "          1.63829132e-01, 1.59767164e-01, 1.54727671e-01],\n",
       "         [8.94062602e-13, 1.81338278e-11, 3.08703951e-10, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [5.14096050e-08, 4.86676580e-06, 2.09589289e-04, ...,\n",
       "          3.69545134e-06, 3.37791221e-07, 2.40998075e-08],\n",
       "         [8.84792239e-13, 1.73908110e-11, 2.86953794e-10, ...,\n",
       "          1.20792265e-13, 8.43769499e-15, 1.33226763e-15],\n",
       "         [9.18608034e-09, 1.15507989e-06, 6.49658906e-05, ...,\n",
       "          1.11835954e-01, 1.02151080e-01, 9.16737825e-02]],\n",
       " \n",
       "        [[1.36380005e-08, 1.52123517e-07, 1.42803927e-06, ...,\n",
       "          9.01305031e-10, 3.05819148e-10, 1.00760067e-10],\n",
       "         [2.04990938e-05, 3.88703247e-05, 7.33278662e-05, ...,\n",
       "          4.05155909e-10, 1.58040470e-10, 6.03812556e-11],\n",
       "         [1.87805327e-12, 6.59278188e-11, 1.93066091e-09, ...,\n",
       "          2.91940482e-06, 1.33745328e-06, 5.96688015e-07],\n",
       "         ...,\n",
       "         [8.81253481e-09, 2.71046093e-08, 8.02934329e-08, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.46009179e-01, 1.82187650e-01, 4.16383520e-03, ...,\n",
       "          5.77891718e-07, 2.64025154e-07, 1.17888542e-07],\n",
       "         [2.10193439e-08, 2.14712487e-07, 1.85690946e-06, ...,\n",
       "          1.19275279e-09, 3.81219945e-10, 1.17838184e-10]],\n",
       " \n",
       "        [[1.05387921e-12, 1.64412373e-10, 1.47061869e-08, ...,\n",
       "          1.65339732e-01, 1.72657043e-01, 1.49912686e-01],\n",
       "         [2.68174944e-04, 9.50767658e-04, 2.96547460e-03, ...,\n",
       "          2.38851060e-02, 2.09608949e-02, 1.82673914e-02],\n",
       "         [1.16641814e-02, 2.45562426e-02, 4.73802455e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.93803447e-02, 4.29207630e-02, 8.23136406e-02, ...,\n",
       "          1.78945498e-01, 2.07778925e-01, 1.87478299e-01],\n",
       "         [5.05603292e-04, 1.72645393e-03, 5.15132031e-03, ...,\n",
       "          1.49355414e-01, 1.24667876e-01, 6.84673299e-02],\n",
       "         [3.25036587e-05, 2.83684018e-04, 3.69349042e-03, ...,\n",
       "          4.60651870e-07, 2.54773980e-12, 0.00000000e+00]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 68, 79)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening\n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "df = np.array(df)\n",
    "df = df.reshape(data['x'].shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5363</th>\n",
       "      <th>5364</th>\n",
       "      <th>5365</th>\n",
       "      <th>5366</th>\n",
       "      <th>5367</th>\n",
       "      <th>5368</th>\n",
       "      <th>5369</th>\n",
       "      <th>5370</th>\n",
       "      <th>5371</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.852107e-12</td>\n",
       "      <td>6.843959e-11</td>\n",
       "      <td>1.334486e-09</td>\n",
       "      <td>2.114389e-08</td>\n",
       "      <td>2.722198e-07</td>\n",
       "      <td>2.847860e-06</td>\n",
       "      <td>2.420928e-05</td>\n",
       "      <td>1.672280e-04</td>\n",
       "      <td>9.386428e-04</td>\n",
       "      <td>4.281104e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.083400e-13</td>\n",
       "      <td>1.199041e-14</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.422859e-02</td>\n",
       "      <td>1.792809e-01</td>\n",
       "      <td>2.261597e-01</td>\n",
       "      <td>1.471350e-01</td>\n",
       "      <td>4.932961e-02</td>\n",
       "      <td>8.522938e-03</td>\n",
       "      <td>7.588586e-04</td>\n",
       "      <td>3.481949e-05</td>\n",
       "      <td>8.233298e-07</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.873727e-04</td>\n",
       "      <td>3.700203e-02</td>\n",
       "      <td>1.338341e-01</td>\n",
       "      <td>8.866054e-03</td>\n",
       "      <td>1.075761e-05</td>\n",
       "      <td>2.390714e-10</td>\n",
       "      <td>1.143530e-13</td>\n",
       "      <td>4.469758e-12</td>\n",
       "      <td>1.420740e-10</td>\n",
       "      <td>4.289156e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.679133e-03</td>\n",
       "      <td>2.858350e-02</td>\n",
       "      <td>1.446466e-01</td>\n",
       "      <td>3.296430e-01</td>\n",
       "      <td>3.146601e-01</td>\n",
       "      <td>1.356668e-01</td>\n",
       "      <td>1.148714e-01</td>\n",
       "      <td>3.878903e-01</td>\n",
       "      <td>4.688989e-01</td>\n",
       "      <td>1.760009e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.721801e-02</td>\n",
       "      <td>2.446504e-02</td>\n",
       "      <td>6.717445e-02</td>\n",
       "      <td>1.737527e-01</td>\n",
       "      <td>2.703009e-01</td>\n",
       "      <td>2.480023e-01</td>\n",
       "      <td>1.340995e-01</td>\n",
       "      <td>4.273146e-02</td>\n",
       "      <td>8.024469e-03</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.426186e-01</td>\n",
       "      <td>1.919957e-01</td>\n",
       "      <td>2.337057e-01</td>\n",
       "      <td>2.572226e-01</td>\n",
       "      <td>2.559831e-01</td>\n",
       "      <td>2.303433e-01</td>\n",
       "      <td>1.874140e-01</td>\n",
       "      <td>1.378767e-01</td>\n",
       "      <td>9.171530e-02</td>\n",
       "      <td>5.516572e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.047329e-02</td>\n",
       "      <td>4.878144e-02</td>\n",
       "      <td>5.355981e-02</td>\n",
       "      <td>1.013861e-01</td>\n",
       "      <td>5.092052e-02</td>\n",
       "      <td>3.967086e-02</td>\n",
       "      <td>3.699821e-02</td>\n",
       "      <td>3.428801e-02</td>\n",
       "      <td>3.155638e-02</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1.641564e-04</td>\n",
       "      <td>5.061825e-03</td>\n",
       "      <td>4.748293e-02</td>\n",
       "      <td>1.355030e-01</td>\n",
       "      <td>1.176366e-01</td>\n",
       "      <td>3.107015e-02</td>\n",
       "      <td>2.513731e-03</td>\n",
       "      <td>1.849108e-04</td>\n",
       "      <td>7.014072e-04</td>\n",
       "      <td>3.183943e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.161835e-08</td>\n",
       "      <td>1.106568e-08</td>\n",
       "      <td>3.738061e-09</td>\n",
       "      <td>1.218730e-09</td>\n",
       "      <td>3.834910e-10</td>\n",
       "      <td>1.164628e-10</td>\n",
       "      <td>3.413536e-11</td>\n",
       "      <td>9.656276e-12</td>\n",
       "      <td>2.636114e-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.273725e-07</td>\n",
       "      <td>2.854585e-06</td>\n",
       "      <td>4.301847e-05</td>\n",
       "      <td>4.342317e-04</td>\n",
       "      <td>2.934193e-03</td>\n",
       "      <td>1.327155e-02</td>\n",
       "      <td>4.019215e-02</td>\n",
       "      <td>8.169716e-02</td>\n",
       "      <td>1.133810e-01</td>\n",
       "      <td>1.182013e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.180279e-12</td>\n",
       "      <td>1.819545e-12</td>\n",
       "      <td>5.200285e-13</td>\n",
       "      <td>1.443290e-13</td>\n",
       "      <td>3.885781e-14</td>\n",
       "      <td>1.021405e-14</td>\n",
       "      <td>2.553513e-15</td>\n",
       "      <td>6.661338e-16</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.771561e-16</td>\n",
       "      <td>3.630429e-14</td>\n",
       "      <td>1.391887e-12</td>\n",
       "      <td>4.209189e-11</td>\n",
       "      <td>1.004152e-09</td>\n",
       "      <td>1.889601e-08</td>\n",
       "      <td>2.804845e-07</td>\n",
       "      <td>3.284092e-06</td>\n",
       "      <td>3.033118e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.329739e-01</td>\n",
       "      <td>1.350156e-01</td>\n",
       "      <td>1.346921e-01</td>\n",
       "      <td>1.320204e-01</td>\n",
       "      <td>1.271395e-01</td>\n",
       "      <td>1.202986e-01</td>\n",
       "      <td>1.118360e-01</td>\n",
       "      <td>1.021511e-01</td>\n",
       "      <td>9.167378e-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>1.363800e-08</td>\n",
       "      <td>1.521235e-07</td>\n",
       "      <td>1.428039e-06</td>\n",
       "      <td>1.127810e-05</td>\n",
       "      <td>7.492867e-05</td>\n",
       "      <td>4.187613e-04</td>\n",
       "      <td>1.968741e-03</td>\n",
       "      <td>7.785975e-03</td>\n",
       "      <td>2.590237e-02</td>\n",
       "      <td>7.248831e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.546025e-07</td>\n",
       "      <td>2.166196e-07</td>\n",
       "      <td>8.182735e-08</td>\n",
       "      <td>2.989401e-08</td>\n",
       "      <td>1.056221e-08</td>\n",
       "      <td>3.609193e-09</td>\n",
       "      <td>1.192753e-09</td>\n",
       "      <td>3.812199e-10</td>\n",
       "      <td>1.178382e-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>1.053879e-12</td>\n",
       "      <td>1.644124e-10</td>\n",
       "      <td>1.470619e-08</td>\n",
       "      <td>7.542047e-07</td>\n",
       "      <td>2.217696e-05</td>\n",
       "      <td>3.738853e-04</td>\n",
       "      <td>3.614084e-03</td>\n",
       "      <td>2.003004e-02</td>\n",
       "      <td>6.364860e-02</td>\n",
       "      <td>1.159630e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.489395e-02</td>\n",
       "      <td>8.484123e-02</td>\n",
       "      <td>8.842089e-03</td>\n",
       "      <td>1.028525e-01</td>\n",
       "      <td>9.254207e-02</td>\n",
       "      <td>1.525615e-03</td>\n",
       "      <td>4.606519e-07</td>\n",
       "      <td>2.547740e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 5373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4  \\\n",
       "0     2.852107e-12  6.843959e-11  1.334486e-09  2.114389e-08  2.722198e-07   \n",
       "1     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2     1.873727e-04  3.700203e-02  1.338341e-01  8.866054e-03  1.075761e-05   \n",
       "3     4.679133e-03  2.858350e-02  1.446466e-01  3.296430e-01  3.146601e-01   \n",
       "4     1.426186e-01  1.919957e-01  2.337057e-01  2.572226e-01  2.559831e-01   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2037  1.641564e-04  5.061825e-03  4.748293e-02  1.355030e-01  1.176366e-01   \n",
       "2038  1.273725e-07  2.854585e-06  4.301847e-05  4.342317e-04  2.934193e-03   \n",
       "2039  0.000000e+00  7.771561e-16  3.630429e-14  1.391887e-12  4.209189e-11   \n",
       "2040  1.363800e-08  1.521235e-07  1.428039e-06  1.127810e-05  7.492867e-05   \n",
       "2041  1.053879e-12  1.644124e-10  1.470619e-08  7.542047e-07  2.217696e-05   \n",
       "\n",
       "                 5             6             7             8             9  \\\n",
       "0     2.847860e-06  2.420928e-05  1.672280e-04  9.386428e-04  4.281104e-03   \n",
       "1     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2     2.390714e-10  1.143530e-13  4.469758e-12  1.420740e-10  4.289156e-09   \n",
       "3     1.356668e-01  1.148714e-01  3.878903e-01  4.688989e-01  1.760009e-01   \n",
       "4     2.303433e-01  1.874140e-01  1.378767e-01  9.171530e-02  5.516572e-02   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2037  3.107015e-02  2.513731e-03  1.849108e-04  7.014072e-04  3.183943e-03   \n",
       "2038  1.327155e-02  4.019215e-02  8.169716e-02  1.133810e-01  1.182013e-01   \n",
       "2039  1.004152e-09  1.889601e-08  2.804845e-07  3.284092e-06  3.033118e-05   \n",
       "2040  4.187613e-04  1.968741e-03  7.785975e-03  2.590237e-02  7.248831e-02   \n",
       "2041  3.738853e-04  3.614084e-03  2.003004e-02  6.364860e-02  1.159630e-01   \n",
       "\n",
       "      ...          5363          5364          5365          5366  \\\n",
       "0     ...  4.083400e-13  1.199041e-14  2.220446e-16  0.000000e+00   \n",
       "1     ...  8.422859e-02  1.792809e-01  2.261597e-01  1.471350e-01   \n",
       "2     ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3     ...  4.721801e-02  2.446504e-02  6.717445e-02  1.737527e-01   \n",
       "4     ...  5.047329e-02  4.878144e-02  5.355981e-02  1.013861e-01   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "2037  ...  3.161835e-08  1.106568e-08  3.738061e-09  1.218730e-09   \n",
       "2038  ...  6.180279e-12  1.819545e-12  5.200285e-13  1.443290e-13   \n",
       "2039  ...  1.329739e-01  1.350156e-01  1.346921e-01  1.320204e-01   \n",
       "2040  ...  5.546025e-07  2.166196e-07  8.182735e-08  2.989401e-08   \n",
       "2041  ...  7.489395e-02  8.484123e-02  8.842089e-03  1.028525e-01   \n",
       "\n",
       "              5367          5368          5369          5370          5371  \\\n",
       "0     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1     4.932961e-02  8.522938e-03  7.588586e-04  3.481949e-05  8.233298e-07   \n",
       "2     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3     2.703009e-01  2.480023e-01  1.340995e-01  4.273146e-02  8.024469e-03   \n",
       "4     5.092052e-02  3.967086e-02  3.699821e-02  3.428801e-02  3.155638e-02   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2037  3.834910e-10  1.164628e-10  3.413536e-11  9.656276e-12  2.636114e-12   \n",
       "2038  3.885781e-14  1.021405e-14  2.553513e-15  6.661338e-16  1.110223e-16   \n",
       "2039  1.271395e-01  1.202986e-01  1.118360e-01  1.021511e-01  9.167378e-02   \n",
       "2040  1.056221e-08  3.609193e-09  1.192753e-09  3.812199e-10  1.178382e-10   \n",
       "2041  9.254207e-02  1.525615e-03  4.606519e-07  2.547740e-12  0.000000e+00   \n",
       "\n",
       "               IDs  \n",
       "0     NDARAA075AMK  \n",
       "1     NDARAA112DMH  \n",
       "2     NDARAA117NEJ  \n",
       "3     NDARAA947ZG5  \n",
       "4     NDARAA948VFH  \n",
       "...            ...  \n",
       "2037           NaN  \n",
       "2038           NaN  \n",
       "2039           NaN  \n",
       "2040           NaN  \n",
       "2041           NaN  \n",
       "\n",
       "[2042 rows x 5373 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YjKzrOY5dKO"
   },
   "source": [
    "## Behavioral Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bFK75cJgWc2G",
    "outputId": "c35c8bfc-2242-43be-aada-379d1ccb4c7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
       "       'SWAN_Avg', 'SCARED_SR_GD', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
       "       'WISC_VCI_Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_data = pd.read_csv(DATA_DIR+'AllData.csv')\n",
    "behaviour_data = behaviour_data.rename(columns = {'EID': 'IDs'}, inplace = False)\n",
    "behaviour_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2579, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_data = behaviour_data[['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "       'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "       'WISC_VCI_Sum']]\n",
    "behaviour_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 9 columns (with column 'IDs').\n",
      "There are 8 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WISC_WMI_Sum</th>\n",
       "      <td>712</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WISC_VCI_Sum</th>\n",
       "      <td>702</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCARED_P_GD</th>\n",
       "      <td>576</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRS_SCI_T</th>\n",
       "      <td>448</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRS_RRB_T</th>\n",
       "      <td>447</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWAN_IN_Avg</th>\n",
       "      <td>385</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWAN_HY_Avg</th>\n",
       "      <td>385</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWAN_Avg</th>\n",
       "      <td>385</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  % of Total Values\n",
       "WISC_WMI_Sum             712               27.6\n",
       "WISC_VCI_Sum             702               27.2\n",
       "SCARED_P_GD              576               22.3\n",
       "SRS_SCI_T                448               17.4\n",
       "SRS_RRB_T                447               17.3\n",
       "SWAN_IN_Avg              385               14.9\n",
       "SWAN_HY_Avg              385               14.9\n",
       "SWAN_Avg                 385               14.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns (with column 'IDs').\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_values_table(behaviour_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge EEG and foof data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 5509)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df, foof, on='IDs', how='inner')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and then with the behaviorals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1014, 5517)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(data, behaviour_data, on='IDs', how='inner')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features and labels preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 5517)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing NaNs\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 5508)\n"
     ]
    }
   ],
   "source": [
    "labels_list = [ 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "       'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "       'WISC_VCI_Sum']\n",
    "\n",
    "X = df[df.columns.difference(['IDs']+labels_list)]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 8)\n"
     ]
    }
   ],
   "source": [
    "Y = df[labels_list]\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 5508) (189, 5508)\n",
      "Applying PCA...\n",
      "(564, 189) (189, 189)\n"
     ]
    }
   ],
   "source": [
    "# scaling x\n",
    "norm = preprocessing.MinMaxScaler().fit(xtrain)\n",
    "\n",
    "# transform training data\n",
    "xtrain = norm.transform(xtrain)\n",
    "xtest = norm.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "\n",
    "print('Applying PCA...')\n",
    "pca = PCA(.90) # 95% variance retained\n",
    "pca.fit(xtrain)\n",
    "\n",
    "# transform data\n",
    "xtrain = pca.transform(xtrain)\n",
    "xtest = pca.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 8) (189, 8)\n"
     ]
    }
   ],
   "source": [
    "# scaling y\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(ytrain)\n",
    "ytrain = min_max_scaler.transform(ytrain)\n",
    "ytest = min_max_scaler.transform(ytest)\n",
    "\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39498863, 0.33217542, 0.61734958, 0.53881007, 0.57807982,\n",
       "       0.25325059, 0.4439273 , 0.52642952])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy regressors (to obtain the random baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (dummy): 0.04\n",
      "Median absolute error (dummy): 0.12\n",
      "r2_score (dummy mean): -0.01\n",
      "r2_score (dummy median): -0.03\n",
      "[[0.64150943 0.65306122 0.70370367 0.611111   0.65740733 0.16666667\n",
      "  0.28125    0.28125   ]\n",
      " [0.47169811 0.79591837 0.68518517 0.74074067 0.71296283 0.88888889\n",
      "  0.4375     0.75      ]\n",
      " [0.16981132 0.10204082 0.66666667 0.68518517 0.67592583 0.11111111\n",
      "  0.71875    0.75      ]\n",
      " [0.16981132 0.02040816 0.5925925  0.574074   0.58333333 0.05555556\n",
      "  0.46875    0.625     ]\n",
      " [0.1509434  0.06122449 0.3703705  0.5        0.43518533 0.05555556\n",
      "  0.71875    0.625     ]\n",
      " [0.16981132 0.2244898  0.648148   0.6296295  0.63888883 0.\n",
      "  0.46875    0.5       ]\n",
      " [0.60377358 0.55102041 0.537037   0.5        0.5185185  0.44444444\n",
      "  0.46875    0.59375   ]\n",
      " [0.20754717 0.10204082 0.12962967 0.27777783 0.20370383 0.77777778\n",
      "  0.65625    1.        ]\n",
      " [1.         1.         0.94444433 1.         0.97222217 0.33333333\n",
      "  0.59375    0.65625   ]\n",
      " [0.62264151 0.51020408 0.537037   0.574074   0.5555555  0.16666667\n",
      "  0.4375     0.53125   ]]\n",
      "SRS_SCI_T       58.166003\n",
      "SRS_RRB_T       57.378486\n",
      "SWAN_IN_Avg      0.698244\n",
      "SWAN_HY_Avg      0.248340\n",
      "SWAN_Avg         0.473292\n",
      "SCARED_P_GD      4.563081\n",
      "WISC_WMI_Sum    18.446215\n",
      "WISC_VCI_Sum    20.787517\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(xtrain, ytrain)\n",
    "lm_dummy_median = DummyRegressor(strategy = 'median').fit(xtrain, ytrain)\n",
    "ypred_dummy_mean = lm_dummy_mean.predict(xtest)\n",
    "ypred_dummy_median = lm_dummy_median.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
    "\n",
    "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_median)))\n",
    "\n",
    "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(ytest, ypred_dummy_mean)))\n",
    "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(ytest, ypred_dummy_median)))\n",
    "\n",
    "print(ytest[:10])\n",
    "print(Y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (SVC): 0.04\n",
      "R2 score (SVC): -0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Create the SVR regressor\n",
    "svr = SVR(epsilon=0.2)\n",
    "#Create the Multioutput Regressor\n",
    "mor = MultiOutputRegressor(svr)\n",
    "# Train the regressor\n",
    "mor = mor.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = mor.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (SVC): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"R2 score (SVC): {:.2f}\".format(mor.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (LinReg): 0.05\n",
      "R2 score (LinReg): -0.22\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "# Generate predictions for testing data\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "print(\"Mean squared error (LinReg): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"R2 score (LinReg): {:.2f}\".format(model.score(xtest, ytest)))\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (RandomForest): 0.05\n",
      "R2 score (RandomForest): -0.02\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "regr_rf = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    "regr_rf.fit(xtrain, ytrain)\n",
    "# Predict on new data\n",
    "y_rf = regr_rf.predict(xtest)\n",
    "regr_rf.score(xtest, ytest)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean squared error (RandomForest): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"R2 score (RandomForest): {:.2f}\".format(regr_rf.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## multi-output meta estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (regr_multirf): 0.05\n",
      "R2 score (regr_multirf): -0.04\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "regr_multirf = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    ")\n",
    "regr_multirf.fit(xtrain, ytrain)\n",
    "y_multirf = regr_multirf.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (regr_multirf): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"R2 score (regr_multirf): {:.2f}\".format(regr_multirf.score(xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regressor chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating chained multioutput regression with an SVM model\n",
    "#from numpy import mean\n",
    "#from numpy import std\n",
    "#from numpy import absolute\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.datasets import make_regression\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import RepeatedKFold\n",
    "#from sklearn.multioutput import RegressorChain\n",
    "#from sklearn.svm import LinearSVR\n",
    "# define base model\n",
    "#model = LinearSVR()\n",
    "#scoring = [\"r2\", \"neg_mean_squared_error\", \"neg_mean_absolute_error\"] \n",
    "# define the chained multioutput wrapper model\n",
    "#wrapper = RegressorChain(model)\n",
    "# define the evaluation procedure\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "#n_scores = model_selection.cross_validate(wrapper, X, Y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "\n",
    "#for i in n_scores:\n",
    "#    print(i)\n",
    "#    print('results: %.3f (%.3f)' % (mean(n_scores[i]), std(n_scores[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 14:04:57.285227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-07 14:04:57.307772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.308446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-12-07 14:04:57.308692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-07 14:04:57.310066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-07 14:04:57.311380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-07 14:04:57.311587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-07 14:04:57.312749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-07 14:04:57.313292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-07 14:04:57.315744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-07 14:04:57.315898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.316623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.317231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-12-07 14:04:57.317572: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-07 14:04:57.323233: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-12-07 14:04:57.323742: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e28de16960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-07 14:04:57.323755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-07 14:04:57.323905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.324534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-12-07 14:04:57.324569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-07 14:04:57.324583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-07 14:04:57.324595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-07 14:04:57.324605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-07 14:04:57.324615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-07 14:04:57.324625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-07 14:04:57.324635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-07 14:04:57.324693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.325348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.326074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-12-07 14:04:57.326109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-07 14:04:57.391318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-07 14:04:57.391349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-12-07 14:04:57.391355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-12-07 14:04:57.391673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.392327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.392944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-07 14:04:57.393557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14109 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-12-07 14:04:57.395484: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e28a988f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-07 14:04:57.395495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.7619 - mse: 0.7619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 14:04:58.200614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3236 - mse: 0.3236 - val_loss: 0.1583 - val_mse: 0.1583\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 0.1113 - val_mse: 0.1113\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.1005 - val_mse: 0.1005\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0916 - val_mse: 0.0916\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0877 - val_mse: 0.0877\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0875 - val_mse: 0.0875\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0871 - val_mse: 0.0871\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0873 - val_mse: 0.0873\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0874 - val_mse: 0.0874\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0885 - val_mse: 0.0885\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0891 - val_mse: 0.0891\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0909 - val_mse: 0.0909\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0901 - val_mse: 0.0901\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0917 - val_mse: 0.0917\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0925 - val_mse: 0.0925\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0935 - val_mse: 0.0935\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0943 - val_mse: 0.0943\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0940 - val_mse: 0.0940\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0948 - val_mse: 0.0948\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0945 - val_mse: 0.0945\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0947 - val_mse: 0.0947\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0958 - val_mse: 0.0958\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0938 - val_mse: 0.0938\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0940 - val_mse: 0.0940\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0934 - val_mse: 0.0934\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0948 - val_mse: 0.0948\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0933 - val_mse: 0.0933\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0943 - val_mse: 0.0943\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0934 - val_mse: 0.0934\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0943 - val_mse: 0.0943\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0933 - val_mse: 0.0933\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0937 - val_mse: 0.0937\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0905 - val_mse: 0.0905\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0918 - val_mse: 0.0918\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0918 - val_mse: 0.0918\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0929 - val_mse: 0.0929\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0921 - val_mse: 0.0921\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0912 - val_mse: 0.0912\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0907 - val_mse: 0.0907\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0913 - val_mse: 0.0913\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0910 - val_mse: 0.0910\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0905 - val_mse: 0.0905\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0908 - val_mse: 0.0908\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0897 - val_mse: 0.0897\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0894 - val_mse: 0.0894\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0894 - val_mse: 0.0894\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0884 - val_mse: 0.0884\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0883 - val_mse: 0.0883\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0884 - val_mse: 0.0884\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0862 - val_mse: 0.0862\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0881 - val_mse: 0.0881\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0865 - val_mse: 0.0865\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0863 - val_mse: 0.0863\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0872 - val_mse: 0.0872\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0848 - val_mse: 0.0848\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0842 - val_mse: 0.0842\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0830 - val_mse: 0.0830\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0825 - val_mse: 0.0825\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0818 - val_mse: 0.0818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07608393"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dim = xtrain.shape[1]\n",
    "out_dim = ytrain.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=in_dim, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss=\"mse\", metrics = ['mse'], optimizer=\"adam\")\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=100, batch_size=12, validation_split = 0.2, verbose=1)\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "score = tf.keras.metrics.mean_squared_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score= np.array(score)\n",
    "score.mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DataScienceLab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
