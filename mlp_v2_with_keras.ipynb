{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "import pandas\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2042, 105, 79)\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat('x.mat')  \n",
    "print(data['x'].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Electrode 1 - 1/2 Hz'],\n",
       "       ['Electrode 1 - 2/2 Hz'],\n",
       "       ['Electrode 1 - 3/2 Hz'],\n",
       "       ...,\n",
       "       ['Electrode 105 - 77/2 Hz'],\n",
       "       ['Electrode 105 - 78/2 Hz'],\n",
       "       ['Electrode 105 - 79/2 Hz']], dtype='<U23')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(data['x'].shape[1]) for j in range(data['x'].shape[2])])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ACE_Score</th>\n",
       "      <th>APQ_P_Total</th>\n",
       "      <th>APQ_SR_Total</th>\n",
       "      <th>ARI_P_Total_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>DX_10_Past_Doc</th>\n",
       "      <th>DX_10_Presum</th>\n",
       "      <th>DX_10_RC</th>\n",
       "      <th>DX_10_Rem</th>\n",
       "      <th>DX_10_RuleOut</th>\n",
       "      <th>DX_10_Spec</th>\n",
       "      <th>DX_10_Sub</th>\n",
       "      <th>DX_10_Time</th>\n",
       "      <th>NoDX</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>1</td>\n",
       "      <td>6.728040</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Diagnosis Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>2</td>\n",
       "      <td>5.545744</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>3</td>\n",
       "      <td>7.475929</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>7</td>\n",
       "      <td>13.627880</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>8</td>\n",
       "      <td>7.982660</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>NDARZN148PMN</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>3028</td>\n",
       "      <td>11.629363</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anxiety Disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>3030</td>\n",
       "      <td>14.878736</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "      <td>3031</td>\n",
       "      <td>16.379534</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Other Neurodevelopmental Disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>3032</td>\n",
       "      <td>15.029545</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Inattentive Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "      <td>3033</td>\n",
       "      <td>11.489162</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Inattentive Type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1785 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope  Unnamed: 0        Age  Sex  \\\n",
       "0     NDARAA075AMK   0.986272  1.825774           1   6.728040    1   \n",
       "1     NDARAA112DMH   1.486650  1.888544           2   5.545744    0   \n",
       "2     NDARAA117NEJ   1.593155  2.095749           3   7.475929    0   \n",
       "3     NDARAA947ZG5   0.703331  1.724831           7  13.627880    0   \n",
       "4     NDARAA948VFH   0.918020  1.749441           8   7.982660    1   \n",
       "...            ...        ...       ...         ...        ...  ...   \n",
       "1780  NDARZN148PMN   0.168009  0.205704        3028  11.629363    1   \n",
       "1781  NDARZN277NR6   1.351549  1.996940        3030  14.878736    1   \n",
       "1782  NDARZN610GTY   0.339229  1.050644        3031  16.379534    1   \n",
       "1783  NDARZN677EYE   0.781225  1.470061        3032  15.029545    1   \n",
       "1784  NDARZN899JCM   0.464107  1.664433        3033  11.489162    1   \n",
       "\n",
       "      ACE_Score  APQ_P_Total  APQ_SR_Total  ARI_P_Total_Score  ...  \\\n",
       "0           NaN         91.0         123.0                1.0  ...   \n",
       "1           NaN          NaN           NaN                3.0  ...   \n",
       "2           NaN        113.0          95.0                2.0  ...   \n",
       "3           NaN         85.0          88.0                8.0  ...   \n",
       "4           NaN         91.0          91.0                3.0  ...   \n",
       "...         ...          ...           ...                ...  ...   \n",
       "1780        NaN        102.0         145.0                2.0  ...   \n",
       "1781        NaN        104.0         112.0                5.0  ...   \n",
       "1782        NaN        106.0         114.0                3.0  ...   \n",
       "1783        NaN        105.0         121.0                7.0  ...   \n",
       "1784        NaN        111.0          74.0                1.0  ...   \n",
       "\n",
       "      DX_10_Past_Doc  DX_10_Presum  DX_10_RC  DX_10_Rem  DX_10_RuleOut  \\\n",
       "0                NaN           NaN       NaN        NaN            NaN   \n",
       "1                NaN           NaN       NaN        NaN            NaN   \n",
       "2                NaN           NaN       NaN        NaN            NaN   \n",
       "3                NaN           NaN       NaN        NaN            NaN   \n",
       "4                NaN           NaN       NaN        NaN            NaN   \n",
       "...              ...           ...       ...        ...            ...   \n",
       "1780             NaN           NaN       NaN        NaN            NaN   \n",
       "1781             NaN           NaN       NaN        NaN            NaN   \n",
       "1782             NaN           NaN       NaN        NaN            NaN   \n",
       "1783             NaN           NaN       NaN        NaN            NaN   \n",
       "1784             NaN           NaN       NaN        NaN            NaN   \n",
       "\n",
       "      DX_10_Spec  DX_10_Sub  DX_10_Time  NoDX  \\\n",
       "0            NaN        NaN         1.0   1.0   \n",
       "1            NaN        NaN         1.0   2.0   \n",
       "2            NaN        NaN         1.0   2.0   \n",
       "3            NaN        NaN         1.0   2.0   \n",
       "4            NaN        NaN         1.0   2.0   \n",
       "...          ...        ...         ...   ...   \n",
       "1780         NaN        NaN         1.0   2.0   \n",
       "1781         NaN        NaN         1.0   2.0   \n",
       "1782         NaN        NaN         1.0   2.0   \n",
       "1783         NaN        NaN         1.0   2.0   \n",
       "1784         NaN        NaN         1.0   2.0   \n",
       "\n",
       "                                   label  \n",
       "0                     No Diagnosis Given  \n",
       "1                     ADHD-Combined Type  \n",
       "2                     ADHD-Combined Type  \n",
       "3                     ADHD-Combined Type  \n",
       "4                     ADHD-Combined Type  \n",
       "...                                  ...  \n",
       "1780                   Anxiety Disorders  \n",
       "1781                  ADHD-Combined Type  \n",
       "1782  Other Neurodevelopmental Disorders  \n",
       "1783               ADHD-Inattentive Type  \n",
       "1784               ADHD-Inattentive Type  \n",
       "\n",
       "[1785 rows x 180 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"table_withlabels.csv\")\n",
    "foof = pd.read_csv(\"foof2features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Neurodevelopmental Disorders    492\n",
      "ADHD-Inattentive Type                 388\n",
      "ADHD-Combined Type                    376\n",
      "Anxiety Disorders                     241\n",
      "No Diagnosis Given                    203\n",
      "Depressive Disorders                   85\n",
      "Name: label, dtype: int64\n",
      "(1785, 8297)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['C1']\n",
    "df = pd.merge(df, labels[['label', 'IDs']], on='IDs', how='inner')\n",
    "print(df['label'].value_counts())\n",
    "dataset = df.values\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1785, 8295)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:,0:8295].astype(float)\n",
    "y = dataset[:,8296]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#X = np.clip(X, -1, 1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 8295)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(888, 8295)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, stratify=y,test_size=0.3)\n",
    "\n",
    "oversample = SMOTE() #oversample to aaccount for the data imbalance\n",
    "trainX,trainy = oversample.fit_resample(trainX,trainy)\n",
    "testX,testy = oversample.fit_resample(testX,testy)\n",
    "\n",
    "print(trainX.shape)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainX = trainX.reshape((2064,105,79)) \n",
    "testX = testX.reshape((888,105,79)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def evaluate(y_test, y_pred, show_cm=False):\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    y_test = np.argmax(y_test, axis=1) # assuming you have n-by-6 class_prob\n",
    "    y_pred = np.argmax(y_pred, axis=1) # assuming you have n-by-6 class_prob\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "#     print(\"ROC AUC:\", metrics.roc_auc_score(y_test, y_pred, multi_class='ovo',))\n",
    "    print(\"F1 score:\", metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "#     print(\"Brier Score:\", metrics.brier_score_loss(y_test, y_pred)) # only for binary classification\n",
    "    labels = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "    if show_cm:\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.transpose(trainX, (0, 2,1))\n",
    "testX = np.transpose(testX, (0, 2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print('Tensorflow Version: ',tensorflow.__version__)\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 79, 32)            13472     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 39, 64)            8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 39, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 19, 128)           32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 19, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 9, 256)            131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 9, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 4, 512)            524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 2, 1024)           2098176   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 2,818,918\n",
      "Trainable params: 2,816,998\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 32, kernel_size =4, input_shape = (79, 105), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters = 32, kernel_size = 5, input_shape = (79, 32), activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 64, kernel_size = 4, input_shape = (39, 32), activation = 'relu', padding = 'same'))\n",
    "##model.add(Conv1D(filters = 64, kernel_size = 3, input_shape = (39, 64), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "# Pooling\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =128, kernel_size = 4, input_shape = (19, 64), activation = 'relu', padding = 'same'))\n",
    "##model.add(Conv1D(filters =128, kernel_size = 3, input_shape = (19, 128), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =256, kernel_size = 4, input_shape = (9, 128), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =256, kernel_size = 3, input_shape = (9, 256), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =512, kernel_size = 4, input_shape = (4, 256), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =512, kernel_size = 3, input_shape = (4, 512), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters = 1024, kernel_size = 4, input_shape = (2, 512), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters = 1024, kernel_size = 3, input_shape = (2, 1028), activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Full connection\n",
    "#model.add(Dense(units = 512, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(units = 128, activation = 'relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(units = 32, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 6, activation = 'softmax'))\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 2.0965 - accuracy: 0.3474 - val_loss: 1.8675 - val_accuracy: 0.1926\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.0249 - accuracy: 0.6163 - val_loss: 2.2390 - val_accuracy: 0.2117\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.6390 - accuracy: 0.7694 - val_loss: 2.4578 - val_accuracy: 0.2095\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.5415 - accuracy: 0.8081 - val_loss: 2.8024 - val_accuracy: 0.1858\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3620 - accuracy: 0.8682 - val_loss: 3.4600 - val_accuracy: 0.2061\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.4093 - accuracy: 0.8488 - val_loss: 3.4474 - val_accuracy: 0.1914\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.3091 - accuracy: 0.8949 - val_loss: 4.0058 - val_accuracy: 0.2173\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1979 - accuracy: 0.9365 - val_loss: 5.3864 - val_accuracy: 0.1881\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2424 - accuracy: 0.9264 - val_loss: 4.4749 - val_accuracy: 0.1903\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1868 - accuracy: 0.9385 - val_loss: 4.5410 - val_accuracy: 0.1745\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1359 - accuracy: 0.9549 - val_loss: 4.5360 - val_accuracy: 0.2128\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1275 - accuracy: 0.9540 - val_loss: 5.0494 - val_accuracy: 0.1678\n",
      "Epoch 13/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0874 - accuracy: 0.9704 - val_loss: 4.9927 - val_accuracy: 0.1757\n",
      "Epoch 14/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1593 - accuracy: 0.9530 - val_loss: 5.0675 - val_accuracy: 0.1836\n",
      "Epoch 15/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1260 - accuracy: 0.9583 - val_loss: 5.1838 - val_accuracy: 0.1892\n",
      "Epoch 16/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1235 - accuracy: 0.9603 - val_loss: 5.5851 - val_accuracy: 0.1689\n",
      "Epoch 17/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1482 - accuracy: 0.9535 - val_loss: 5.1458 - val_accuracy: 0.1847\n",
      "Epoch 18/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1510 - accuracy: 0.9520 - val_loss: 5.4640 - val_accuracy: 0.1959\n",
      "Epoch 19/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0901 - accuracy: 0.9704 - val_loss: 5.8828 - val_accuracy: 0.1914\n",
      "Epoch 20/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0928 - accuracy: 0.9671 - val_loss: 5.2139 - val_accuracy: 0.2309\n",
      "Epoch 21/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9743 - val_loss: 5.6392 - val_accuracy: 0.2376\n",
      "Epoch 22/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1729 - accuracy: 0.9525 - val_loss: 6.3524 - val_accuracy: 0.1858\n",
      "Epoch 23/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.2666 - accuracy: 0.9176 - val_loss: 5.0810 - val_accuracy: 0.1926\n",
      "Epoch 24/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1554 - accuracy: 0.9516 - val_loss: 4.9939 - val_accuracy: 0.1993\n",
      "Epoch 25/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 5.0463 - val_accuracy: 0.2050\n",
      "Epoch 26/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 5.2509 - val_accuracy: 0.2173\n",
      "Epoch 27/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 5.7522 - val_accuracy: 0.1903\n",
      "Epoch 28/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 5.8204 - val_accuracy: 0.2016\n",
      "Epoch 29/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 5.8752 - val_accuracy: 0.2185\n",
      "Epoch 30/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 6.0396 - val_accuracy: 0.2016\n",
      "Epoch 31/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.2536 - val_accuracy: 0.2027\n",
      "Epoch 32/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 2.9060e-04 - accuracy: 1.0000 - val_loss: 6.2117 - val_accuracy: 0.2095\n",
      "Epoch 33/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 2.4686e-04 - accuracy: 1.0000 - val_loss: 6.2159 - val_accuracy: 0.2027\n",
      "Epoch 34/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.3706e-04 - accuracy: 1.0000 - val_loss: 6.2275 - val_accuracy: 0.2016\n",
      "Epoch 35/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.7351e-04 - accuracy: 1.0000 - val_loss: 6.2425 - val_accuracy: 0.2027\n",
      "Epoch 36/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.3544e-04 - accuracy: 1.0000 - val_loss: 6.2602 - val_accuracy: 0.2038\n",
      "Epoch 37/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: 6.2665 - val_accuracy: 0.2038\n",
      "Epoch 38/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 9.4020e-05 - accuracy: 1.0000 - val_loss: 6.2846 - val_accuracy: 0.2016\n",
      "Epoch 39/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 6.7150e-05 - accuracy: 1.0000 - val_loss: 6.2994 - val_accuracy: 0.2027\n",
      "Epoch 40/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 7.3141e-05 - accuracy: 1.0000 - val_loss: 6.3115 - val_accuracy: 0.2005\n",
      "Epoch 41/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.4731e-04 - accuracy: 1.0000 - val_loss: 6.3860 - val_accuracy: 0.2050\n",
      "Epoch 42/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 1.0175e-04 - accuracy: 1.0000 - val_loss: 6.3391 - val_accuracy: 0.2050\n",
      "Epoch 43/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 7.8162e-05 - accuracy: 1.0000 - val_loss: 6.3363 - val_accuracy: 0.2095\n",
      "Epoch 44/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 9.6399e-05 - accuracy: 1.0000 - val_loss: 6.3925 - val_accuracy: 0.2050\n",
      "Epoch 45/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 4.5328e-05 - accuracy: 1.0000 - val_loss: 6.4002 - val_accuracy: 0.2027\n",
      "Epoch 46/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 5.2103e-05 - accuracy: 1.0000 - val_loss: 6.3917 - val_accuracy: 0.2038\n",
      "Epoch 47/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 3.6180e-05 - accuracy: 1.0000 - val_loss: 6.4087 - val_accuracy: 0.2061\n",
      "Epoch 48/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 3.7004e-05 - accuracy: 1.0000 - val_loss: 6.4140 - val_accuracy: 0.2083\n",
      "Epoch 49/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 6.0462e-05 - accuracy: 1.0000 - val_loss: 6.4452 - val_accuracy: 0.2050\n",
      "Epoch 50/50\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 3.1342e-05 - accuracy: 1.0000 - val_loss: 6.4687 - val_accuracy: 0.2038\n",
      "[[0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "[[6.5862948e-01 3.2415786e-01 1.1808828e-02 4.3528862e-06 4.6950797e-04\n",
      "  4.9299859e-03]\n",
      " [6.4961040e-01 8.3927921e-04 3.9544394e-03 7.6434037e-07 5.4617389e-04\n",
      "  3.4504890e-01]\n",
      " [2.1768001e-01 7.4645901e-01 2.2571383e-05 2.8826376e-05 7.4669464e-05\n",
      "  3.5734851e-02]\n",
      " ...\n",
      " [5.0052805e-03 7.5895055e-03 3.1755763e-04 1.3011446e-05 2.7390081e-02\n",
      "  9.5968449e-01]\n",
      " [2.1757772e-02 8.3865758e-05 2.1816432e-01 2.5310433e-03 6.9805950e-01\n",
      "  5.9403460e-02]\n",
      " [1.9247664e-02 4.6102173e-04 1.3611946e-01 4.2496173e-04 1.9010856e-04\n",
      "  8.4355670e-01]]\n",
      "[5 0 1 0 0 1 1 1 5 0 4 5 0 1 3 5 2 3 1 5 5 1 4 5 1 5 0 1 2 0 0 3 5 4 4 5 5\n",
      " 5 0 1 0 5 5 4 5 5 0 0 2 2 0 0 1 1 0 0 2 5 1 5 1 0 1 1 1 5 0 3 1 0 0 4 1 0\n",
      " 0 4 3 5 2 2 5 0 1 1 1 2 0 5 4 0 5 0 2 5 2 0 4 2 0 0 0 1 1 0 1 2 1 5 5 1 5\n",
      " 1 3 1 4 5 4 0 5 5 0 2 5 3 5 3 5 4 5 0 5 2 4 5 3 2 1 5 0 0 5 5 2 5 4 1 5 0\n",
      " 4 0 5 1 2 4 5 5 0 0 5 0 1 4 5 2 1 1 5 3 1 5 3 5 0 1 2 1 5 5 5 5 5 0 0 0 2\n",
      " 1 5 1 0 0 5 2 5 0 0 4 1 4 5 1 1 4 0 5 1 5 0 5 1 5 5 0 2 2 5 1 4 5 5 0 5 1\n",
      " 1 0 0 5 4 5 0 1 0 0 5 5 5 5 5 2 3 4 1 4 0 2 2 4 2 0 2 1 2 2 2 4 5 1 0 4 5\n",
      " 1 1 1 1 0 1 4 1 1 1 5 2 0 2 4 2 2 1 1 0 0 5 5 5 5 1 5 2 2 2 1 1 0 0 1 4 1\n",
      " 5 1 1 5 5 1 5 3 5 5 2 4 5 4 2 4 1 5 4 1 1 2 5 5 4 0 5 4 0 0 4 1 5 5 1 1 5\n",
      " 1 4 5 0 5 5 0 5 1 1 5 1 5 4 2 4 5 2 0 5 1 0 4 5 2 1 2 1 5 3 5 5 1 0 3 0 2\n",
      " 1 0 1 2 4 5 1 5 2 3 5 5 2 4 0 0 2 0 2 1 5 0 1 2 4 3 5 2 5 3 4 1 0 1 5 0 1\n",
      " 2 1 2 0 5 5 0 0 1 5 1 5 4 4 1 2 2 2 2 4 5 2 1 5 0 1 5 5 0 4 3 1 5 3 1 3 5\n",
      " 2 2 1 1 5 5 2 3 4 0 1 4 5 5 5 0 4 4 5 3 0 0 4 0 5 5 0 2 5 4 1 5 0 0 2 1 0\n",
      " 1 5 0 2 1 0 1 2 0 5 1 2 0 1 5 5 4 4 5 0 5 2 1 0 0 0 0 0 5 2 1 5 2 5 4 4 0\n",
      " 2 5 0 1 3 1 0 1 0 1 0 4 5 0 5 3 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[0 0 1 5 1 1 0 4 1 1 1 1 5 5 0 2 0 4 0 1 1 0 5 0 1 2 1 5 4 5 5 1 5 5 3 1 2\n",
      " 1 5 1 5 1 1 1 0 0 1 1 5 1 0 5 1 2 5 1 5 5 1 4 5 5 4 5 5 5 2 5 1 5 5 0 0 1\n",
      " 5 1 2 1 0 2 2 1 0 3 2 0 5 1 1 3 5 1 5 2 0 0 4 5 5 5 4 1 1 2 0 2 0 5 2 5 2\n",
      " 5 1 1 3 1 5 0 1 5 0 1 4 5 5 3 0 0 5 2 5 0 5 5 4 1 5 0 0 0 5 5 5 5 5 5 1 5\n",
      " 5 2 0 5 0 1 5 5 5 4 1 5 2 5 0 5 2 5 0 1 5 5 2 1 5 0 1 0 5 0 1 0 0 1 5 1 4\n",
      " 1 5 1 5 0 4 5 2 1 0 2 1 5 1 4 5 0 5 2 0 0 5 5 2 2 4 0 5 0 4 2 2 1 0 1 1 1\n",
      " 0 0 0 5 5 5 5 5 5 0 0 5 5 0 0 1 0 1 5 0 1 5 1 0 5 2 1 0 5 5 1 0 4 0 5 5 1\n",
      " 5 1 1 5 2 1 2 1 5 1 1 2 1 5 5 1 5 0 1 0 5 2 5 5 1 0 5 5 5 0 1 5 2 5 0 1 4\n",
      " 5 1 5 1 1 5 5 0 5 2 5 5 5 5 0 5 4 5 1 1 1 1 0 0 4 1 0 5 1 0 5 1 0 1 5 5 1\n",
      " 2 5 5 1 1 4 1 1 1 2 0 0 1 5 5 2 5 0 0 5 1 2 5 0 0 5 5 1 1 2 0 5 0 1 4 5 0\n",
      " 0 1 5 0 0 5 0 5 2 2 0 2 1 2 0 5 2 1 5 2 5 0 0 1 5 0 4 2 5 2 0 5 1 1 0 0 1\n",
      " 2 4 5 0 0 1 5 1 1 5 0 3 2 2 5 5 0 5 5 4 5 4 0 0 5 2 5 5 1 3 1 5 0 1 1 5 2\n",
      " 5 5 0 5 1 2 4 4 1 2 2 3 0 0 5 5 2 0 1 5 5 0 5 0 3 1 0 5 4 5 5 2 2 5 5 1 2\n",
      " 5 0 0 5 2 5 5 3 1 5 1 5 1 5 0 2 1 5 4 0 0 1 5 1 1 0 0 0 4 5 5 1 1 1 0 5 2\n",
      " 0 4 1 1 5 5 5 1 1 2 0 5 0 5 5 5 5 4 5 1 5 5 1 5 4 0 1 2 2 5 5 2 5 0 1 1 5\n",
      " 5 5 2 0 0 5 5 1 5 1 1 5 1 5 1 0 5 5 4 5 2 2 0 2 1 1 2 1 1 1 0 1 5 5 1 2 1\n",
      " 5 5 1 0 5 1 2 2 1 4 1 5 5 1 5 2 4 2 0 2 0 5 5 2 5 1 1 0 4 5 5 5 0 1 0 4 5\n",
      " 0 0 5 5 2 2 0 5 1 0 1 5 0 2 0 4 1 0 5 1 5 5 1 2 4 0 2 5 1 5 5 5 4 4 5 5 1\n",
      " 5 1 2 0 2 3 0 4 5 1 4 2 5 1 1 0 5 2 1 1 2 5 3 2 5 1 0 1 0 5 0 5 0 3 3 5 0\n",
      " 1 1 1 3 2 1 1 5 0 1 2 5 0 1 3 4 2 2 5 2 5 4 0 1 1 1 5 3 1 0 0 1 1 1 2 0 2\n",
      " 1 4 4 0 4 5 2 1 3 1 0 1 4 5 4 5 4 4 1 4 4 4 5 0 0 1 4 2 1 4 0 4 4 1 5 5 0\n",
      " 4 5 3 1 1 1 5 5 4 4 5 2 1 5 5 5 1 5 4 0 4 2 1 1 5 5 5 5 3 1 4 0 5 5 5 1 2\n",
      " 5 1 4 1 0 5 2 2 2 4 4 4 5 1 1 5 3 1 5 4 5 5 1 3 4 2 5 2 2 4 4 4 1 3 4 5 5\n",
      " 1 4 2 5 5 5 4 5 5 5 1 2 3 4 4 3 5 0 5 1 5 3 4 4 4 2 4 5 5 3 4 5 1 3 5 4 5]\n",
      "Accuracy: 0.20382882882882883\n",
      "Precision: 0.229882125306378\n",
      "Recall: 0.20382882882882883\n",
      "F1 score: 0.19310578101098144\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_317039/2738495669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_cm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_cm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_317039/3926076614.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_test, y_pred, show_cm)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Other Neurodevelopmental Disorders'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADHD-Inattentive Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ADHD-Combined Type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Anxiety Disorders'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'No Diagnosis Given'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Depressive Disorders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_cm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=50, verbose=1)\n",
    "# evaluate the model\n",
    "evaluate(testy, model.predict(testX), show_cm=True)\n",
    "evaluate(trainy, model.predict(trainX), show_cm=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
