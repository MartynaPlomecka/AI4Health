{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartynaPlomecka/AI4Health/blob/main/autoenc_on_spectras_on_fixed_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiBt83nWX1ZY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_theme(style=\"ticks\", color_codes=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCMKijMGX1ZZ",
        "outputId": "4abb05dc-0591-45b5-bb63-8131f822a850"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['Electrode 1 - 1/2 Hz'],\n",
              "       ['Electrode 1 - 2/2 Hz'],\n",
              "       ['Electrode 1 - 3/2 Hz'],\n",
              "       ...,\n",
              "       ['Electrode 105 - 77/2 Hz'],\n",
              "       ['Electrode 105 - 78/2 Hz'],\n",
              "       ['Electrode 105 - 79/2 Hz']], dtype='<U23')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = scipy.io.loadmat('x.mat')\n",
        "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(data['x'].shape[1]) for j in range(data['x'].shape[2])])\n",
        "data['x'].shape\n",
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xWA71-W3X1Za"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv(\"table_withlabels.csv\")\n",
        "foof = pd.read_csv(\"foof2features.csv\")\n",
        "beh = pd.read_csv(\"behaviorals.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBoVPLD5X1Za"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
        "df.columns = columns\n",
        "df['IDs'] = foof['C1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "iMnrjPZQX1Za",
        "outputId": "30e5b1c8-5cf2-4700-e250-b00184f768f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
              "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
              "      <th>...</th>\n",
              "      <th>(Electrode 105 - 72/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 73/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 74/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 75/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 76/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 77/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 78/2 Hz,)</th>\n",
              "      <th>(Electrode 105 - 79/2 Hz,)</th>\n",
              "      <th>IDs</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.707834e-12</td>\n",
              "      <td>1.512286e-10</td>\n",
              "      <td>2.475735e-09</td>\n",
              "      <td>3.453763e-08</td>\n",
              "      <td>4.554996e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.001314</td>\n",
              "      <td>0.009992</td>\n",
              "      <td>0.045200</td>\n",
              "      <td>...</td>\n",
              "      <td>1.223086e-09</td>\n",
              "      <td>4.893694e-10</td>\n",
              "      <td>1.915752e-10</td>\n",
              "      <td>7.337775e-11</td>\n",
              "      <td>2.749867e-11</td>\n",
              "      <td>1.008282e-11</td>\n",
              "      <td>3.617107e-12</td>\n",
              "      <td>1.269651e-12</td>\n",
              "      <td>NDARAA075AMK</td>\n",
              "      <td>No Diagnosis Given</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.798713e-02</td>\n",
              "      <td>1.639433e-01</td>\n",
              "      <td>2.897591e-01</td>\n",
              "      <td>2.097609e-01</td>\n",
              "      <td>6.347556e-02</td>\n",
              "      <td>0.027758</td>\n",
              "      <td>0.105298</td>\n",
              "      <td>0.184513</td>\n",
              "      <td>0.130638</td>\n",
              "      <td>0.163258</td>\n",
              "      <td>...</td>\n",
              "      <td>1.856717e-06</td>\n",
              "      <td>5.922864e-07</td>\n",
              "      <td>1.928109e-07</td>\n",
              "      <td>6.449918e-08</td>\n",
              "      <td>2.204650e-08</td>\n",
              "      <td>7.598678e-09</td>\n",
              "      <td>2.604260e-09</td>\n",
              "      <td>8.780452e-10</td>\n",
              "      <td>NDARAA112DMH</td>\n",
              "      <td>ADHD-Combined Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.104310e-06</td>\n",
              "      <td>4.299647e-05</td>\n",
              "      <td>5.644195e-04</td>\n",
              "      <td>4.760137e-03</td>\n",
              "      <td>2.579253e-02</td>\n",
              "      <td>0.089799</td>\n",
              "      <td>0.201005</td>\n",
              "      <td>0.290260</td>\n",
              "      <td>0.276177</td>\n",
              "      <td>0.196151</td>\n",
              "      <td>...</td>\n",
              "      <td>5.270957e-08</td>\n",
              "      <td>2.026971e-08</td>\n",
              "      <td>7.575282e-09</td>\n",
              "      <td>2.751336e-09</td>\n",
              "      <td>9.711398e-10</td>\n",
              "      <td>3.331297e-10</td>\n",
              "      <td>1.110552e-10</td>\n",
              "      <td>3.597966e-11</td>\n",
              "      <td>NDARAA117NEJ</td>\n",
              "      <td>ADHD-Combined Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.692639e-01</td>\n",
              "      <td>2.021357e-01</td>\n",
              "      <td>2.273063e-01</td>\n",
              "      <td>2.406964e-01</td>\n",
              "      <td>2.400039e-01</td>\n",
              "      <td>0.225430</td>\n",
              "      <td>0.202278</td>\n",
              "      <td>0.198154</td>\n",
              "      <td>0.228356</td>\n",
              "      <td>0.181836</td>\n",
              "      <td>...</td>\n",
              "      <td>7.759521e-02</td>\n",
              "      <td>7.183415e-02</td>\n",
              "      <td>6.604061e-02</td>\n",
              "      <td>6.029416e-02</td>\n",
              "      <td>5.466678e-02</td>\n",
              "      <td>4.922161e-02</td>\n",
              "      <td>4.401211e-02</td>\n",
              "      <td>3.908162e-02</td>\n",
              "      <td>NDARAA947ZG5</td>\n",
              "      <td>ADHD-Combined Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.332328e-06</td>\n",
              "      <td>1.552379e-04</td>\n",
              "      <td>1.804338e-03</td>\n",
              "      <td>1.287033e-02</td>\n",
              "      <td>5.615280e-02</td>\n",
              "      <td>0.149809</td>\n",
              "      <td>0.244887</td>\n",
              "      <td>0.247738</td>\n",
              "      <td>0.163687</td>\n",
              "      <td>0.094061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NDARAA948VFH</td>\n",
              "      <td>ADHD-Combined Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>3.397339e-06</td>\n",
              "      <td>1.701445e-05</td>\n",
              "      <td>7.576350e-05</td>\n",
              "      <td>2.999317e-04</td>\n",
              "      <td>1.055570e-03</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>0.009185</td>\n",
              "      <td>0.022711</td>\n",
              "      <td>0.049919</td>\n",
              "      <td>0.097542</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NDARZN148PMN</td>\n",
              "      <td>Anxiety Disorders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1781</th>\n",
              "      <td>8.241315e-06</td>\n",
              "      <td>2.938160e-04</td>\n",
              "      <td>4.641777e-03</td>\n",
              "      <td>3.249546e-02</td>\n",
              "      <td>1.008094e-01</td>\n",
              "      <td>0.138615</td>\n",
              "      <td>0.084707</td>\n",
              "      <td>0.024339</td>\n",
              "      <td>0.009157</td>\n",
              "      <td>0.021386</td>\n",
              "      <td>...</td>\n",
              "      <td>4.262113e-03</td>\n",
              "      <td>3.068545e-03</td>\n",
              "      <td>2.184048e-03</td>\n",
              "      <td>1.536788e-03</td>\n",
              "      <td>1.069025e-03</td>\n",
              "      <td>7.351630e-04</td>\n",
              "      <td>4.998062e-04</td>\n",
              "      <td>3.359246e-04</td>\n",
              "      <td>NDARZN277NR6</td>\n",
              "      <td>ADHD-Combined Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>5.472767e-03</td>\n",
              "      <td>8.816325e-03</td>\n",
              "      <td>1.629356e-02</td>\n",
              "      <td>3.226822e-02</td>\n",
              "      <td>6.212373e-02</td>\n",
              "      <td>0.108594</td>\n",
              "      <td>0.166461</td>\n",
              "      <td>0.220594</td>\n",
              "      <td>0.252412</td>\n",
              "      <td>0.252807</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NDARZN610GTY</td>\n",
              "      <td>Other Neurodevelopmental Disorders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>2.658455e-03</td>\n",
              "      <td>5.749806e-03</td>\n",
              "      <td>1.180538e-02</td>\n",
              "      <td>2.300961e-02</td>\n",
              "      <td>4.257369e-02</td>\n",
              "      <td>0.074778</td>\n",
              "      <td>0.124685</td>\n",
              "      <td>0.197358</td>\n",
              "      <td>0.296551</td>\n",
              "      <td>0.423009</td>\n",
              "      <td>...</td>\n",
              "      <td>1.925477e-04</td>\n",
              "      <td>9.805386e-05</td>\n",
              "      <td>4.855040e-05</td>\n",
              "      <td>2.337344e-05</td>\n",
              "      <td>1.094093e-05</td>\n",
              "      <td>4.979521e-06</td>\n",
              "      <td>2.203549e-06</td>\n",
              "      <td>9.481114e-07</td>\n",
              "      <td>NDARZN677EYE</td>\n",
              "      <td>ADHD-Inattentive Type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>4.856385e-04</td>\n",
              "      <td>3.048976e-03</td>\n",
              "      <td>1.546836e-02</td>\n",
              "      <td>5.645783e-02</td>\n",
              "      <td>1.419824e-01</td>\n",
              "      <td>0.245335</td>\n",
              "      <td>0.301591</td>\n",
              "      <td>0.291822</td>\n",
              "      <td>0.267454</td>\n",
              "      <td>0.265932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>NDARZN899JCM</td>\n",
              "      <td>ADHD-Inattentive Type</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1785 rows × 8297 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
              "0                7.707834e-12             1.512286e-10   \n",
              "1                3.798713e-02             1.639433e-01   \n",
              "2                2.104310e-06             4.299647e-05   \n",
              "3                1.692639e-01             2.021357e-01   \n",
              "4                8.332328e-06             1.552379e-04   \n",
              "...                       ...                      ...   \n",
              "1780             3.397339e-06             1.701445e-05   \n",
              "1781             8.241315e-06             2.938160e-04   \n",
              "1782             5.472767e-03             8.816325e-03   \n",
              "1783             2.658455e-03             5.749806e-03   \n",
              "1784             4.856385e-04             3.048976e-03   \n",
              "\n",
              "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
              "0                2.475735e-09             3.453763e-08   \n",
              "1                2.897591e-01             2.097609e-01   \n",
              "2                5.644195e-04             4.760137e-03   \n",
              "3                2.273063e-01             2.406964e-01   \n",
              "4                1.804338e-03             1.287033e-02   \n",
              "...                       ...                      ...   \n",
              "1780             7.576350e-05             2.999317e-04   \n",
              "1781             4.641777e-03             3.249546e-02   \n",
              "1782             1.629356e-02             3.226822e-02   \n",
              "1783             1.180538e-02             2.300961e-02   \n",
              "1784             1.546836e-02             5.645783e-02   \n",
              "\n",
              "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
              "0                4.554996e-07                 0.000007   \n",
              "1                6.347556e-02                 0.027758   \n",
              "2                2.579253e-02                 0.089799   \n",
              "3                2.400039e-01                 0.225430   \n",
              "4                5.615280e-02                 0.149809   \n",
              "...                       ...                      ...   \n",
              "1780             1.055570e-03                 0.003303   \n",
              "1781             1.008094e-01                 0.138615   \n",
              "1782             6.212373e-02                 0.108594   \n",
              "1783             4.257369e-02                 0.074778   \n",
              "1784             1.419824e-01                 0.245335   \n",
              "\n",
              "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
              "0                    0.000109                 0.001314   \n",
              "1                    0.105298                 0.184513   \n",
              "2                    0.201005                 0.290260   \n",
              "3                    0.202278                 0.198154   \n",
              "4                    0.244887                 0.247738   \n",
              "...                       ...                      ...   \n",
              "1780                 0.009185                 0.022711   \n",
              "1781                 0.084707                 0.024339   \n",
              "1782                 0.166461                 0.220594   \n",
              "1783                 0.124685                 0.197358   \n",
              "1784                 0.301591                 0.291822   \n",
              "\n",
              "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
              "0                    0.009992                  0.045200  ...   \n",
              "1                    0.130638                  0.163258  ...   \n",
              "2                    0.276177                  0.196151  ...   \n",
              "3                    0.228356                  0.181836  ...   \n",
              "4                    0.163687                  0.094061  ...   \n",
              "...                       ...                       ...  ...   \n",
              "1780                 0.049919                  0.097542  ...   \n",
              "1781                 0.009157                  0.021386  ...   \n",
              "1782                 0.252412                  0.252807  ...   \n",
              "1783                 0.296551                  0.423009  ...   \n",
              "1784                 0.267454                  0.265932  ...   \n",
              "\n",
              "      (Electrode 105 - 72/2 Hz,)  (Electrode 105 - 73/2 Hz,)  \\\n",
              "0                   1.223086e-09                4.893694e-10   \n",
              "1                   1.856717e-06                5.922864e-07   \n",
              "2                   5.270957e-08                2.026971e-08   \n",
              "3                   7.759521e-02                7.183415e-02   \n",
              "4                   0.000000e+00                0.000000e+00   \n",
              "...                          ...                         ...   \n",
              "1780                0.000000e+00                0.000000e+00   \n",
              "1781                4.262113e-03                3.068545e-03   \n",
              "1782                0.000000e+00                0.000000e+00   \n",
              "1783                1.925477e-04                9.805386e-05   \n",
              "1784                0.000000e+00                0.000000e+00   \n",
              "\n",
              "      (Electrode 105 - 74/2 Hz,)  (Electrode 105 - 75/2 Hz,)  \\\n",
              "0                   1.915752e-10                7.337775e-11   \n",
              "1                   1.928109e-07                6.449918e-08   \n",
              "2                   7.575282e-09                2.751336e-09   \n",
              "3                   6.604061e-02                6.029416e-02   \n",
              "4                   0.000000e+00                0.000000e+00   \n",
              "...                          ...                         ...   \n",
              "1780                0.000000e+00                0.000000e+00   \n",
              "1781                2.184048e-03                1.536788e-03   \n",
              "1782                0.000000e+00                0.000000e+00   \n",
              "1783                4.855040e-05                2.337344e-05   \n",
              "1784                0.000000e+00                0.000000e+00   \n",
              "\n",
              "      (Electrode 105 - 76/2 Hz,)  (Electrode 105 - 77/2 Hz,)  \\\n",
              "0                   2.749867e-11                1.008282e-11   \n",
              "1                   2.204650e-08                7.598678e-09   \n",
              "2                   9.711398e-10                3.331297e-10   \n",
              "3                   5.466678e-02                4.922161e-02   \n",
              "4                   0.000000e+00                0.000000e+00   \n",
              "...                          ...                         ...   \n",
              "1780                0.000000e+00                0.000000e+00   \n",
              "1781                1.069025e-03                7.351630e-04   \n",
              "1782                0.000000e+00                0.000000e+00   \n",
              "1783                1.094093e-05                4.979521e-06   \n",
              "1784                0.000000e+00                0.000000e+00   \n",
              "\n",
              "      (Electrode 105 - 78/2 Hz,)  (Electrode 105 - 79/2 Hz,)           IDs  \\\n",
              "0                   3.617107e-12                1.269651e-12  NDARAA075AMK   \n",
              "1                   2.604260e-09                8.780452e-10  NDARAA112DMH   \n",
              "2                   1.110552e-10                3.597966e-11  NDARAA117NEJ   \n",
              "3                   4.401211e-02                3.908162e-02  NDARAA947ZG5   \n",
              "4                   0.000000e+00                0.000000e+00  NDARAA948VFH   \n",
              "...                          ...                         ...           ...   \n",
              "1780                0.000000e+00                0.000000e+00  NDARZN148PMN   \n",
              "1781                4.998062e-04                3.359246e-04  NDARZN277NR6   \n",
              "1782                0.000000e+00                0.000000e+00  NDARZN610GTY   \n",
              "1783                2.203549e-06                9.481114e-07  NDARZN677EYE   \n",
              "1784                0.000000e+00                0.000000e+00  NDARZN899JCM   \n",
              "\n",
              "                                   label  \n",
              "0                     No Diagnosis Given  \n",
              "1                     ADHD-Combined Type  \n",
              "2                     ADHD-Combined Type  \n",
              "3                     ADHD-Combined Type  \n",
              "4                     ADHD-Combined Type  \n",
              "...                                  ...  \n",
              "1780                   Anxiety Disorders  \n",
              "1781                  ADHD-Combined Type  \n",
              "1782  Other Neurodevelopmental Disorders  \n",
              "1783               ADHD-Inattentive Type  \n",
              "1784               ADHD-Inattentive Type  \n",
              "\n",
              "[1785 rows x 8297 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.merge(df, labels[['label', 'IDs']], on='IDs', how='inner')\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9O2ukS9X1Zb",
        "outputId": "b03aeb00-7951-4609-b1ac-8f17508fedac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Other Neurodevelopmental Disorders    492\n",
            "ADHD-Inattentive Type                 388\n",
            "ADHD-Combined Type                    376\n",
            "Anxiety Disorders                     241\n",
            "No Diagnosis Given                    203\n",
            "Depressive Disorders                   85\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df2['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzcbk6N4Fi71",
        "outputId": "38cf4a42-04f4-407f-aca7-f75f87806f08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1785, 8297)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYmZ78tbX1Zc",
        "outputId": "a35eae41-8038-43bb-c599-d4f412095a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1785, 8295)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1785,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df2[df2.columns.difference(['IDs', 'label'])]\n",
        "y = df2['label']\n",
        "print(X.shape)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWQ6ALkzXd91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# number of input columns\n",
        "n_inputs = X.shape[1]\n",
        "# split into train test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# scale data\n",
        "t = MinMaxScaler()\n",
        "t.fit(X_train)\n",
        "X_train = t.transform(X_train)\n",
        "X_test = t.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kBu2xVt8XvMp",
        "outputId": "d2ec5044-7c1e-4544-aeec-15e3bf6cf27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-09 21:03:26.171343: W tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 524.96MiB (rounded to 550456320)\n",
            "Current allocation summary follows.\n",
            "2021-11-09 21:03:26.171386: I tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc\n",
            "2021-11-09 21:03:26.171396: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (256): \tTotal Chunks: 37, Chunks in use: 37. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 168B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171401: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171406: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171411: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171416: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4096): \tTotal Chunks: 7, Chunks in use: 7. 45.5KiB allocated for chunks. 45.5KiB in use in bin. 45.4KiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171420: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171425: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171429: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (32768): \tTotal Chunks: 54, Chunks in use: 54. 1.71MiB allocated for chunks. 1.71MiB in use in bin. 1.71MiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171435: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (65536): \tTotal Chunks: 46, Chunks in use: 46. 2.92MiB allocated for chunks. 2.92MiB in use in bin. 2.91MiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171439: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171443: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171447: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171451: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171456: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171460: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171464: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171468: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171473: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (33554432): \tTotal Chunks: 13, Chunks in use: 12. 678.23MiB allocated for chunks. 629.95MiB in use in bin. 629.95MiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171479: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 104.51MiB allocated for chunks. 104.51MiB in use in bin. 52.50MiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171486: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171491: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (268435456): \tTotal Chunks: 26, Chunks in use: 24. 13.01GiB allocated for chunks. 12.30GiB in use in bin. 12.30GiB client-requested in use in bin.\n",
            "2021-11-09 21:03:26.171496: I tensorflow/core/common_runtime/bfc_allocator.cc:957] Bin for 524.96MiB was 256.00MiB, Chunk State: \n",
            "2021-11-09 21:03:26.171505: I tensorflow/core/common_runtime/bfc_allocator.cc:963]   Size: 302.82MiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 52.50MiB | Requested Size: 52.50MiB | in_use: 1 | bin_num: -1\n",
            "2021-11-09 21:03:26.171512: I tensorflow/core/common_runtime/bfc_allocator.cc:963]   Size: 419.96MiB | Requested Size: 1B | in_use: 0 | bin_num: 20, prev:   Size: 524.96MiB | Requested Size: 524.96MiB | in_use: 1 | bin_num: -1, next:   Size: 524.96MiB | Requested Size: 524.96MiB | in_use: 1 | bin_num: -1\n",
            "2021-11-09 21:03:26.171516: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 14794531840\n",
            "2021-11-09 21:03:26.171523: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6000000 of size 1280 next 1\n",
            "2021-11-09 21:03:26.171527: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6000500 of size 256 next 5\n",
            "2021-11-09 21:03:26.171530: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6000600 of size 66560 next 8\n",
            "2021-11-09 21:03:26.171533: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6010a00 of size 256 next 9\n",
            "2021-11-09 21:03:26.171537: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6010b00 of size 66560 next 10\n",
            "2021-11-09 21:03:26.171540: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6020f00 of size 66560 next 11\n",
            "2021-11-09 21:03:26.171543: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6031300 of size 66560 next 12\n",
            "2021-11-09 21:03:26.171546: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6041700 of size 66560 next 13\n",
            "2021-11-09 21:03:26.171549: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6051b00 of size 33280 next 16\n",
            "2021-11-09 21:03:26.171553: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6059d00 of size 33280 next 17\n",
            "2021-11-09 21:03:26.171556: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6061f00 of size 33280 next 18\n",
            "2021-11-09 21:03:26.171559: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e606a100 of size 33280 next 19\n",
            "2021-11-09 21:03:26.171562: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6072300 of size 33280 next 20\n",
            "2021-11-09 21:03:26.171566: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e607a500 of size 6656 next 24\n",
            "2021-11-09 21:03:26.171569: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e607bf00 of size 33280 next 29\n",
            "2021-11-09 21:03:26.171572: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6084100 of size 33280 next 30\n",
            "2021-11-09 21:03:26.171575: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e608c300 of size 33280 next 31\n",
            "2021-11-09 21:03:26.171578: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6094500 of size 33280 next 32\n",
            "2021-11-09 21:03:26.171581: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e609c700 of size 33280 next 33\n",
            "2021-11-09 21:03:26.171584: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60a4900 of size 66560 next 35\n",
            "2021-11-09 21:03:26.171587: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60b4d00 of size 66560 next 36\n",
            "2021-11-09 21:03:26.171591: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60c5100 of size 66560 next 37\n",
            "2021-11-09 21:03:26.171594: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60d5500 of size 66560 next 38\n",
            "2021-11-09 21:03:26.171598: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60e5900 of size 66560 next 39\n",
            "2021-11-09 21:03:26.171601: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60f5d00 of size 33280 next 41\n",
            "2021-11-09 21:03:26.171604: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fdf00 of size 256 next 42\n",
            "2021-11-09 21:03:26.171607: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe000 of size 256 next 43\n",
            "2021-11-09 21:03:26.171610: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe100 of size 256 next 44\n",
            "2021-11-09 21:03:26.171613: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe200 of size 256 next 45\n",
            "2021-11-09 21:03:26.171616: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe300 of size 256 next 46\n",
            "2021-11-09 21:03:26.171619: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe400 of size 256 next 47\n",
            "2021-11-09 21:03:26.171622: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe500 of size 256 next 48\n",
            "2021-11-09 21:03:26.171625: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe600 of size 256 next 49\n",
            "2021-11-09 21:03:26.171629: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e60fe700 of size 66560 next 50\n",
            "2021-11-09 21:03:26.171632: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e610eb00 of size 66560 next 51\n",
            "2021-11-09 21:03:26.171635: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e611ef00 of size 66560 next 52\n",
            "2021-11-09 21:03:26.171638: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e612f300 of size 33280 next 53\n",
            "2021-11-09 21:03:26.171641: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6137500 of size 33280 next 54\n",
            "2021-11-09 21:03:26.171644: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e613f700 of size 33280 next 55\n",
            "2021-11-09 21:03:26.171647: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6147900 of size 6656 next 56\n",
            "2021-11-09 21:03:26.171650: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6149300 of size 33280 next 57\n",
            "2021-11-09 21:03:26.171654: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6151500 of size 33280 next 58\n",
            "2021-11-09 21:03:26.171657: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6159700 of size 33280 next 59\n",
            "2021-11-09 21:03:26.171660: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6161900 of size 66560 next 61\n",
            "2021-11-09 21:03:26.171663: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6171d00 of size 66560 next 62\n",
            "2021-11-09 21:03:26.171666: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6182100 of size 66560 next 63\n",
            "2021-11-09 21:03:26.171669: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6192500 of size 33280 next 65\n",
            "2021-11-09 21:03:26.171672: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e619a700 of size 66560 next 67\n",
            "2021-11-09 21:03:26.171675: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61aab00 of size 66560 next 68\n",
            "2021-11-09 21:03:26.171683: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61baf00 of size 66560 next 69\n",
            "2021-11-09 21:03:26.171687: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61cb300 of size 33280 next 71\n",
            "2021-11-09 21:03:26.171690: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61d3500 of size 33280 next 72\n",
            "2021-11-09 21:03:26.171693: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61db700 of size 33280 next 73\n",
            "2021-11-09 21:03:26.171706: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61e3900 of size 6656 next 75\n",
            "2021-11-09 21:03:26.171709: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61e5300 of size 33280 next 77\n",
            "2021-11-09 21:03:26.171712: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61ed500 of size 33280 next 78\n",
            "2021-11-09 21:03:26.171715: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61f5700 of size 33280 next 79\n",
            "2021-11-09 21:03:26.171718: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e61fd900 of size 66560 next 81\n",
            "2021-11-09 21:03:26.171722: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e620dd00 of size 66560 next 82\n",
            "2021-11-09 21:03:26.171725: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e621e100 of size 66560 next 83\n",
            "2021-11-09 21:03:26.171728: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e622e500 of size 33280 next 85\n",
            "2021-11-09 21:03:26.171731: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236700 of size 256 next 86\n",
            "2021-11-09 21:03:26.171734: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236800 of size 256 next 87\n",
            "2021-11-09 21:03:26.171737: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236900 of size 256 next 88\n",
            "2021-11-09 21:03:26.171740: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236a00 of size 256 next 89\n",
            "2021-11-09 21:03:26.171743: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236b00 of size 256 next 90\n",
            "2021-11-09 21:03:26.171746: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236c00 of size 256 next 91\n",
            "2021-11-09 21:03:26.171749: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236d00 of size 256 next 92\n",
            "2021-11-09 21:03:26.171753: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236e00 of size 256 next 93\n",
            "2021-11-09 21:03:26.171756: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6236f00 of size 256 next 94\n",
            "2021-11-09 21:03:26.171759: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237000 of size 256 next 95\n",
            "2021-11-09 21:03:26.171762: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237100 of size 256 next 96\n",
            "2021-11-09 21:03:26.171765: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237200 of size 256 next 97\n",
            "2021-11-09 21:03:26.171768: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237300 of size 256 next 98\n",
            "2021-11-09 21:03:26.171771: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237400 of size 256 next 99\n",
            "2021-11-09 21:03:26.171774: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237500 of size 256 next 100\n",
            "2021-11-09 21:03:26.171777: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237600 of size 256 next 101\n",
            "2021-11-09 21:03:26.171781: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237700 of size 256 next 102\n",
            "2021-11-09 21:03:26.171784: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237800 of size 256 next 103\n",
            "2021-11-09 21:03:26.171787: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237900 of size 256 next 152\n",
            "2021-11-09 21:03:26.171790: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237a00 of size 256 next 115\n",
            "2021-11-09 21:03:26.171793: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6237b00 of size 66560 next 127\n",
            "2021-11-09 21:03:26.171796: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6247f00 of size 66560 next 150\n",
            "2021-11-09 21:03:26.171799: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6258300 of size 66560 next 125\n",
            "2021-11-09 21:03:26.171802: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6268700 of size 66560 next 143\n",
            "2021-11-09 21:03:26.171806: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6278b00 of size 33280 next 120\n",
            "2021-11-09 21:03:26.171810: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6280d00 of size 33280 next 149\n",
            "2021-11-09 21:03:26.171813: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6288f00 of size 33280 next 134\n",
            "2021-11-09 21:03:26.171816: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6291100 of size 33280 next 138\n",
            "2021-11-09 21:03:26.171819: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6299300 of size 33280 next 110\n",
            "2021-11-09 21:03:26.171822: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62a1500 of size 6656 next 142\n",
            "2021-11-09 21:03:26.171825: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62a2f00 of size 66560 next 157\n",
            "2021-11-09 21:03:26.171828: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62b3300 of size 66560 next 141\n",
            "2021-11-09 21:03:26.171831: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62c3700 of size 66560 next 112\n",
            "2021-11-09 21:03:26.171834: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62d3b00 of size 66560 next 122\n",
            "2021-11-09 21:03:26.171837: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62e3f00 of size 66560 next 163\n",
            "2021-11-09 21:03:26.171841: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e62f4300 of size 66560 next 161\n",
            "2021-11-09 21:03:26.171844: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6304700 of size 33280 next 159\n",
            "2021-11-09 21:03:26.171847: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e630c900 of size 33280 next 121\n",
            "2021-11-09 21:03:26.171850: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6314b00 of size 33280 next 162\n",
            "2021-11-09 21:03:26.171853: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e631cd00 of size 33280 next 135\n",
            "2021-11-09 21:03:26.171856: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6324f00 of size 33280 next 139\n",
            "2021-11-09 21:03:26.171859: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e632d100 of size 6656 next 140\n",
            "2021-11-09 21:03:26.171863: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e632eb00 of size 33280 next 133\n",
            "2021-11-09 21:03:26.171866: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6336d00 of size 33280 next 158\n",
            "2021-11-09 21:03:26.171870: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e633ef00 of size 33280 next 129\n",
            "2021-11-09 21:03:26.171874: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6347100 of size 33280 next 154\n",
            "2021-11-09 21:03:26.171877: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e634f300 of size 33280 next 126\n",
            "2021-11-09 21:03:26.171880: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6357500 of size 66560 next 136\n",
            "2021-11-09 21:03:26.171883: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6367900 of size 66560 next 108\n",
            "2021-11-09 21:03:26.171887: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6377d00 of size 66560 next 132\n",
            "2021-11-09 21:03:26.171890: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6388100 of size 66560 next 145\n",
            "2021-11-09 21:03:26.171893: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6398500 of size 66560 next 151\n",
            "2021-11-09 21:03:26.171896: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63a8900 of size 33280 next 137\n",
            "2021-11-09 21:03:26.171899: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63b0b00 of size 256 next 107\n",
            "2021-11-09 21:03:26.171902: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63b0c00 of size 256 next 123\n",
            "2021-11-09 21:03:26.171905: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63b0d00 of size 256 next 113\n",
            "2021-11-09 21:03:26.171909: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63b0e00 of size 66560 next 117\n",
            "2021-11-09 21:03:26.171912: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63c1200 of size 66560 next 144\n",
            "2021-11-09 21:03:26.171915: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63d1600 of size 66560 next 147\n",
            "2021-11-09 21:03:26.171918: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63e1a00 of size 33280 next 109\n",
            "2021-11-09 21:03:26.171921: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63e9c00 of size 33280 next 148\n",
            "2021-11-09 21:03:26.171925: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63f1e00 of size 33280 next 124\n",
            "2021-11-09 21:03:26.171928: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63fa000 of size 6656 next 105\n",
            "2021-11-09 21:03:26.171931: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e63fba00 of size 33280 next 104\n",
            "2021-11-09 21:03:26.171934: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6403c00 of size 33280 next 164\n",
            "2021-11-09 21:03:26.171937: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e640be00 of size 33280 next 160\n",
            "2021-11-09 21:03:26.171940: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6414000 of size 66560 next 166\n",
            "2021-11-09 21:03:26.171944: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6424400 of size 66560 next 167\n",
            "2021-11-09 21:03:26.171947: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6434800 of size 66560 next 168\n",
            "2021-11-09 21:03:26.171950: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6444c00 of size 33280 next 170\n",
            "2021-11-09 21:03:26.171953: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e644ce00 of size 66560 next 172\n",
            "2021-11-09 21:03:26.171956: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e645d200 of size 66560 next 173\n",
            "2021-11-09 21:03:26.171959: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e646d600 of size 66560 next 174\n",
            "2021-11-09 21:03:26.171963: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e647da00 of size 33280 next 176\n",
            "2021-11-09 21:03:26.171966: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6485c00 of size 33280 next 177\n",
            "2021-11-09 21:03:26.171969: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e648de00 of size 33280 next 178\n",
            "2021-11-09 21:03:26.171972: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6496000 of size 6656 next 180\n",
            "2021-11-09 21:03:26.171975: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e6497a00 of size 33280 next 182\n",
            "2021-11-09 21:03:26.171979: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e649fc00 of size 33280 next 183\n",
            "2021-11-09 21:03:26.171982: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e64a7e00 of size 33280 next 184\n",
            "2021-11-09 21:03:26.171985: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7fe8e64b0000 of size 50631424 next 21\n",
            "2021-11-09 21:03:26.171989: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e94f9300 of size 256 next 22\n",
            "2021-11-09 21:03:26.171992: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e94f9400 of size 256 next 23\n",
            "2021-11-09 21:03:26.171995: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8e94f9500 of size 55045888 next 25\n",
            "2021-11-09 21:03:26.171999: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8ec978400 of size 55045632 next 26\n",
            "2021-11-09 21:03:26.172002: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8efdf7200 of size 55045632 next 28\n",
            "2021-11-09 21:03:26.172005: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8f3276000 of size 55045632 next 27\n",
            "2021-11-09 21:03:26.172009: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8f66f4e00 of size 55045632 next 74\n",
            "2021-11-09 21:03:26.172013: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8f9b73c00 of size 55045632 next 76\n",
            "2021-11-09 21:03:26.172016: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe8fcff2a00 of size 55045632 next 146\n",
            "2021-11-09 21:03:26.172020: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe900471800 of size 109590784 next 2\n",
            "2021-11-09 21:03:26.172023: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe906cf5100 of size 256 next 3\n",
            "2021-11-09 21:03:26.172026: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe906cf5200 of size 256 next 4\n",
            "2021-11-09 21:03:26.172029: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe906cf5300 of size 550456576 next 6\n",
            "2021-11-09 21:03:26.172033: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9279ea000 of size 550456320 next 7\n",
            "2021-11-09 21:03:26.172036: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9486dec00 of size 550456320 next 15\n",
            "2021-11-09 21:03:26.172039: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9693d3800 of size 550456320 next 14\n",
            "2021-11-09 21:03:26.172042: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe98a0c8400 of size 550456320 next 34\n",
            "2021-11-09 21:03:26.172045: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9aadbd000 of size 550456320 next 40\n",
            "2021-11-09 21:03:26.172049: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9cbab1c00 of size 550456320 next 60\n",
            "2021-11-09 21:03:26.172052: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fe9ec7a6800 of size 550456320 next 64\n",
            "2021-11-09 21:03:26.172055: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea0d49b400 of size 550456320 next 66\n",
            "2021-11-09 21:03:26.172058: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea2e190000 of size 550456320 next 70\n",
            "2021-11-09 21:03:26.172061: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea4ee84c00 of size 550456320 next 80\n",
            "2021-11-09 21:03:26.172064: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea6fb79800 of size 550456320 next 84\n",
            "2021-11-09 21:03:26.172067: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea9086e400 of size 55045632 next 119\n",
            "2021-11-09 21:03:26.172071: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fea93ced200 of size 550456320 next 128\n",
            "2021-11-09 21:03:26.172074: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feab49e1e00 of size 550456320 next 131\n",
            "2021-11-09 21:03:26.172077: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fead56d6a00 of size 55045632 next 106\n",
            "2021-11-09 21:03:26.172080: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fead8b55800 of size 55045632 next 111\n",
            "2021-11-09 21:03:26.172083: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feadbfd4600 of size 550456320 next 155\n",
            "2021-11-09 21:03:26.172087: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7feafccc9200 of size 440365056 next 130\n",
            "2021-11-09 21:03:26.172090: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feb170c0200 of size 550456320 next 114\n",
            "2021-11-09 21:03:26.172093: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feb37db4e00 of size 550456320 next 153\n",
            "2021-11-09 21:03:26.172096: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feb58aa9a00 of size 550456320 next 116\n",
            "2021-11-09 21:03:26.172099: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feb7979e600 of size 550456320 next 118\n",
            "2021-11-09 21:03:26.172102: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7feb9a493200 of size 550456320 next 156\n",
            "2021-11-09 21:03:26.172105: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7febbb187e00 of size 550456320 next 165\n",
            "2021-11-09 21:03:26.172108: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7febdbe7ca00 of size 550456320 next 169\n",
            "2021-11-09 21:03:26.172112: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7febfcb71600 of size 550456320 next 171\n",
            "2021-11-09 21:03:26.172115: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fec1d866200 of size 550456320 next 175\n",
            "2021-11-09 21:03:26.172118: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fec3e55ae00 of size 55045632 next 179\n",
            "2021-11-09 21:03:26.172121: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 7fec419d9c00 of size 55045632 next 181\n",
            "2021-11-09 21:03:26.172125: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 7fec44e58a00 of size 317528576 next 18446744073709551615\n",
            "2021-11-09 21:03:26.172128: I tensorflow/core/common_runtime/bfc_allocator.cc:995]      Summary of in-use Chunks by size: \n",
            "2021-11-09 21:03:26.172133: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 37 Chunks of size 256 totalling 9.2KiB\n",
            "2021-11-09 21:03:26.172137: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1280 totalling 1.2KiB\n",
            "2021-11-09 21:03:26.172140: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 7 Chunks of size 6656 totalling 45.5KiB\n",
            "2021-11-09 21:03:26.172144: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 54 Chunks of size 33280 totalling 1.71MiB\n",
            "2021-11-09 21:03:26.172148: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 46 Chunks of size 66560 totalling 2.92MiB\n",
            "2021-11-09 21:03:26.172152: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 11 Chunks of size 55045632 totalling 577.45MiB\n",
            "2021-11-09 21:03:26.172156: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 55045888 totalling 52.50MiB\n",
            "2021-11-09 21:03:26.172160: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 109590784 totalling 104.51MiB\n",
            "2021-11-09 21:03:26.172163: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 23 Chunks of size 550456320 totalling 11.79GiB\n",
            "2021-11-09 21:03:26.172167: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 550456576 totalling 524.96MiB\n",
            "2021-11-09 21:03:26.172171: I tensorflow/core/common_runtime/bfc_allocator.cc:1002] Sum Total of in-use chunks: 13.03GiB\n",
            "2021-11-09 21:03:26.172175: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] total_region_allocated_bytes_: 14794531840 memory_limit_: 14794531840 available bytes: 0 curr_region_allocation_bytes_: 29589063680\n",
            "2021-11-09 21:03:26.172182: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats: \n",
            "Limit:                 14794531840\n",
            "InUse:                 13986006784\n",
            "MaxInUse:              13986007296\n",
            "NumAllocs:                  514268\n",
            "MaxAllocSize:            550456576\n",
            "\n",
            "2021-11-09 21:03:26.172192: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *************************************************************__***********************************__\n",
            "2021-11-09 21:03:26.172215: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at constant_op.cc:184 : Resource exhausted: OOM when allocating tensor with shape[8295,16590] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "in user code:\n\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:540 train_step  **\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1810 _minimize\n        optimizer.apply_gradients(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:478 apply_gradients\n        self._create_all_weights(var_list)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:663 _create_all_weights\n        self._create_slots(var_list)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:158 _create_slots\n        self.add_slot(var, 'v')\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:719 add_slot\n        weight = tf_variables.Variable(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:261 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:243 _variable_v2_call\n        return previous_getter(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:492 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:263 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:180 __init__\n        initial_value() if init_from_fn else initial_value,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/init_ops_v2.py:129 __call__\n        return array_ops.zeros(shape, dtype)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2677 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2733 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:234 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:3316 fill\n        _ops.raise_from_not_ok_status(e, name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6653 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[8295,16590] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_41777/2301505619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoencoder_compress.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# fit the autoencoder model to reconstruct input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m# plot loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#pyplot.plot(history.history['loss'], label='train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: in user code:\n\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:540 train_step  **\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1810 _minimize\n        optimizer.apply_gradients(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:478 apply_gradients\n        self._create_all_weights(var_list)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:663 _create_all_weights\n        self._create_slots(var_list)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adam.py:158 _create_slots\n        self.add_slot(var, 'v')\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:719 add_slot\n        weight = tf_variables.Variable(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:261 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:243 _variable_v2_call\n        return previous_getter(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2562 creator\n        return next_creator(**kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:66 getter\n        return captured_getter(captured_previous, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:492 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:263 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:180 __init__\n        initial_value() if init_from_fn else initial_value,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/init_ops_v2.py:129 __call__\n        return array_ops.zeros(shape, dtype)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2677 wrapped\n        tensor = fun(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:2733 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:234 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:3316 fill\n        _ops.raise_from_not_ok_status(e, name)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6653 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[8295,16590] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
          ]
        }
      ],
      "source": [
        "# define encoder\n",
        "visible = Input(shape=(n_inputs,))\n",
        "# encoder level 1\n",
        "e = Dense(n_inputs*2)(visible)\n",
        "e = BatchNormalization()(e)\n",
        "e = LeakyReLU()(e)\n",
        "# encoder level 2\n",
        "e = Dense(n_inputs)(e)\n",
        "e = BatchNormalization()(e)\n",
        "e = LeakyReLU()(e)\n",
        "# bottleneck\n",
        "n_bottleneck = round(float(n_inputs) / 5.0)\n",
        "bottleneck = Dense(n_bottleneck)(e)\n",
        "# define decoder, level 1\n",
        "d = Dense(n_inputs)(bottleneck)\n",
        "d = BatchNormalization()(d)\n",
        "d = LeakyReLU()(d)\n",
        "# decoder level 2\n",
        "d = Dense(n_inputs*2)(d)\n",
        "d = BatchNormalization()(d)\n",
        "d = LeakyReLU()(d)\n",
        "# output layer\n",
        "output = Dense(n_inputs, activation='linear')(d)\n",
        "# define autoencoder model\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# compile autoencoder model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# plot the autoencoder\n",
        "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "# fit the autoencoder model to reconstruct input\n",
        "history = model.fit(X_train, X_train, epochs=50, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
        "# plot loss\n",
        "#pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "#pyplot.legend()\n",
        "#pyplot.show()\n",
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\n",
        "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "wJBGZ06ZlbVS",
        "outputId": "6a0ae41d-7559-4760-8b4f-09074cdb129f"
      },
      "outputs": [],
      "source": [
        "# define model 1\n",
        "#model = LogisticRegression(solver='lbfgs', max_iter=10000, random_state=0)\n",
        "# fit model on training set\n",
        "#model.fit(X_train, y_train)\n",
        "# make prediction on test set\n",
        "#yhat = model.predict(X_test)\n",
        "# calculate accuracy\n",
        "#acc = accuracy_score(y_test, yhat)\n",
        "#print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGd2GEwNmDoV",
        "outputId": "cd45ca1f-2074-4087-9ac9-3446c75f108b"
      },
      "outputs": [],
      "source": [
        "#model2 = RandomForestClassifier(n_estimators=1000, class_weight='balanced')\n",
        "#model2.fit(X_train, y_train)\n",
        "#preds = model2.predict(X_test)\n",
        "#acc = accuracy_score(y_test, yhat)\n",
        "#print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.2058165548098434"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
        "                                                    random_state=1)\n",
        "model3 = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
        "model3.predict(X_test)\n",
        "\n",
        "\n",
        "model3.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIsU47QTm1fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 8295) for input Tensor(\"input_1:0\", shape=(None, 8295), dtype=float32), but it was called on an input with incompatible shape (None, 1659).\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 8295 but received input with shape [None, 1659]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_41777/32528470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# calculate classification accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 8295 but received input with shape [None, 1659]\n"
          ]
        }
      ],
      "source": [
        "# evaluate logistic regression on encoded input\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "# define dataset\n",
        "# split into train test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# scale data\n",
        "t = MinMaxScaler()\n",
        "t.fit(X_train)\n",
        "X_train = t.transform(X_train)\n",
        "X_test = t.transform(X_test)\n",
        "# load the model from file\n",
        "encoder= load_model('encoder.h5', compile=False)\n",
        "# encode the train data\n",
        "X_train_encode = encoder.predict(X_train)\n",
        "# encode the test data\n",
        "X_test_encode = encoder.predict(X_test)\n",
        "# define the model\n",
        "model3 = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
        "# fit the model on the training set\n",
        "model3.fit(X_train_encode, y_train)\n",
        "# make predictions on the test set\n",
        "yhat = model.predict(X_test_encode)\n",
        "# calculate classification accuracy\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "autoenc_on_spectras_on_fixed_classes.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('ai4halth': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
