{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imbalanced_ensemble.sampler import over_sampling as os\n",
    "from imbalanced_ensemble import pipeline as pl\n",
    "from imbalanced_ensemble.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Neurodevelopmental Disorders    492\n",
      "ADHD-Inattentive Type                 388\n",
      "ADHD-Combined Type                    376\n",
      "Anxiety Disorders                     241\n",
      "No Diagnosis Given                    203\n",
      "Depressive Disorders                   85\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat('x.mat')\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(data['x'].shape[1]) for j in range(data['x'].shape[2])])\n",
    "data['x'].shape\n",
    "labels = pd.read_csv(\"table_withlabels.csv\")\n",
    "foof = pd.read_csv(\"foof2features.csv\")\n",
    "beh = pd.read_csv(\"behaviorals.csv\")\n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['C1']\n",
    "df2 = pd.merge(df, labels[['label', 'IDs']], on='IDs', how='inner')\n",
    "print(df2['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traversing through disease\n",
    "# column of dataFrame and \n",
    "# writing values where\n",
    "# condition matches.\n",
    "df2.label[df2.label == 'Other Neurodevelopmental Disorders'] = 1\n",
    "df2.label[df2.label == 'ADHD-Inattentive Type'] = 2\n",
    "df2.label[df2.label == 'ADHD-Combined Type'] = 3\n",
    "df2.label[df2.label == 'Anxiety Disorders'] = 4\n",
    "df2.label[df2.label == 'No Diagnosis Given'] = 5\n",
    "df2.label[df2.label == 'Depressive Disorders'] = 6\n",
    "print(df2['label'].unique())\n",
    "print(df2['label'].value_counts())\n",
    "\n",
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1785, 8295)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       3\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "1780    4\n",
       "1781    3\n",
       "1782    1\n",
       "1783    2\n",
       "1784    2\n",
       "Name: label, Length: 1785, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns.difference(['IDs', 'label'])]\n",
    "y = df['label']\n",
    "print(X.shape)\n",
    "y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = pl.make_pipeline(\n",
    "    os.SMOTE(random_state=22), LinearSVC(random_state=22)\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(random_state=22)),\n",
       "                ('linearsvc', LinearSVC(random_state=22))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.30      0.29      0.73      0.29      0.46      0.20       129\n",
      "          2       0.27      0.26      0.80      0.27      0.46      0.20        99\n",
      "          3       0.16      0.19      0.76      0.17      0.38      0.14        84\n",
      "          4       0.22      0.18      0.88      0.20      0.40      0.15        71\n",
      "          5       0.11      0.13      0.88      0.12      0.34      0.10        47\n",
      "          6       0.07      0.06      0.97      0.06      0.24      0.05        17\n",
      "\n",
      "avg / total       0.23      0.22      0.80      0.22      0.41      0.16       447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "\n",
    "# Show the classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
