{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Electrode 105 - 31/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 32/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 33/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 34/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 35/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 36/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 37/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 38/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 39/2 Hz,)</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.333844e-07</td>\n",
       "      <td>9.373567e-08</td>\n",
       "      <td>1.616373e-08</td>\n",
       "      <td>3.256580e-09</td>\n",
       "      <td>4.986456e-10</td>\n",
       "      <td>7.457518e-11</td>\n",
       "      <td>1.130004e-11</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>2.352137e-03</td>\n",
       "      <td>4.122513e-04</td>\n",
       "      <td>4.825197e-05</td>\n",
       "      <td>5.944433e-06</td>\n",
       "      <td>5.749150e-07</td>\n",
       "      <td>6.398086e-08</td>\n",
       "      <td>8.415637e-09</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.045964e-05</td>\n",
       "      <td>4.443460e-06</td>\n",
       "      <td>7.491343e-07</td>\n",
       "      <td>1.436770e-07</td>\n",
       "      <td>2.039047e-08</td>\n",
       "      <td>2.751924e-09</td>\n",
       "      <td>3.663748e-10</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>1.580043e-01</td>\n",
       "      <td>1.518115e-01</td>\n",
       "      <td>1.233778e-01</td>\n",
       "      <td>1.242931e-01</td>\n",
       "      <td>1.009636e-01</td>\n",
       "      <td>8.498748e-02</td>\n",
       "      <td>7.690149e-02</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093399</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>4.012462e-02</td>\n",
       "      <td>2.464919e-02</td>\n",
       "      <td>1.257993e-02</td>\n",
       "      <td>7.816617e-03</td>\n",
       "      <td>3.846395e-03</td>\n",
       "      <td>1.926406e-03</td>\n",
       "      <td>1.018633e-03</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.385606e-02</td>\n",
       "      <td>2.124126e-02</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.222227</td>\n",
       "      <td>0.444972</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>5.877454e-03</td>\n",
       "      <td>3.190797e-03</td>\n",
       "      <td>1.418509e-03</td>\n",
       "      <td>7.564419e-04</td>\n",
       "      <td>3.146594e-04</td>\n",
       "      <td>1.311957e-04</td>\n",
       "      <td>5.687030e-05</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1.089647e-02</td>\n",
       "      <td>3.749309e-02</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>0.413368</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>1.169173e-02</td>\n",
       "      <td>4.410850e-03</td>\n",
       "      <td>1.294309e-03</td>\n",
       "      <td>4.329110e-04</td>\n",
       "      <td>1.073561e-04</td>\n",
       "      <td>2.536768e-05</td>\n",
       "      <td>5.924775e-06</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2.695401e-03</td>\n",
       "      <td>5.553206e-02</td>\n",
       "      <td>0.315364</td>\n",
       "      <td>0.444302</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.232912</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "2037             2.303407e-04             2.867255e-02   \n",
       "2038             1.385606e-02             2.124126e-02   \n",
       "2039             1.089647e-02             3.749309e-02   \n",
       "2040             6.411911e-03             2.687961e-02   \n",
       "2041             2.695401e-03             5.553206e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                    0.000006                 0.001066   \n",
       "1                    0.074284                 0.216988   \n",
       "2                    0.094118                 0.367821   \n",
       "3                    0.378969                 0.299813   \n",
       "4                    0.167700                 0.368840   \n",
       "...                       ...                      ...   \n",
       "2037                 0.194945                 0.081646   \n",
       "2038                 0.032991                 0.043456   \n",
       "2039                 0.139003                 0.289797   \n",
       "2040                 0.095551                 0.241121   \n",
       "2041                 0.315364                 0.444302   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "2037                 0.018422                 0.076959   \n",
       "2038                 0.048827                 0.049759   \n",
       "2039                 0.304728                 0.196113   \n",
       "2040                 0.434011                 0.574767   \n",
       "2041                 0.321718                 0.232912   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "2037                 0.179779                 0.300051   \n",
       "2038                 0.074988                 0.222227   \n",
       "2039                 0.191950                 0.342653   \n",
       "2040                 0.694741                 0.815939   \n",
       "2041                 0.152557                 0.178452   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
       "0                    0.593581                  0.401686  ...   \n",
       "1                    0.049898                  0.004720  ...   \n",
       "2                    0.526883                  0.511715  ...   \n",
       "3                    0.003988                  0.061608  ...   \n",
       "4                    0.233210                  0.125520  ...   \n",
       "...                       ...                       ...  ...   \n",
       "2037                 0.417245                  0.459853  ...   \n",
       "2038                 0.444972                  0.464653  ...   \n",
       "2039                 0.413368                  0.344024  ...   \n",
       "2040                 0.678021                  0.490314  ...   \n",
       "2041                 0.289553                  0.280580  ...   \n",
       "\n",
       "      (Electrode 105 - 31/2 Hz,)  (Electrode 105 - 32/2 Hz,)  \\\n",
       "0                       0.000007                    0.000002   \n",
       "1                       0.031636                    0.009416   \n",
       "2                       0.000311                    0.000079   \n",
       "3                       0.158691                    0.150551   \n",
       "4                       0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "2037                    0.093399                    0.058729   \n",
       "2038                    0.016832                    0.009602   \n",
       "2039                    0.000000                    0.000000   \n",
       "2040                    0.059230                    0.026090   \n",
       "2041                    0.000000                    0.000000   \n",
       "\n",
       "      (Electrode 105 - 33/2 Hz,)  (Electrode 105 - 34/2 Hz,)  \\\n",
       "0                   4.333844e-07                9.373567e-08   \n",
       "1                   2.352137e-03                4.122513e-04   \n",
       "2                   2.045964e-05                4.443460e-06   \n",
       "3                   1.580043e-01                1.518115e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                4.012462e-02                2.464919e-02   \n",
       "2038                5.877454e-03                3.190797e-03   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.169173e-02                4.410850e-03   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 35/2 Hz,)  (Electrode 105 - 36/2 Hz,)  \\\n",
       "0                   1.616373e-08                3.256580e-09   \n",
       "1                   4.825197e-05                5.944433e-06   \n",
       "2                   7.491343e-07                1.436770e-07   \n",
       "3                   1.233778e-01                1.242931e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                1.257993e-02                7.816617e-03   \n",
       "2038                1.418509e-03                7.564419e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.294309e-03                4.329110e-04   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 37/2 Hz,)  (Electrode 105 - 38/2 Hz,)  \\\n",
       "0                   4.986456e-10                7.457518e-11   \n",
       "1                   5.749150e-07                6.398086e-08   \n",
       "2                   2.039047e-08                2.751924e-09   \n",
       "3                   1.009636e-01                8.498748e-02   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                3.846395e-03                1.926406e-03   \n",
       "2038                3.146594e-04                1.311957e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.073561e-04                2.536768e-05   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 39/2 Hz,)           IDs  \n",
       "0                   1.130004e-11  NDARAA075AMK  \n",
       "1                   8.415637e-09  NDARAA112DMH  \n",
       "2                   3.663748e-10  NDARAA117NEJ  \n",
       "3                   7.690149e-02  NDARAA947ZG5  \n",
       "4                   0.000000e+00  NDARAA948VFH  \n",
       "...                          ...           ...  \n",
       "2037                1.018633e-03  NDARZN277NR6  \n",
       "2038                5.687030e-05  NDARZN578YDP  \n",
       "2039                0.000000e+00  NDARZN610GTY  \n",
       "2040                5.924775e-06  NDARZN677EYE  \n",
       "2041                0.000000e+00  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 4096 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df = np.array(df).reshape(data['x'].shape)\n",
    "df_sparsed = np.concatenate([np.expand_dims(df[:,:,i:i+2].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-2, 2)], axis = 2)\n",
    "df = pd.DataFrame(df_sparsed.reshape((df_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df)\n",
    "df = norm.transform(df)\n",
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(df_sparsed.shape[1]) for j in range(df_sparsed.shape[2])])\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2939, 177)\n",
      "Removing 137 patients as their evaluations was incomplete.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders',  'No Diagnosis Given', 'Other Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# removing patients with incomplete eval\n",
    "initial_size = beh.shape[0]\n",
    "beh = beh[beh.DX_01 != 'No Diagnosis Given: Incomplete Eval']\n",
    "beh = beh.reset_index(drop=True)\n",
    "new_size = beh.shape[0]\n",
    "\n",
    "print('After:'+str(beh.shape))\n",
    "print('Removing', initial_size - new_size,\n",
    "      'patients as their evaluations was incomplete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6,\n",
       " 'No Diagnosis Given': 7,\n",
       " 'Other Disorders': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        else:\n",
    "            if diagnoses_to_ids['Other Disorders'] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids['Other Disorders'])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "        \n",
    "    order_of_disorders.append(disorders_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_disorders = []\n",
    "no_diagnosis_given = []\n",
    "for i in order_of_disorders:\n",
    "    if 7 in i:\n",
    "        no_diagnosis_given.append(1)\n",
    "        i.remove(7)\n",
    "    else:\n",
    "        no_diagnosis_given.append(0)\n",
    "    if 8 in i:\n",
    "        other_disorders.append(1)\n",
    "        i.remove(8)\n",
    "    else:\n",
    "        other_disorders.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-48b714085ca7>:25: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  behaviour_data_columns = beh.columns.values.astype(np.str)\n"
     ]
    }
   ],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-26c912096f42>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[\"Other Disorders\"] = other_disorders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "      <th>Other Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2934  NDARZZ007YMP                                         0   \n",
       "2935  NDARZZ740MLM                                         1   \n",
       "2936  NDARZZ810LVF                                         0   \n",
       "2937  NDARZZ830JM7                                         0   \n",
       "2938  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2934                  0                           0                         1   \n",
       "2935                  0                           0                         0   \n",
       "2936                  0                           0                         1   \n",
       "2937                  0                           0                         1   \n",
       "2938                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \\\n",
       "0              0                       0                     0   \n",
       "1              1                       0                     0   \n",
       "2              1                       0                     0   \n",
       "3              0                       1                     0   \n",
       "4              0                       0                     0   \n",
       "...          ...                     ...                   ...   \n",
       "2934           0                       0                     0   \n",
       "2935           0                       0                     0   \n",
       "2936           0                       1                     0   \n",
       "2937           0                       0                     0   \n",
       "2938           0                       0                     0   \n",
       "\n",
       "      Other Disorders  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "...               ...  \n",
       "2934                1  \n",
       "2935                0  \n",
       "2936                1  \n",
       "2937                1  \n",
       "2938                0  \n",
       "\n",
       "[2939 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "labels=behaviour_data[[\"IDs\"]+list(common_disorders)]\n",
    "labels[\"Other Disorders\"] = other_disorders\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "      <th>Other Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>1.556547e-05</td>\n",
       "      <td>2.900630e-04</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.189421</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.445277</td>\n",
       "      <td>0.644915</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>1.089647e-02</td>\n",
       "      <td>3.749309e-02</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>0.413368</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>2.695401e-03</td>\n",
       "      <td>5.553206e-02</td>\n",
       "      <td>0.315364</td>\n",
       "      <td>0.444302</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.232912</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1921 rows × 4106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "1916             1.556547e-05             2.900630e-04   \n",
       "1917             2.303407e-04             2.867255e-02   \n",
       "1918             1.089647e-02             3.749309e-02   \n",
       "1919             6.411911e-03             2.687961e-02   \n",
       "1920             2.695401e-03             5.553206e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                    0.000006                 0.001066   \n",
       "1                    0.074284                 0.216988   \n",
       "2                    0.094118                 0.367821   \n",
       "3                    0.378969                 0.299813   \n",
       "4                    0.167700                 0.368840   \n",
       "...                       ...                      ...   \n",
       "1916                 0.003548                 0.023882   \n",
       "1917                 0.194945                 0.081646   \n",
       "1918                 0.139003                 0.289797   \n",
       "1919                 0.095551                 0.241121   \n",
       "1920                 0.315364                 0.444302   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "1916                 0.088943                 0.189421   \n",
       "1917                 0.018422                 0.076959   \n",
       "1918                 0.304728                 0.196113   \n",
       "1919                 0.434011                 0.574767   \n",
       "1920                 0.321718                 0.232912   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "1916                 0.293481                 0.445277   \n",
       "1917                 0.179779                 0.300051   \n",
       "1918                 0.191950                 0.342653   \n",
       "1919                 0.694741                 0.815939   \n",
       "1920                 0.152557                 0.178452   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  Intercept  \\\n",
       "0                    0.593581                  0.401686  ...   0.986272   \n",
       "1                    0.049898                  0.004720  ...   1.486650   \n",
       "2                    0.526883                  0.511715  ...   1.593155   \n",
       "3                    0.003988                  0.061608  ...   0.703331   \n",
       "4                    0.233210                  0.125520  ...   0.918020   \n",
       "...                       ...                       ...  ...        ...   \n",
       "1916                 0.644915                  0.577096  ...   0.168009   \n",
       "1917                 0.417245                  0.459853  ...   1.351549   \n",
       "1918                 0.413368                  0.344024  ...   0.339229   \n",
       "1919                 0.678021                  0.490314  ...   0.781225   \n",
       "1920                 0.289553                  0.280580  ...   0.464107   \n",
       "\n",
       "         Slope  Attention-Deficit/Hyperactivity Disorder  Anxiety Disorders  \\\n",
       "0     1.825774                                         0                  0   \n",
       "1     1.888544                                         1                  0   \n",
       "2     2.095749                                         1                  0   \n",
       "3     1.724831                                         1                  0   \n",
       "4     1.749441                                         1                  0   \n",
       "...        ...                                       ...                ...   \n",
       "1916  0.205704                                         0                  1   \n",
       "1917  1.996940                                         1                  1   \n",
       "1918  1.050644                                         0                  0   \n",
       "1919  1.470061                                         1                  0   \n",
       "1920  1.664433                                         1                  1   \n",
       "\n",
       "      Specific Learning Disorder  Autism Spectrum Disorder  Disruptive  \\\n",
       "0                              0                         0           0   \n",
       "1                              0                         0           1   \n",
       "2                              0                         0           1   \n",
       "3                              1                         1           0   \n",
       "4                              0                         0           0   \n",
       "...                          ...                       ...         ...   \n",
       "1916                           0                         0           0   \n",
       "1917                           0                         0           0   \n",
       "1918                           0                         0           0   \n",
       "1919                           0                         0           0   \n",
       "1920                           0                         1           0   \n",
       "\n",
       "      Communication Disorder  Depressive Disorders  Other Disorders  \n",
       "0                          0                     0                0  \n",
       "1                          0                     0                1  \n",
       "2                          0                     0                1  \n",
       "3                          0                     0                1  \n",
       "4                          0                     0                1  \n",
       "...                      ...                   ...              ...  \n",
       "1916                       0                     0                0  \n",
       "1917                       0                     1                0  \n",
       "1918                       0                     0                1  \n",
       "1919                       0                     0                0  \n",
       "1920                       0                     0                1  \n",
       "\n",
       "[1921 rows x 4106 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, foof, on='IDs', how='inner')\n",
    "df = pd.merge(df, labels, on='IDs', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1921, 4097) (1921, 8)\n"
     ]
    }
   ],
   "source": [
    "disorders_list = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'Communication Disorder',\n",
    "                         'Depressive Disorders', 'Other Disorders']\n",
    "x = df[df.columns.difference(['IDs']+disorders_list)]\n",
    "y = df[disorders_list]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 4097) (481, 4097)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 4097) (481, 4097)\n"
     ]
    }
   ],
   "source": [
    "#scaling features\n",
    "\n",
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(train_features)\n",
    "\n",
    "# transform training data\n",
    "train_features = norm.transform(train_features)\n",
    "test_features = norm.transform(test_features)\n",
    "\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 222) (481, 222)\n"
     ]
    }
   ],
   "source": [
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.95) # 95% variance retained\n",
    "pca.fit(train_features)\n",
    "\n",
    "# transform data\n",
    "train_features = pca.transform(train_features)\n",
    "test_features = pca.transform(test_features)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention-Deficit/Hyperactivity Disorder    871\n",
       "Anxiety Disorders                           486\n",
       "Specific Learning Disorder                  316\n",
       "Autism Spectrum Disorder                    207\n",
       "Disruptive                                  228\n",
       "Communication Disorder                      207\n",
       "Depressive Disorders                        145\n",
       "Other Disorders                             570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention-Deficit/Hyperactivity Disorder    295\n",
       "Anxiety Disorders                           154\n",
       "Specific Learning Disorder                  123\n",
       "Autism Spectrum Disorder                     85\n",
       "Disruptive                                   69\n",
       "Communication Disorder                       65\n",
       "Depressive Disorders                         49\n",
       "Other Disorders                             187\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "# from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "# n_inputs = train_features.shape[1]\n",
    "\n",
    "# visible = Input(shape=(n_inputs,))\n",
    "# e = Dense(n_inputs*2)(visible)\n",
    "# e = BatchNormalization()(e)\n",
    "# e = LeakyReLU()(e)\n",
    "# e = Dense(n_inputs)(e)\n",
    "# e = BatchNormalization()(e)\n",
    "# e = LeakyReLU()(e)\n",
    "# n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "# bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "# d = Dense(n_inputs)(bottleneck)\n",
    "# d = BatchNormalization()(d)\n",
    "# d = LeakyReLU()(d)\n",
    "\n",
    "# d = Dense(n_inputs*2)(d)\n",
    "# d = BatchNormalization()(d)\n",
    "# d = LeakyReLU()(d)\n",
    "\n",
    "# output = Dense(8, activation='linear')(d)\n",
    "\n",
    "# model = Model(inputs=visible, outputs=output)\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "\n",
    "# history = model.fit(train_features, train_labels, epochs=50, batch_size=16, verbose=2)\n",
    "# encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "# plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "# encoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode the data\n",
    "# encoder= load_model('autoencoder.h5', compile=False)\n",
    "\n",
    "# train_features = encoder.predict(train_features)\n",
    "# test_features = encoder.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))\n",
    "\n",
    "def evaluate(y_test, y_pred_prob, brier=True):\n",
    "    y_pred = y_pred_prob.round()\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    if brier:\n",
    "        print(\"Brier Score:\", brier_multi(y_test, y_pred_prob))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:1675: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = OneVsRestClassifier(\n",
    "    make_pipeline(StandardScaler(), LinearSVC(random_state=42))\n",
    ")\n",
    "classifier.fit(train_features, train_labels)\n",
    "y_score = classifier.decision_function(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The average precision score in multi-label settings\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(test_labels[:, i], y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(test_labels[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "    test_labels.ravel(), y_score.ravel()\n",
    ")\n",
    "average_precision[\"micro\"] = average_precision_score(test_labels, y_score, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "display = PrecisionRecallDisplay(\n",
    "    recall=recall[3],\n",
    "    precision=precision[3],\n",
    "    average_precision=average_precision[3],\n",
    ")\n",
    "\n",
    "display.plot()\n",
    "_ = display.ax_.set_title(\"secind class (zero)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "display = PrecisionRecallDisplay(\n",
    "    recall=recall[\"micro\"],\n",
    "    precision=precision[\"micro\"],\n",
    "    average_precision=average_precision[\"micro\"],\n",
    ")\n",
    "display.plot()\n",
    "_ = display.ax_.set_title(\"Micro-averaged over all classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.06860706860706861\n",
      "Hamming Loss: 0.28534303534303534\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63       291\n",
      "           1       0.37      0.26      0.30       158\n",
      "           2       0.20      0.12      0.15       108\n",
      "           3       0.21      0.08      0.12        75\n",
      "           4       0.12      0.05      0.07        75\n",
      "           5       0.10      0.03      0.05        63\n",
      "           6       0.42      0.12      0.19        40\n",
      "           7       0.36      0.34      0.35       179\n",
      "\n",
      "   micro avg       0.43      0.33      0.37       989\n",
      "   macro avg       0.30      0.21      0.23       989\n",
      "weighted avg       0.37      0.33      0.34       989\n",
      " samples avg       0.54      0.43      0.33       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 65 125]\n",
      "  [ 99 192]]\n",
      "\n",
      " [[252  71]\n",
      "  [117  41]]\n",
      "\n",
      " [[321  52]\n",
      "  [ 95  13]]\n",
      "\n",
      " [[384  22]\n",
      "  [ 69   6]]\n",
      "\n",
      " [[377  29]\n",
      "  [ 71   4]]\n",
      "\n",
      " [[399  19]\n",
      "  [ 61   2]]\n",
      "\n",
      " [[434   7]\n",
      "  [ 35   5]]\n",
      "\n",
      " [[195 107]\n",
      "  [119  60]]]\n",
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.13721413721413722\n",
      "Hamming Loss: 0.24168399168399168\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       291\n",
      "           1       0.35      0.04      0.07       158\n",
      "           2       1.00      0.02      0.04       108\n",
      "           3       0.00      0.00      0.00        75\n",
      "           4       0.50      0.01      0.03        75\n",
      "           5       0.00      0.00      0.00        63\n",
      "           6       0.00      0.00      0.00        40\n",
      "           7       0.38      0.10      0.16       179\n",
      "\n",
      "   micro avg       0.56      0.28      0.38       989\n",
      "   macro avg       0.35      0.13      0.12       989\n",
      "weighted avg       0.45      0.28      0.25       989\n",
      " samples avg       0.61      0.41      0.36       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 15 175]\n",
      "  [ 38 253]]\n",
      "\n",
      " [[312  11]\n",
      "  [152   6]]\n",
      "\n",
      " [[373   0]\n",
      "  [106   2]]\n",
      "\n",
      " [[404   2]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[405   1]\n",
      "  [ 74   1]]\n",
      "\n",
      " [[416   2]\n",
      "  [ 63   0]]\n",
      "\n",
      " [[440   1]\n",
      "  [ 40   0]]\n",
      "\n",
      " [[273  29]\n",
      "  [161  18]]]\n",
      "SVC():\n",
      "Accuracy: 0.14345114345114346\n",
      "Hamming Loss: 0.2312889812889813\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.75       291\n",
      "           1       1.00      0.00      0.00       158\n",
      "           2       1.00      0.00      0.00       108\n",
      "           3       1.00      0.00      0.00        75\n",
      "           4       1.00      0.00      0.00        75\n",
      "           5       1.00      0.00      0.00        63\n",
      "           6       1.00      0.00      0.00        40\n",
      "           7       0.00      0.00      0.00       179\n",
      "\n",
      "   micro avg       0.60      0.29      0.39       989\n",
      "   macro avg       0.83      0.12      0.09       989\n",
      "weighted avg       0.70      0.29      0.22       989\n",
      " samples avg       0.61      0.42      0.39       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  2 188]\n",
      "  [  3 288]]\n",
      "\n",
      " [[323   0]\n",
      "  [158   0]]\n",
      "\n",
      " [[373   0]\n",
      "  [108   0]]\n",
      "\n",
      " [[406   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[406   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[418   0]\n",
      "  [ 63   0]]\n",
      "\n",
      " [[441   0]\n",
      "  [ 40   0]]\n",
      "\n",
      " [[301   1]\n",
      "  [179   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels, brier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5466\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5235\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5197\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5146\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5100\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5072\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.5023\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4980\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4932\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4886\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4856\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4796\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4737\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4683\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4669\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4632\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4593\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4536\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4492\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4473\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4435\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4374\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4352\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4355\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4273\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4242\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4204\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4143\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4133\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4088\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4096\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4011\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.4006\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3935\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3905\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3908\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3829\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3789\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3788\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3708\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3701\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3653\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3632\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3649\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3577\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3517\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3525\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3517\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3436\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3415\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3361\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3365\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3328\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3287\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3252\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3244\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3175\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3171\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3174\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3189\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3162\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3075\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3050\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.3015\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.3040\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2980\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2972\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2885\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2882\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2852\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2828\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2778\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2784\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2834\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2765\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2702\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2681\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2630\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2616\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2614\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2613\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2588\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2604\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2584\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2555\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2490\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2506\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2445\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2454\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2384\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2345\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2371\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2354\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2291\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2286\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2274\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2270\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2279\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2254\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 0.2226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f95a09d9190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = train_features.shape[1],train_labels.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06444906444906445\n",
      "Hamming Loss: 0.28326403326403327\n",
      "Brier Score: 1.7176272807338944\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       291\n",
      "           1       0.39      0.32      0.35       158\n",
      "           2       0.26      0.14      0.18       108\n",
      "           3       0.24      0.05      0.09        75\n",
      "           4       0.28      0.11      0.15        75\n",
      "           5       0.06      0.03      0.04        63\n",
      "           6       0.23      0.07      0.11        40\n",
      "           7       0.40      0.46      0.42       179\n",
      "\n",
      "   micro avg       0.43      0.33      0.37       989\n",
      "   macro avg       0.31      0.22      0.24       989\n",
      "weighted avg       0.39      0.33      0.35       989\n",
      " samples avg       0.55      0.42      0.32       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 89 101]\n",
      "  [131 160]]\n",
      "\n",
      " [[243  80]\n",
      "  [107  51]]\n",
      "\n",
      " [[331  42]\n",
      "  [ 93  15]]\n",
      "\n",
      " [[393  13]\n",
      "  [ 71   4]]\n",
      "\n",
      " [[385  21]\n",
      "  [ 67   8]]\n",
      "\n",
      " [[384  34]\n",
      "  [ 61   2]]\n",
      "\n",
      " [[431  10]\n",
      "  [ 37   3]]\n",
      "\n",
      " [[177 125]\n",
      "  [ 97  82]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.04781704781704782\n",
      "Hamming Loss: 0.4041060291060291\n",
      "Brier Score: 3.2221146411774755\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.52      0.62       291\n",
      "           1       0.40      0.87      0.55       158\n",
      "           2       0.32      0.86      0.47       108\n",
      "           3       0.37      0.40      0.38        75\n",
      "           4       0.20      0.89      0.33        75\n",
      "           5       0.22      0.73      0.34        63\n",
      "           6       0.15      0.90      0.26        40\n",
      "           7       0.51      0.66      0.58       179\n",
      "\n",
      "   micro avg       0.35      0.69      0.47       989\n",
      "   macro avg       0.37      0.73      0.44       989\n",
      "weighted avg       0.48      0.69      0.51       989\n",
      " samples avg       0.38      0.71      0.43       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[144  46]\n",
      "  [140 151]]\n",
      "\n",
      " [[114 209]\n",
      "  [ 20 138]]\n",
      "\n",
      " [[176 197]\n",
      "  [ 15  93]]\n",
      "\n",
      " [[355  51]\n",
      "  [ 45  30]]\n",
      "\n",
      " [[139 267]\n",
      "  [  8  67]]\n",
      "\n",
      " [[255 163]\n",
      "  [ 17  46]]\n",
      "\n",
      " [[243 198]\n",
      "  [  4  36]]\n",
      "\n",
      " [[187 115]\n",
      "  [ 60 119]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_br.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07276507276507277\n",
      "Hamming Loss: 0.28326403326403327\n",
      "Brier Score: 1.6334844077705128\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63       291\n",
      "           1       0.36      0.27      0.31       158\n",
      "           2       0.22      0.13      0.16       108\n",
      "           3       0.20      0.09      0.13        75\n",
      "           4       0.21      0.11      0.14        75\n",
      "           5       0.05      0.02      0.02        63\n",
      "           6       0.41      0.17      0.25        40\n",
      "           7       0.36      0.25      0.30       179\n",
      "\n",
      "   micro avg       0.43      0.32      0.37       989\n",
      "   macro avg       0.30      0.21      0.24       989\n",
      "weighted avg       0.38      0.32      0.34       989\n",
      " samples avg       0.57      0.42      0.32       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 65 125]\n",
      "  [ 99 192]]\n",
      "\n",
      " [[249  74]\n",
      "  [116  42]]\n",
      "\n",
      " [[323  50]\n",
      "  [ 94  14]]\n",
      "\n",
      " [[378  28]\n",
      "  [ 68   7]]\n",
      "\n",
      " [[375  31]\n",
      "  [ 67   8]]\n",
      "\n",
      " [[399  19]\n",
      "  [ 62   1]]\n",
      "\n",
      " [[431  10]\n",
      "  [ 33   7]]\n",
      "\n",
      " [[222  80]\n",
      "  [134  45]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10810810810810811\n",
      "Hamming Loss: 0.24896049896049896\n",
      "Brier Score: 1.4215643591297917\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       291\n",
      "           1       0.39      0.14      0.20       158\n",
      "           2       0.20      0.02      0.03       108\n",
      "           3       0.25      0.04      0.07        75\n",
      "           4       0.20      0.04      0.07        75\n",
      "           5       0.00      0.00      0.00        63\n",
      "           6       0.00      0.00      0.00        40\n",
      "           7       0.41      0.22      0.29       179\n",
      "\n",
      "   micro avg       0.53      0.30      0.38       989\n",
      "   macro avg       0.26      0.16      0.17       989\n",
      "weighted avg       0.37      0.30      0.30       989\n",
      " samples avg       0.64      0.41      0.35       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 50 140]\n",
      "  [ 64 227]]\n",
      "\n",
      " [[288  35]\n",
      "  [136  22]]\n",
      "\n",
      " [[365   8]\n",
      "  [106   2]]\n",
      "\n",
      " [[397   9]\n",
      "  [ 72   3]]\n",
      "\n",
      " [[394  12]\n",
      "  [ 72   3]]\n",
      "\n",
      " [[415   3]\n",
      "  [ 63   0]]\n",
      "\n",
      " [[440   1]\n",
      "  [ 40   0]]\n",
      "\n",
      " [[244  58]\n",
      "  [139  40]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLkNN()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "mlknn = MLkNN(k=10)\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "\n",
    "mlknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10602910602910603\n",
      "Hamming Loss: 0.257016632016632\n",
      "Brier Score: 1.8118628649328041\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       291\n",
      "           1       1.00      0.00      0.00       158\n",
      "           2       1.00      0.00      0.00       108\n",
      "           3       1.00      0.00      0.00        75\n",
      "           4       1.00      0.00      0.00        75\n",
      "           5       1.00      0.00      0.00        63\n",
      "           6       1.00      0.00      0.00        40\n",
      "           7       1.00      0.00      0.00       179\n",
      "\n",
      "   micro avg       1.00      0.00      0.00       989\n",
      "   macro avg       1.00      0.00      0.00       989\n",
      "weighted avg       1.00      0.00      0.00       989\n",
      " samples avg       1.00      0.11      0.11       989\n",
      "\n",
      "Confusion matrix:\n",
      " [[[190   0]\n",
      "  [291   0]]\n",
      "\n",
      " [[323   0]\n",
      "  [158   0]]\n",
      "\n",
      " [[373   0]\n",
      "  [108   0]]\n",
      "\n",
      " [[406   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[406   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[418   0]\n",
      "  [ 63   0]]\n",
      "\n",
      " [[441   0]\n",
      "  [ 40   0]]\n",
      "\n",
      " [[302   0]\n",
      "  [179   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlknn = mlknn.predict_proba(x_test)\n",
    "evaluate(test_labels, predicted_labels_mlknn.todense())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
