{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7YxOz-zNNlyy"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import mat73\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import uniform\n",
        "from numpy import hstack\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier as rf\n",
        "from sklearn.svm import SVC as svm\n",
        "from sklearn.linear_model import LogisticRegression as lg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,f1_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from warnings import simplefilter,filterwarnings\n",
        "\n",
        "import os\n",
        "# ignore all future warnings1\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EEG data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "## data loading\n",
        "data = mat73.loadmat('x_source.mat')  \n",
        "id = scipy.io.loadmat('id.mat')\n",
        "IDs = pd.DataFrame(id[\"id\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2041, 68, 391)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# flattening\n",
        "df2 = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
        "df2 = np.array(df2)\n",
        "df2 = df2.reshape((2041,68,391)) \n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2041, 68, 39)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sparsed= np.concatenate([np.expand_dims(df2[:,:,i:i+10].mean(axis = 2), axis = 2) for i in range(0,381,10)], axis = 2)\n",
        "\n",
        "#sanity check\n",
        "df2[0,0,10:20].mean()\n",
        "sparsed[0,0,1]\n",
        "sparsed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2041, 2653)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#flattening and adding id\n",
        "df2 = pd.DataFrame(sparsed.reshape((sparsed.shape[0], -1)))\n",
        "df2.shape\n",
        "\n",
        "df2['IDs'] = IDs\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2041, 2653)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#df2['IDs']#array of arrays\n",
        "#df2['IDs'][0][0] #this is what i want for 1 guy\n",
        "df2['IDs'] = [df2['IDs'][i][0] for i in range(2041)] #removing these weird square brackets frm ids\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-YjKzrOY5dKO"
      },
      "source": [
        "## Behavioral Data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "bFK75cJgWc2G",
        "outputId": "c35c8bfc-2242-43be-aada-379d1ccb4c7e"
      },
      "outputs": [],
      "source": [
        "behaviour_data = pd.read_csv('scores.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We need columns with:\n",
        "1. IDs\n",
        "\n",
        " \n",
        "2. for Anxiety:  \"SCARED_SR\" \"SCARED_P\". \n",
        "    \n",
        "\n",
        "\n",
        "2. for ADHD inattention: Strengths and Weaknesses of ADHD Symptoms and Normal Behavior Scale (\"SWAN IN\")\n",
        "\n",
        "\n",
        "3. for ADHD combined: Strengths and Weaknesses of ADHD Symptoms and Normal Behavior Scale (\"SWAN HY\")\n",
        "\n",
        "\n",
        "4. for Autism Social Responsiveness Scale-2 (\"SRS_Pre\" (preschool) or \"SRS\") \n",
        "\n",
        "\n",
        "5. for Depression: Children's Depression Index (average score of: \"CDI_SR\" \"CDI_P\") (alternative 1: Mood & Feelings Questionnaire (MFQ); Alternative 2: Affective Reactivity Indexâ€”(ARI-S) Self Report)\n",
        "\n",
        "\n",
        "6. WISC-Full IQ \"WISC_FSIQ\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3076, 7)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "behaviour_data = behaviour_data[['IDs', 'MFQ_P_Total', 'SCARED_P_Total', 'SWAN_HY', \"SWAN_IN\", 'SRS_Total','ARI_S_Total_Score']]#, 'WISC_FSIQ' ]]\n",
        "behaviour_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your selected dataframe has 7 columns (with column 'IDs').\n",
            "There are 6 columns that have missing values.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Values</th>\n",
              "      <th>% of Total Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MFQ_P_Total</th>\n",
              "      <td>466</td>\n",
              "      <td>15.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCARED_P_Total</th>\n",
              "      <td>328</td>\n",
              "      <td>10.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS_Total</th>\n",
              "      <td>218</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SWAN_HY</th>\n",
              "      <td>163</td>\n",
              "      <td>5.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SWAN_IN</th>\n",
              "      <td>163</td>\n",
              "      <td>5.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARI_S_Total_Score</th>\n",
              "      <td>125</td>\n",
              "      <td>4.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Missing Values  % of Total Values\n",
              "MFQ_P_Total                   466               15.1\n",
              "SCARED_P_Total                328               10.7\n",
              "SRS_Total                     218                7.1\n",
              "SWAN_HY                       163                5.3\n",
              "SWAN_IN                       163                5.3\n",
              "ARI_S_Total_Score             125                4.1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def missing_values_table(df):\n",
        "    mis_val = df.isnull().sum()\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "    mis_val_table_ren_columns = mis_val_table.rename(\n",
        "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "    '% of Total Values', ascending=False).round(1)\n",
        "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns (with column 'IDs').\\n\"      \n",
        "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "            \" columns that have missing values.\")\n",
        "    return mis_val_table_ren_columns\n",
        "\n",
        "missing_values_table(behaviour_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge EEG and behavioral data together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1929, 2659)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.merge(df2, behaviour_data, on='IDs', how='inner')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## features and labels preparation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1599, 2659)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#removing NaNs\n",
        "df = df.dropna()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X = df.iloc[:, 0:2652].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = df[[ 'MFQ_P_Total', 'SCARED_P_Total', 'SWAN_HY', \"SWAN_IN\", 'SRS_Total','ARI_S_Total_Score']]#, 'WISC_FSIQ' ]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data normalisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1599, 6)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y = Y.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Y_scaled = min_max_scaler.fit_transform(Y)\n",
        "Y = pd.DataFrame(Y_scaled)\n",
        "Y.shape\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.161708\n",
              "1    0.210177\n",
              "2    0.543870\n",
              "3    0.615419\n",
              "4    0.301258\n",
              "5    0.289921\n",
              "dtype: float64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "Y.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA on X dimension, not needed:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dimensionality reduction\n",
        "#pca = PCA(.95) # 95% variance retained\n",
        "#pca.fit(X)\n",
        "\n",
        "# transform data\n",
        "#X_pca = pca.transform(X)\n",
        "#X_pca.shape\n",
        "#X_pca = X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: (1599, 2652) Y: (1599, 6)\n"
          ]
        }
      ],
      "source": [
        "print(\"X:\", X.shape, \"Y:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_dim = X.shape[1]\n",
        "out_dim = Y.shape[1]\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(X, Y, test_size=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODELLING PART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### dummy regressors (to obtain the random baseline):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error (dummy): 0.04\n",
            "Median absolute error (dummy): 0.12\n",
            "r2_score (dummy mean): -0.00\n",
            "r2_score (dummy median): -0.03\n",
            "             0         1         2         3         4         5\n",
            "411   0.125000  0.028986  0.666667  0.500000  0.211765  0.166667\n",
            "122   0.071429  0.086957  0.648148  0.648148  0.252941  0.250000\n",
            "84    0.017857  0.086957  0.518518  0.685185  0.464706  0.333333\n",
            "554   0.250000  0.130435  0.759259  0.851852  0.335294  0.500000\n",
            "1298  0.160714  0.376812  0.537037  0.425926  0.252941  0.166667\n",
            "1140  0.017857  0.028986  0.629630  0.518518  0.135294  0.166667\n",
            "1363  0.642857  0.913043  0.351852  0.981481  0.705882  0.083333\n",
            "389   0.053571  0.028986  0.555555  0.685185  0.100000  0.166667\n",
            "1316  0.035714  0.000000  0.685185  0.907407  0.176471  0.166667\n",
            "941   0.196429  0.101449  0.314815  0.333333  0.088235  0.500000\n",
            "0    0.161708\n",
            "1    0.210177\n",
            "2    0.543870\n",
            "3    0.615419\n",
            "4    0.301258\n",
            "5    0.289921\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(X, Y, test_size=0.5)\n",
        "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(xtrain, ytrain)\n",
        "lm_dummy_median = DummyRegressor(strategy = 'median').fit(xtrain, ytrain)\n",
        "ypred_dummy_mean = lm_dummy_mean.predict(xtest)\n",
        "ypred_dummy_median = lm_dummy_median.predict(xtest)\n",
        "\n",
        "\n",
        "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(ytest,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
        "\n",
        "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(ytest,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_median)))\n",
        "\n",
        "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(ytest, ypred_dummy_mean)))\n",
        "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(ytest, ypred_dummy_median)))\n",
        "\n",
        "print(ytest[:10])\n",
        "print(Y.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVR regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error (SVC): 0.04\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Create the SVR regressor\n",
        "svr = SVR(epsilon=0.2)\n",
        "#Create the Multioutput Regressor\n",
        "mor = MultiOutputRegressor(svr)\n",
        "# Train the regressor\n",
        "mor = mor.fit(xtrain, ytrain)\n",
        "# Generate predictions for testing data\n",
        "ypred = mor.predict(xtest)\n",
        "\n",
        "\n",
        "print(\"Mean squared error (SVC): {:.2f}\".format(mean_squared_error(ytest,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## keras, simple MLP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-18 07:44:31.732141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-18 07:44:31.754893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.755565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-11-18 07:44:31.755806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-18 07:44:31.756981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-18 07:44:31.758258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-18 07:44:31.758465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-18 07:44:31.759551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-18 07:44:31.760096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-18 07:44:31.762464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-18 07:44:31.762616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.763343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.763945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2021-11-18 07:44:31.764368: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "2021-11-18 07:44:31.769720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
            "2021-11-18 07:44:31.770291: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591b0f72ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-18 07:44:31.770301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-18 07:44:31.770453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.771083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-11-18 07:44:31.771123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-18 07:44:31.771138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-18 07:44:31.771149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-18 07:44:31.771160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-18 07:44:31.771171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-18 07:44:31.771182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-18 07:44:31.771193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-18 07:44:31.771251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.771904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.772502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2021-11-18 07:44:31.772533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-18 07:44:31.847412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-18 07:44:31.847441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2021-11-18 07:44:31.847447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2021-11-18 07:44:31.847741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.848397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.849028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-18 07:44:31.849673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14109 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
            "2021-11-18 07:44:31.851433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591b4599440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-18 07:44:31.851444: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 1/91 [..............................] - ETA: 0s - loss: 1.1547 - mse: 1.1547"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-18 07:44:32.673106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 0s 3ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0440 - val_mse: 0.0440\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0460 - val_mse: 0.0460\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0445 - val_mse: 0.0445\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0479 - val_mse: 0.0479\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0454 - val_mse: 0.0454\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0452 - val_mse: 0.0452\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0462 - val_mse: 0.0462\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0467 - val_mse: 0.0467\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0530 - val_mse: 0.0530\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0461 - val_mse: 0.0461\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0468 - val_mse: 0.0468\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0471 - val_mse: 0.0471\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0471 - val_mse: 0.0471\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0459 - val_mse: 0.0459\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0512 - val_mse: 0.0512\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0480 - val_mse: 0.0480\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0517 - val_mse: 0.0517\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0497 - val_mse: 0.0497\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0513 - val_mse: 0.0513\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0521 - val_mse: 0.0521\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0582 - val_mse: 0.0582\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0605 - val_mse: 0.0605\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0541 - val_mse: 0.0541\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0544 - val_mse: 0.0544\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0695 - val_mse: 0.0695\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0559 - val_mse: 0.0559\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0555 - val_mse: 0.0555\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0569 - val_mse: 0.0569\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0613 - val_mse: 0.0613\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0579 - val_mse: 0.0579\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0587 - val_mse: 0.0587\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0603 - val_mse: 0.0603\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0626 - val_mse: 0.0626\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0599 - val_mse: 0.0599\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0613 - val_mse: 0.0613\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0588 - val_mse: 0.0588\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0635 - val_mse: 0.0635\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0633 - val_mse: 0.0633\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0638 - val_mse: 0.0638\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0635 - val_mse: 0.0635\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0624 - val_mse: 0.0624\n",
            "Epoch 73/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0654 - val_mse: 0.0654\n",
            "Epoch 74/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 75/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 76/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 77/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0622 - val_mse: 0.0622\n",
            "Epoch 78/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0655 - val_mse: 0.0655\n",
            "Epoch 79/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0637 - val_mse: 0.0637\n",
            "Epoch 80/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0628 - val_mse: 0.0628\n",
            "Epoch 81/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0660 - val_mse: 0.0660\n",
            "Epoch 82/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0653 - val_mse: 0.0653\n",
            "Epoch 83/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 84/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0702 - val_mse: 0.0702\n",
            "Epoch 85/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0660 - val_mse: 0.0660\n",
            "Epoch 86/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 87/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0662 - val_mse: 0.0662\n",
            "Epoch 88/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0673 - val_mse: 0.0673\n",
            "Epoch 89/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0646 - val_mse: 0.0646\n",
            "Epoch 90/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0637 - val_mse: 0.0637\n",
            "Epoch 91/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0635 - val_mse: 0.0635\n",
            "Epoch 92/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0648 - val_mse: 0.0648\n",
            "Epoch 93/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 94/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0654 - val_mse: 0.0654\n",
            "Epoch 95/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0708 - val_mse: 0.0708\n",
            "Epoch 96/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0685 - val_mse: 0.0685\n",
            "Epoch 97/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0658 - val_mse: 0.0658\n",
            "Epoch 98/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0656 - val_mse: 0.0656\n",
            "Epoch 99/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 100/100\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0660 - val_mse: 0.0660\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=in_dim, activation=\"relu\"))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dense(out_dim))\n",
        "model.compile(loss=\"mse\", metrics = ['mse'], optimizer=\"adam\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=100, batch_size=12, validation_split = 0.2, verbose=1)\n",
        "ypred = model.predict(xtest)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.059276782"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score = tf.keras.metrics.mean_squared_error(\n",
        "    ytest, ypred\n",
        ")\n",
        "\n",
        "score= np.array(score)\n",
        "\n",
        "score.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#xtrain = np.asarray(xtrain).astype('float32')\n",
        "#xtest = np.asarray(xtest).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D , MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def get_CNN_2_classifier():\n",
        "\n",
        "    k = 3  # kernel size\n",
        "    s = 2  # stride\n",
        "    n_filters = 32 # number of filters\n",
        "    inputs = Input(shape=(39, 68, 1))\n",
        "\n",
        "    conv1 = Conv2D(n_filters, kernel_size=(k, k), strides=(s, s), padding='same')(inputs)\n",
        "    conv1 = BatchNormalization(scale=False, axis=3)(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "    conv1 = Conv2D(n_filters, kernel_size=(k, k), padding='same')(conv1)\n",
        "    conv1 = BatchNormalization(scale=False, axis=3)(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
        "    pool1 = conv1 # MaxPooling2D(pool_size=(s, s))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(2 * n_filters, kernel_size=(k, k), strides=(s, s), padding='same')(pool1)\n",
        "    conv2 = BatchNormalization(scale=False, axis=3)(conv2)\n",
        "    conv2 = LeakyReLU(alpha=0.3)(conv2)\n",
        "    conv2 = Conv2D(2 * n_filters, kernel_size=(k, k), padding='same')(conv2)\n",
        "    conv2 = BatchNormalization(scale=False, axis=3)(conv2)\n",
        "    conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(s, s))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(4 * n_filters, kernel_size=(k, k), padding='same')(pool2)\n",
        "    conv3 = BatchNormalization(scale=False, axis=3)(conv3)\n",
        "    conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
        "    conv3 = Conv2D(4 * n_filters, kernel_size=(k, k), padding='same')(conv3)\n",
        "    conv3 = BatchNormalization(scale=False, axis=3)(conv3)\n",
        "    conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(s, s))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(8 * n_filters, kernel_size=(k, k), padding='same')(pool3)\n",
        "    conv4 = BatchNormalization(scale=False, axis=3)(conv4)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    conv4 = Conv2D(8 * n_filters, kernel_size=(k, k), padding='same')(conv4)\n",
        "    conv4 = BatchNormalization(scale=False, axis=3)(conv4)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(s, s))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(16 * n_filters, kernel_size=(k, k), padding='same')(pool4)\n",
        "    conv5 = BatchNormalization(scale=False, axis=3)(conv5)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "    conv5 = Conv2D(16 * n_filters, kernel_size=(k, k), padding='same')(conv5)\n",
        "    conv5 = BatchNormalization(scale=False, axis=3)(conv5)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "\n",
        "    gap = GlobalAveragePooling2D()(conv5)\n",
        "    outputs = Dense(6, activation='relu')(gap)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer = Adam(lr=1e-4), loss = 'mse', metrics = ['mse'])\n",
        "    model.summary()\n",
        "  \n",
        "    return model\n",
        "\n",
        "CNN_model_2 = get_CNN_2_classifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 39, 68, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 20, 34, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 20, 34, 32)        96        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 20, 34, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 20, 34, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 20, 34, 32)        96        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 20, 34, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 20, 34, 256)       73984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 20, 34, 256)       768       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 20, 34, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 20, 34, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 20, 34, 256)       768       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 20, 34, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 10, 17, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 10, 17, 512)       1536      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 10, 17, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 10, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 10, 17, 512)       1536      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 10, 17, 512)       0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 4,221,478\n",
            "Trainable params: 4,218,278\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_CNN_1_classifier():\n",
        "\n",
        "    k = 3  # kernel size\n",
        "    s = 2  # stride\n",
        "    n_filters = 32 # number of filters\n",
        "    inputs = Input(shape=(39, 68, 1))\n",
        "\n",
        "    conv1 = Conv2D(n_filters, kernel_size=(k, k), strides=(s, s), padding='same')(inputs)\n",
        "    conv1 = BatchNormalization(scale=False, axis=3)(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "    conv1 = Conv2D(n_filters, kernel_size=(k, k), padding='same')(conv1)\n",
        "    conv1 = BatchNormalization(scale=False, axis=3)(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
        "    pool1 = conv1 # MaxPooling2D(pool_size=(s, s))(conv1)\n",
        "\n",
        "\n",
        "    conv4 = Conv2D(8 * n_filters, kernel_size=(k, k), padding='same')(pool1)\n",
        "    conv4 = BatchNormalization(scale=False, axis=3)(conv4)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    conv4 = Conv2D(8 * n_filters, kernel_size=(k, k), padding='same')(conv4)\n",
        "    conv4 = BatchNormalization(scale=False, axis=3)(conv4)\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(s, s))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(16 * n_filters, kernel_size=(k, k), padding='same')(pool4)\n",
        "    conv5 = BatchNormalization(scale=False, axis=3)(conv5)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "    conv5 = Conv2D(16 * n_filters, kernel_size=(k, k), padding='same')(conv5)\n",
        "    conv5 = BatchNormalization(scale=False, axis=3)(conv5)\n",
        "    conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
        "\n",
        "    gap = GlobalAveragePooling2D()(conv5)\n",
        "    outputs = Dense(6, activation='relu')(gap)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer = Adam(lr=1e-4), loss = 'mse', metrics = ['mse'])\n",
        "    model.summary()\n",
        "  \n",
        "    return model\n",
        "\n",
        "CNN_model_1 = get_CNN_1_classifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data reshaping for CNN\n",
        "n_electrode = 68\n",
        "n_freq =39 \n",
        "\n",
        "xtrain = xtrain.reshape((xtrain.shape[0], n_electrode, n_freq))\n",
        "xtest = xtest.reshape((xtest.shape[0], n_electrode, n_freq))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 2s 94ms/step - loss: 0.1533 - mse: 0.1533 - val_loss: 0.1773 - val_mse: 0.1773\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.1762 - val_mse: 0.1762\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.1366 - val_mse: 0.1366\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.1669 - val_mse: 0.1669\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.1153 - val_mse: 0.1153\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.1117 - val_mse: 0.1117\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.1138 - val_mse: 0.1138\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.1181 - val_mse: 0.1181\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.1620 - val_mse: 0.1620\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.1715 - val_mse: 0.1715\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.1606 - val_mse: 0.1606\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.1941 - val_mse: 0.1941\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.2020 - val_mse: 0.2020\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.2099 - val_mse: 0.2099\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.1987 - val_mse: 0.1987\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.1894 - val_mse: 0.1894\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.1770 - val_mse: 0.1770\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.1696 - val_mse: 0.1696\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.1657 - val_mse: 0.1657\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.1559 - val_mse: 0.1559\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.1127 - val_mse: 0.1127\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.1261 - val_mse: 0.1261\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0893 - val_mse: 0.0893\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0883 - val_mse: 0.0883\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0750 - val_mse: 0.0750\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0701 - val_mse: 0.0701\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.1006 - val_mse: 0.1006\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0694 - val_mse: 0.0694\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0727 - val_mse: 0.0727\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0703 - val_mse: 0.0703\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0682 - val_mse: 0.0682\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0657 - val_mse: 0.0657\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0594 - val_mse: 0.0594\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0581 - val_mse: 0.0581\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0605 - val_mse: 0.0605\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0643 - val_mse: 0.0643\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0725 - val_mse: 0.0725\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0667 - val_mse: 0.0667\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0803 - val_mse: 0.0803\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0719 - val_mse: 0.0719\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0806 - val_mse: 0.0806\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0612 - val_mse: 0.0612\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0672 - val_mse: 0.0672\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0663 - val_mse: 0.0663\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.060835075"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_CNN_1 = CNN_model_1.fit(np.transpose(xtrain, (0, 2, 1)), ytrain, validation_split=0.2, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "ypred = CNN_model_1.predict(np.transpose(xtest, (0, 2, 1)))\n",
        "\n",
        "\n",
        "\n",
        "score = tf.keras.metrics.mean_squared_error(\n",
        "    ytest, ypred\n",
        ")\n",
        "\n",
        "score = np.array(score)\n",
        "\n",
        "score.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0507 - val_mse: 0.0507\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0506 - val_mse: 0.0506\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0498 - val_mse: 0.0498\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0496 - val_mse: 0.0496\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0508 - val_mse: 0.0508\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0492 - val_mse: 0.0492\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0505 - val_mse: 0.0505\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0497 - val_mse: 0.0497\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0498 - val_mse: 0.0498\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0484 - val_mse: 0.0484\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0480 - val_mse: 0.0480\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0527 - val_mse: 0.0527\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0501 - val_mse: 0.0501\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0478 - val_mse: 0.0478\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0504 - val_mse: 0.0504\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0484 - val_mse: 0.0484\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0486 - val_mse: 0.0486\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0503 - val_mse: 0.0503\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0485 - val_mse: 0.0485\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0485 - val_mse: 0.0485\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0485 - val_mse: 0.0485\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0491 - val_mse: 0.0491\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0551 - val_mse: 0.0551\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0492 - val_mse: 0.0492\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0491 - val_mse: 0.0491\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0472 - val_mse: 0.0472\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0469 - val_mse: 0.0469\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0480 - val_mse: 0.0480\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0482 - val_mse: 0.0482\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0477 - val_mse: 0.0477\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0480 - val_mse: 0.0480\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0479 - val_mse: 0.0479\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0493 - val_mse: 0.0493\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0497 - val_mse: 0.0497\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0518 - val_mse: 0.0518\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0494 - val_mse: 0.0494\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0465 - val_mse: 0.0465\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0469 - val_mse: 0.0469\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0463 - val_mse: 0.0463\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0463 - val_mse: 0.0463\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0463 - val_mse: 0.0463\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0477 - val_mse: 0.0477\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0475 - val_mse: 0.0475\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0462 - val_mse: 0.0462\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0483 - val_mse: 0.0483\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0511 - val_mse: 0.0511\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0467 - val_mse: 0.0467\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.03990904"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_CNN_2 = CNN_model_2.fit(np.transpose(xtrain, (0, 2, 1)), ytrain, validation_split=0.2, epochs=50, verbose=1)\n",
        "\n",
        "\n",
        "ypred = CNN_model_2.predict(np.transpose(xtest, (0, 2, 1)))\n",
        "\n",
        "\n",
        "\n",
        "score = tf.keras.metrics.mean_squared_error(\n",
        "    ytest, ypred\n",
        ")\n",
        "\n",
        "score = np.array(score)\n",
        "\n",
        "score.mean()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "DataScienceLab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
