{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "import pandas\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2042, 105, 79)\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat('x.mat')  \n",
    "print(data['x'].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Electrode 1 - 1/2 Hz'],\n",
       "       ['Electrode 1 - 2/2 Hz'],\n",
       "       ['Electrode 1 - 3/2 Hz'],\n",
       "       ...,\n",
       "       ['Electrode 105 - 77/2 Hz'],\n",
       "       ['Electrode 105 - 78/2 Hz'],\n",
       "       ['Electrode 105 - 79/2 Hz']], dtype='<U23')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(data['x'].shape[1]) for j in range(data['x'].shape[2])])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ACE_Score</th>\n",
       "      <th>APQ_P_Total</th>\n",
       "      <th>APQ_SR_Total</th>\n",
       "      <th>ARI_P_Total_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>DX_10_Past_Doc</th>\n",
       "      <th>DX_10_Presum</th>\n",
       "      <th>DX_10_RC</th>\n",
       "      <th>DX_10_Rem</th>\n",
       "      <th>DX_10_RuleOut</th>\n",
       "      <th>DX_10_Spec</th>\n",
       "      <th>DX_10_Sub</th>\n",
       "      <th>DX_10_Time</th>\n",
       "      <th>NoDX</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>1</td>\n",
       "      <td>6.728040</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Diagnosis Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>2</td>\n",
       "      <td>5.545744</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>3</td>\n",
       "      <td>7.475929</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>7</td>\n",
       "      <td>13.627880</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>8</td>\n",
       "      <td>7.982660</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>NDARZN148PMN</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>3028</td>\n",
       "      <td>11.629363</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anxiety Disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>3030</td>\n",
       "      <td>14.878736</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Combined Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "      <td>3031</td>\n",
       "      <td>16.379534</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Other Neurodevelopmental Disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>3032</td>\n",
       "      <td>15.029545</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Inattentive Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "      <td>3033</td>\n",
       "      <td>11.489162</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADHD-Inattentive Type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1785 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope  Unnamed: 0        Age  Sex  \\\n",
       "0     NDARAA075AMK   0.986272  1.825774           1   6.728040    1   \n",
       "1     NDARAA112DMH   1.486650  1.888544           2   5.545744    0   \n",
       "2     NDARAA117NEJ   1.593155  2.095749           3   7.475929    0   \n",
       "3     NDARAA947ZG5   0.703331  1.724831           7  13.627880    0   \n",
       "4     NDARAA948VFH   0.918020  1.749441           8   7.982660    1   \n",
       "...            ...        ...       ...         ...        ...  ...   \n",
       "1780  NDARZN148PMN   0.168009  0.205704        3028  11.629363    1   \n",
       "1781  NDARZN277NR6   1.351549  1.996940        3030  14.878736    1   \n",
       "1782  NDARZN610GTY   0.339229  1.050644        3031  16.379534    1   \n",
       "1783  NDARZN677EYE   0.781225  1.470061        3032  15.029545    1   \n",
       "1784  NDARZN899JCM   0.464107  1.664433        3033  11.489162    1   \n",
       "\n",
       "      ACE_Score  APQ_P_Total  APQ_SR_Total  ARI_P_Total_Score  ...  \\\n",
       "0           NaN         91.0         123.0                1.0  ...   \n",
       "1           NaN          NaN           NaN                3.0  ...   \n",
       "2           NaN        113.0          95.0                2.0  ...   \n",
       "3           NaN         85.0          88.0                8.0  ...   \n",
       "4           NaN         91.0          91.0                3.0  ...   \n",
       "...         ...          ...           ...                ...  ...   \n",
       "1780        NaN        102.0         145.0                2.0  ...   \n",
       "1781        NaN        104.0         112.0                5.0  ...   \n",
       "1782        NaN        106.0         114.0                3.0  ...   \n",
       "1783        NaN        105.0         121.0                7.0  ...   \n",
       "1784        NaN        111.0          74.0                1.0  ...   \n",
       "\n",
       "      DX_10_Past_Doc  DX_10_Presum  DX_10_RC  DX_10_Rem  DX_10_RuleOut  \\\n",
       "0                NaN           NaN       NaN        NaN            NaN   \n",
       "1                NaN           NaN       NaN        NaN            NaN   \n",
       "2                NaN           NaN       NaN        NaN            NaN   \n",
       "3                NaN           NaN       NaN        NaN            NaN   \n",
       "4                NaN           NaN       NaN        NaN            NaN   \n",
       "...              ...           ...       ...        ...            ...   \n",
       "1780             NaN           NaN       NaN        NaN            NaN   \n",
       "1781             NaN           NaN       NaN        NaN            NaN   \n",
       "1782             NaN           NaN       NaN        NaN            NaN   \n",
       "1783             NaN           NaN       NaN        NaN            NaN   \n",
       "1784             NaN           NaN       NaN        NaN            NaN   \n",
       "\n",
       "      DX_10_Spec  DX_10_Sub  DX_10_Time  NoDX  \\\n",
       "0            NaN        NaN         1.0   1.0   \n",
       "1            NaN        NaN         1.0   2.0   \n",
       "2            NaN        NaN         1.0   2.0   \n",
       "3            NaN        NaN         1.0   2.0   \n",
       "4            NaN        NaN         1.0   2.0   \n",
       "...          ...        ...         ...   ...   \n",
       "1780         NaN        NaN         1.0   2.0   \n",
       "1781         NaN        NaN         1.0   2.0   \n",
       "1782         NaN        NaN         1.0   2.0   \n",
       "1783         NaN        NaN         1.0   2.0   \n",
       "1784         NaN        NaN         1.0   2.0   \n",
       "\n",
       "                                   label  \n",
       "0                     No Diagnosis Given  \n",
       "1                     ADHD-Combined Type  \n",
       "2                     ADHD-Combined Type  \n",
       "3                     ADHD-Combined Type  \n",
       "4                     ADHD-Combined Type  \n",
       "...                                  ...  \n",
       "1780                   Anxiety Disorders  \n",
       "1781                  ADHD-Combined Type  \n",
       "1782  Other Neurodevelopmental Disorders  \n",
       "1783               ADHD-Inattentive Type  \n",
       "1784               ADHD-Inattentive Type  \n",
       "\n",
       "[1785 rows x 180 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"table_withlabels.csv\")\n",
    "foof = pd.read_csv(\"foof2features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Neurodevelopmental Disorders    492\n",
      "ADHD-Inattentive Type                 388\n",
      "ADHD-Combined Type                    376\n",
      "Anxiety Disorders                     241\n",
      "No Diagnosis Given                    203\n",
      "Depressive Disorders                   85\n",
      "Name: label, dtype: int64\n",
      "(1785, 8297)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['C1']\n",
    "df = pd.merge(df, labels[['label', 'IDs']], on='IDs', how='inner')\n",
    "print(df['label'].value_counts())\n",
    "dataset = df.values\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1785, 8295)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:,0:8295].astype(float)\n",
    "y = dataset[:,8296]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#X = np.clip(X, -1, 1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 8295)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(888, 8295)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, stratify=y,test_size=0.3)\n",
    "\n",
    "oversample = SMOTE() #oversample to aaccount for the data imbalance\n",
    "trainX,trainy = oversample.fit_resample(trainX,trainy)\n",
    "testX,testy = oversample.fit_resample(testX,testy)\n",
    "\n",
    "print(trainX.shape)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainX = trainX.reshape((2064,105,79)) \n",
    "testX = testX.reshape((888,105,79)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def evaluate(y_test, y_pred, show_cm=False):\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    y_test = np.argmax(y_test, axis=1) # assuming you have n-by-6 class_prob\n",
    "    y_pred = np.argmax(y_pred, axis=1) # assuming you have n-by-6 class_prob\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "#     print(\"ROC AUC:\", metrics.roc_auc_score(y_test, y_pred, multi_class='ovo',))\n",
    "    print(\"F1 score:\", metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "#     print(\"Brier Score:\", metrics.brier_score_loss(y_test, y_pred)) # only for binary classification\n",
    "    labels = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "    if show_cm:\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "        disp.plot()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.transpose(trainX, (0, 2,1))\n",
    "testX = np.transpose(testX, (0, 2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print('Tensorflow Version: ',tensorflow.__version__)\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_158 (Conv1D)          (None, 79, 32)            13472     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 39, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 39, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 19, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 19, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 9, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 9, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 4, 512)            393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 4, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 2, 1024)           1573888   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 2,120,550\n",
      "Trainable params: 2,118,630\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 32, kernel_size =4, input_shape = (79, 105), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters = 32, kernel_size = 5, input_shape = (79, 32), activation = 'relu', padding = 'same'))\n",
    "# Pooling\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, input_shape = (39, 32), activation = 'relu', padding = 'same'))\n",
    "##model.add(Conv1D(filters = 64, kernel_size = 3, input_shape = (39, 64), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =128, kernel_size = 3, input_shape = (19, 64), activation = 'relu', padding = 'same'))\n",
    "##model.add(Conv1D(filters =128, kernel_size = 3, input_shape = (19, 128), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =256, kernel_size = 3, input_shape = (9, 128), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =256, kernel_size = 3, input_shape = (9, 256), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =512, kernel_size = 3, input_shape = (4, 256), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =512, kernel_size = 3, input_shape = (4, 512), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters = 1024, kernel_size = 3, input_shape = (2, 512), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters = 1024, kernel_size = 3, input_shape = (2, 1028), activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Full connection\n",
    "#model.add(Dense(units = 512, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(units = 128, activation = 'relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(units = 32, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 6, activation = 'softmax'))\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_185 (Conv1D)          (None, 79, 32)            10112     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_167 (MaxPoolin (None, 39, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_186 (Conv1D)          (None, 39, 64)            6208      \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 39, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 39, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_168 (MaxPoolin (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_188 (Conv1D)          (None, 19, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 19, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_169 (MaxPoolin (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_189 (Conv1D)          (None, 9, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 9, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_170 (MaxPoolin (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_190 (Conv1D)          (None, 4, 512)            393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 4, 512)            2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_171 (MaxPoolin (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_191 (Conv1D)          (None, 2, 1024)           1573888   \n",
      "_________________________________________________________________\n",
      "conv1d_192 (Conv1D)          (None, 2, 1024)           3146752   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_172 (MaxPoolin (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 5,276,294\n",
      "Trainable params: 5,274,374\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 32, kernel_size = 3, input_shape = (79, 105), activation = 'relu', padding = 'same'))\n",
    "# Pooling\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Convolution\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, input_shape = (39, 32), activation = 'relu', padding = 'same'))\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, input_shape = (39, 64), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =128, kernel_size = 3, input_shape = (19, 64), activation = 'relu', padding = 'same'))\n",
    "##model.add(Conv1D(filters =128, kernel_size = 3, input_shape = (19, 128), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =256, kernel_size = 3, input_shape = (9, 128), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =256, kernel_size = 3, input_shape = (9, 256), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters =512, kernel_size = 3, input_shape = (4, 256), activation = 'relu', padding = 'same'))\n",
    "#model.add(Conv1D(filters =512, kernel_size = 3, input_shape = (4, 512), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Conv1D(filters = 1024, kernel_size = 3, input_shape = (2, 512), activation = 'relu', padding = 'same'))\n",
    "model.add(Conv1D(filters = 1024, kernel_size = 3, input_shape = (2, 1028), activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 6, activation = 'softmax'))\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 1.8801 - accuracy: 0.3193 - val_loss: 2.5084 - val_accuracy: 0.1847\n",
      "Epoch 2/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 1.3107 - accuracy: 0.4797 - val_loss: 2.4738 - val_accuracy: 0.2252\n",
      "Epoch 3/20\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 1.1593 - accuracy: 0.5383 - val_loss: 2.3377 - val_accuracy: 0.2376\n",
      "Epoch 4/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.9040 - accuracy: 0.6579 - val_loss: 2.9332 - val_accuracy: 0.1959\n",
      "Epoch 5/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.7676 - accuracy: 0.7035 - val_loss: 3.0121 - val_accuracy: 0.2140\n",
      "Epoch 6/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.6397 - accuracy: 0.7616 - val_loss: 3.3537 - val_accuracy: 0.1768\n",
      "Epoch 7/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.5314 - accuracy: 0.8261 - val_loss: 2.9276 - val_accuracy: 0.1903\n",
      "Epoch 8/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.4391 - accuracy: 0.8445 - val_loss: 3.7245 - val_accuracy: 0.1869\n",
      "Epoch 9/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.2766 - accuracy: 0.9026 - val_loss: 3.8780 - val_accuracy: 0.1858\n",
      "Epoch 10/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.2711 - accuracy: 0.9089 - val_loss: 3.9390 - val_accuracy: 0.1858\n",
      "Epoch 11/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.3555 - accuracy: 0.8852 - val_loss: 3.5913 - val_accuracy: 0.1892\n",
      "Epoch 12/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.2623 - accuracy: 0.9162 - val_loss: 4.1044 - val_accuracy: 0.1881\n",
      "Epoch 13/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1898 - accuracy: 0.9288 - val_loss: 4.8004 - val_accuracy: 0.1914\n",
      "Epoch 14/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1559 - accuracy: 0.9482 - val_loss: 4.6388 - val_accuracy: 0.1914\n",
      "Epoch 15/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1783 - accuracy: 0.9370 - val_loss: 3.9535 - val_accuracy: 0.1869\n",
      "Epoch 16/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1342 - accuracy: 0.9593 - val_loss: 4.4016 - val_accuracy: 0.2050\n",
      "Epoch 17/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1321 - accuracy: 0.9588 - val_loss: 4.6984 - val_accuracy: 0.2128\n",
      "Epoch 18/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1014 - accuracy: 0.9641 - val_loss: 4.8092 - val_accuracy: 0.2264\n",
      "Epoch 19/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9656 - val_loss: 4.1378 - val_accuracy: 0.2095\n",
      "Epoch 20/20\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.1268 - accuracy: 0.9578 - val_loss: 4.4864 - val_accuracy: 0.2252\n",
      "[[0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]]\n",
      "[[9.9997127e-01 1.8620332e-05 2.3008173e-09 6.2258332e-10 8.7641301e-06\n",
      "  1.3809382e-06]\n",
      " [9.3318123e-01 1.1300666e-03 9.2892448e-04 3.6154315e-06 4.6390115e-04\n",
      "  6.4292289e-02]\n",
      " [8.4777959e-02 9.0952826e-01 1.3913822e-04 6.9830174e-05 3.2267984e-05\n",
      "  5.4526092e-03]\n",
      " ...\n",
      " [1.5553751e-02 4.8513088e-01 4.8594630e-01 3.6304296e-04 8.1025145e-04\n",
      "  1.2195806e-02]\n",
      " [5.1861431e-04 1.1518378e-02 1.4591373e-02 9.6795551e-02 8.6469448e-01\n",
      "  1.1881569e-02]\n",
      " [1.4912957e-01 6.6866964e-04 8.2753107e-02 1.4440819e-04 1.3360180e-03\n",
      "  7.6596820e-01]]\n",
      "[5 0 1 0 0 1 1 1 5 0 4 5 0 1 3 5 2 3 1 5 5 1 4 5 1 5 0 1 2 0 0 3 5 4 4 5 5\n",
      " 5 0 1 0 5 5 4 5 5 0 0 2 2 0 0 1 1 0 0 2 5 1 5 1 0 1 1 1 5 0 3 1 0 0 4 1 0\n",
      " 0 4 3 5 2 2 5 0 1 1 1 2 0 5 4 0 5 0 2 5 2 0 4 2 0 0 0 1 1 0 1 2 1 5 5 1 5\n",
      " 1 3 1 4 5 4 0 5 5 0 2 5 3 5 3 5 4 5 0 5 2 4 5 3 2 1 5 0 0 5 5 2 5 4 1 5 0\n",
      " 4 0 5 1 2 4 5 5 0 0 5 0 1 4 5 2 1 1 5 3 1 5 3 5 0 1 2 1 5 5 5 5 5 0 0 0 2\n",
      " 1 5 1 0 0 5 2 5 0 0 4 1 4 5 1 1 4 0 5 1 5 0 5 1 5 5 0 2 2 5 1 4 5 5 0 5 1\n",
      " 1 0 0 5 4 5 0 1 0 0 5 5 5 5 5 2 3 4 1 4 0 2 2 4 2 0 2 1 2 2 2 4 5 1 0 4 5\n",
      " 1 1 1 1 0 1 4 1 1 1 5 2 0 2 4 2 2 1 1 0 0 5 5 5 5 1 5 2 2 2 1 1 0 0 1 4 1\n",
      " 5 1 1 5 5 1 5 3 5 5 2 4 5 4 2 4 1 5 4 1 1 2 5 5 4 0 5 4 0 0 4 1 5 5 1 1 5\n",
      " 1 4 5 0 5 5 0 5 1 1 5 1 5 4 2 4 5 2 0 5 1 0 4 5 2 1 2 1 5 3 5 5 1 0 3 0 2\n",
      " 1 0 1 2 4 5 1 5 2 3 5 5 2 4 0 0 2 0 2 1 5 0 1 2 4 3 5 2 5 3 4 1 0 1 5 0 1\n",
      " 2 1 2 0 5 5 0 0 1 5 1 5 4 4 1 2 2 2 2 4 5 2 1 5 0 1 5 5 0 4 3 1 5 3 1 3 5\n",
      " 2 2 1 1 5 5 2 3 4 0 1 4 5 5 5 0 4 4 5 3 0 0 4 0 5 5 0 2 5 4 1 5 0 0 2 1 0\n",
      " 1 5 0 2 1 0 1 2 0 5 1 2 0 1 5 5 4 4 5 0 5 2 1 0 0 0 0 0 5 2 1 5 2 5 4 4 0\n",
      " 2 5 0 1 3 1 0 1 0 1 0 4 5 0 5 3 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[0 0 1 5 1 5 4 3 2 5 1 0 5 5 0 1 0 5 1 5 5 5 1 5 0 1 1 5 4 2 0 5 2 5 4 0 2\n",
      " 5 5 1 0 1 5 2 5 0 5 5 5 1 5 4 1 1 5 1 2 5 1 5 5 0 1 5 1 3 5 5 2 0 5 0 1 1\n",
      " 1 0 2 1 2 0 0 5 1 1 2 1 5 5 1 4 1 5 1 1 5 4 1 5 0 1 5 1 4 5 1 1 5 1 1 1 2\n",
      " 4 1 5 1 1 0 5 5 5 3 0 1 5 5 3 0 5 0 3 4 1 5 5 4 5 2 1 5 5 1 0 5 5 5 4 5 5\n",
      " 0 0 5 4 1 1 0 5 5 5 4 5 0 5 0 5 4 1 1 1 2 1 1 1 2 5 5 1 5 1 1 0 0 5 1 0 1\n",
      " 5 0 2 1 1 1 1 5 5 4 0 2 0 5 5 0 0 3 1 3 5 0 5 2 0 5 5 5 5 3 1 5 1 5 1 1 5\n",
      " 5 1 2 5 0 5 1 5 1 5 0 5 4 1 1 1 3 1 5 1 1 0 2 5 0 3 1 3 5 5 0 2 1 2 0 1 5\n",
      " 1 1 0 0 1 5 1 1 2 1 5 3 1 5 5 1 5 5 1 5 1 4 1 3 5 5 5 5 0 2 5 5 3 1 1 2 1\n",
      " 1 4 5 5 0 1 5 5 1 2 0 1 1 5 1 5 0 2 5 1 1 5 1 0 1 1 0 5 5 0 3 1 1 1 5 5 3\n",
      " 2 5 5 5 1 0 1 1 5 5 5 1 4 4 5 4 5 1 5 2 1 2 1 5 1 0 1 1 2 0 5 1 5 1 3 0 4\n",
      " 1 2 5 0 5 0 1 5 0 1 5 1 1 0 5 3 4 1 5 2 0 0 1 1 2 0 5 1 0 5 5 1 0 2 5 5 0\n",
      " 1 1 1 4 0 1 5 1 1 1 2 5 1 1 1 0 5 5 5 1 5 5 1 5 5 1 5 5 1 1 1 5 5 3 1 1 1\n",
      " 2 1 1 1 2 5 4 4 1 0 4 4 0 1 5 2 2 5 5 1 4 4 5 0 1 1 5 2 5 0 5 3 2 5 1 1 1\n",
      " 1 3 5 1 5 5 5 4 1 3 2 1 1 5 5 3 5 0 5 0 1 4 1 5 1 1 2 0 2 5 5 1 1 1 0 5 5\n",
      " 1 5 1 5 5 5 5 1 5 0 0 5 5 0 1 4 1 5 1 5 5 5 5 2 0 4 5 0 0 5 1 2 0 0 1 0 1\n",
      " 2 2 0 0 4 0 5 1 5 1 1 1 1 0 5 4 1 5 0 5 4 1 2 2 1 1 2 5 5 2 0 0 5 0 1 2 5\n",
      " 0 2 1 1 1 1 4 4 4 5 1 5 5 1 0 5 4 4 0 4 1 5 5 4 5 0 4 1 5 1 0 5 1 0 0 4 5\n",
      " 1 1 5 5 4 1 4 1 1 5 5 2 0 1 2 5 4 1 1 4 5 5 4 1 5 0 0 5 2 2 4 5 5 4 5 1 1\n",
      " 5 5 0 5 5 1 0 1 5 1 0 1 2 1 4 3 1 1 0 5 3 5 3 3 4 3 0 1 4 5 0 1 4 3 3 0 1\n",
      " 3 0 1 4 3 5 2 1 0 1 1 1 4 3 3 2 1 3 4 3 5 5 0 1 1 5 1 5 2 0 4 1 1 3 3 3 3\n",
      " 1 4 3 4 3 4 3 5 4 4 5 1 3 1 4 1 3 4 5 2 4 4 1 3 4 4 4 0 2 1 5 2 0 5 1 5 4\n",
      " 4 1 5 1 1 5 5 5 3 3 5 1 1 5 4 0 1 5 4 4 1 1 1 1 0 0 5 5 4 2 0 1 1 1 0 1 2\n",
      " 0 1 4 1 1 1 2 2 0 0 0 3 1 1 0 0 1 0 1 0 1 2 5 1 0 4 5 0 4 1 0 1 2 4 4 0 3\n",
      " 5 5 1 5 0 5 1 0 0 0 1 2 3 3 1 1 1 0 0 2 4 4 0 5 0 2 5 0 0 4 0 4 4 4 2 4 5]\n",
      "Accuracy: 0.22522522522522523\n",
      "Precision: 0.2548833729951647\n",
      "Recall: 0.22522522522522523\n",
      "F1 score: 0.21438634660691458\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=20, verbose=1)\n",
    "# evaluate the model\n",
    "evaluate(testy, model.predict(testX))#, show_cm=True)\n",
    "#evaluate(trainy, model.predict(trainX))#, show_cm=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
