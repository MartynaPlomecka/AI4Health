{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YxOz-zNNlyy"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import uniform\n",
    "from numpy import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter,filterwarnings\n",
    "\n",
    "# ignore all future warnings1\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "    if \"anuja\" in os.environ.get('USER'):\n",
    "        DATA_DIR = 'data/'\n",
    "    #elif \"martyna\" in os.environv.get('USER'):\n",
    "    #    DATA_DIR = '/home/ubuntu/Martyna/repo/AI4Health/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Martyna  \n",
    "DATA_DIR = '/home/ubuntu/Martyna/repo/AI4Health/DATAfoof/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG data and foof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.610769</td>\n",
       "      <td>1.793923</td>\n",
       "      <td>1.639958</td>\n",
       "      <td>1.803579</td>\n",
       "      <td>1.622763</td>\n",
       "      <td>1.867163</td>\n",
       "      <td>1.596286</td>\n",
       "      <td>1.868653</td>\n",
       "      <td>1.459489</td>\n",
       "      <td>1.880624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637747</td>\n",
       "      <td>1.472414</td>\n",
       "      <td>1.775967</td>\n",
       "      <td>1.534612</td>\n",
       "      <td>1.803604</td>\n",
       "      <td>1.575800</td>\n",
       "      <td>1.869977</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.572269</td>\n",
       "      <td>1.762184</td>\n",
       "      <td>1.615888</td>\n",
       "      <td>1.938907</td>\n",
       "      <td>1.515331</td>\n",
       "      <td>1.878222</td>\n",
       "      <td>1.577389</td>\n",
       "      <td>1.888830</td>\n",
       "      <td>1.645799</td>\n",
       "      <td>1.892993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.698141</td>\n",
       "      <td>1.698537</td>\n",
       "      <td>1.854421</td>\n",
       "      <td>1.486611</td>\n",
       "      <td>1.755794</td>\n",
       "      <td>1.517099</td>\n",
       "      <td>1.845983</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.414507</td>\n",
       "      <td>1.818785</td>\n",
       "      <td>1.504383</td>\n",
       "      <td>1.902537</td>\n",
       "      <td>1.563395</td>\n",
       "      <td>1.936381</td>\n",
       "      <td>1.554663</td>\n",
       "      <td>2.085351</td>\n",
       "      <td>1.566065</td>\n",
       "      <td>2.106747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.847331</td>\n",
       "      <td>1.417519</td>\n",
       "      <td>1.869143</td>\n",
       "      <td>1.323095</td>\n",
       "      <td>1.838333</td>\n",
       "      <td>1.496008</td>\n",
       "      <td>1.895424</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561062</td>\n",
       "      <td>1.068994</td>\n",
       "      <td>0.333554</td>\n",
       "      <td>0.991180</td>\n",
       "      <td>0.555779</td>\n",
       "      <td>1.304169</td>\n",
       "      <td>0.665864</td>\n",
       "      <td>1.491464</td>\n",
       "      <td>0.524828</td>\n",
       "      <td>1.573271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.464311</td>\n",
       "      <td>0.576556</td>\n",
       "      <td>1.265274</td>\n",
       "      <td>0.199181</td>\n",
       "      <td>0.863242</td>\n",
       "      <td>0.246682</td>\n",
       "      <td>1.010393</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.262007</td>\n",
       "      <td>1.901401</td>\n",
       "      <td>1.305927</td>\n",
       "      <td>1.924721</td>\n",
       "      <td>1.293914</td>\n",
       "      <td>1.924840</td>\n",
       "      <td>1.226456</td>\n",
       "      <td>1.947274</td>\n",
       "      <td>0.818595</td>\n",
       "      <td>1.905113</td>\n",
       "      <td>...</td>\n",
       "      <td>1.859064</td>\n",
       "      <td>1.158560</td>\n",
       "      <td>1.863190</td>\n",
       "      <td>1.173287</td>\n",
       "      <td>1.773532</td>\n",
       "      <td>1.252168</td>\n",
       "      <td>1.878925</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>0.648706</td>\n",
       "      <td>1.508826</td>\n",
       "      <td>0.591809</td>\n",
       "      <td>1.640814</td>\n",
       "      <td>0.640782</td>\n",
       "      <td>1.665891</td>\n",
       "      <td>0.455759</td>\n",
       "      <td>1.679019</td>\n",
       "      <td>0.866016</td>\n",
       "      <td>1.786340</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536850</td>\n",
       "      <td>0.528776</td>\n",
       "      <td>1.478037</td>\n",
       "      <td>0.466827</td>\n",
       "      <td>1.767683</td>\n",
       "      <td>0.570274</td>\n",
       "      <td>1.664126</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.332278</td>\n",
       "      <td>1.729382</td>\n",
       "      <td>1.387863</td>\n",
       "      <td>1.788208</td>\n",
       "      <td>1.452167</td>\n",
       "      <td>1.841329</td>\n",
       "      <td>1.524229</td>\n",
       "      <td>1.976239</td>\n",
       "      <td>1.480653</td>\n",
       "      <td>2.022584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.876485</td>\n",
       "      <td>1.214977</td>\n",
       "      <td>1.795080</td>\n",
       "      <td>1.456392</td>\n",
       "      <td>1.835807</td>\n",
       "      <td>1.399127</td>\n",
       "      <td>1.795906</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>0.746123</td>\n",
       "      <td>1.324138</td>\n",
       "      <td>0.653335</td>\n",
       "      <td>1.285734</td>\n",
       "      <td>0.564490</td>\n",
       "      <td>1.271931</td>\n",
       "      <td>0.375903</td>\n",
       "      <td>1.245331</td>\n",
       "      <td>0.258508</td>\n",
       "      <td>1.206112</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307891</td>\n",
       "      <td>0.691917</td>\n",
       "      <td>1.310004</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>1.283587</td>\n",
       "      <td>0.564744</td>\n",
       "      <td>1.273098</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>0.976055</td>\n",
       "      <td>1.441830</td>\n",
       "      <td>0.823197</td>\n",
       "      <td>1.407064</td>\n",
       "      <td>0.879368</td>\n",
       "      <td>1.464799</td>\n",
       "      <td>0.902699</td>\n",
       "      <td>1.512205</td>\n",
       "      <td>1.012450</td>\n",
       "      <td>1.505105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341166</td>\n",
       "      <td>0.598687</td>\n",
       "      <td>1.282644</td>\n",
       "      <td>0.697733</td>\n",
       "      <td>1.421177</td>\n",
       "      <td>0.753861</td>\n",
       "      <td>1.457204</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>1.446742</td>\n",
       "      <td>1.836616</td>\n",
       "      <td>1.472051</td>\n",
       "      <td>1.879054</td>\n",
       "      <td>1.057873</td>\n",
       "      <td>1.842461</td>\n",
       "      <td>0.877576</td>\n",
       "      <td>1.860347</td>\n",
       "      <td>0.527547</td>\n",
       "      <td>1.858452</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568499</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>1.667971</td>\n",
       "      <td>1.240605</td>\n",
       "      <td>1.815564</td>\n",
       "      <td>1.222354</td>\n",
       "      <td>1.859915</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     1.610769  1.793923  1.639958  1.803579  1.622763  1.867163  1.596286   \n",
       "1     1.572269  1.762184  1.615888  1.938907  1.515331  1.878222  1.577389   \n",
       "2     1.414507  1.818785  1.504383  1.902537  1.563395  1.936381  1.554663   \n",
       "3     0.561062  1.068994  0.333554  0.991180  0.555779  1.304169  0.665864   \n",
       "4     1.262007  1.901401  1.305927  1.924721  1.293914  1.924840  1.226456   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2037  0.648706  1.508826  0.591809  1.640814  0.640782  1.665891  0.455759   \n",
       "2038  1.332278  1.729382  1.387863  1.788208  1.452167  1.841329  1.524229   \n",
       "2039  0.746123  1.324138  0.653335  1.285734  0.564490  1.271931  0.375903   \n",
       "2040  0.976055  1.441830  0.823197  1.407064  0.879368  1.464799  0.902699   \n",
       "2041  1.446742  1.836616  1.472051  1.879054  1.057873  1.842461  0.877576   \n",
       "\n",
       "             7         8         9  ...       201       202       203  \\\n",
       "0     1.868653  1.459489  1.880624  ...  1.637747  1.472414  1.775967   \n",
       "1     1.888830  1.645799  1.892993  ...  1.698141  1.698537  1.854421   \n",
       "2     2.085351  1.566065  2.106747  ...  1.847331  1.417519  1.869143   \n",
       "3     1.491464  0.524828  1.573271  ...  1.464311  0.576556  1.265274   \n",
       "4     1.947274  0.818595  1.905113  ...  1.859064  1.158560  1.863190   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2037  1.679019  0.866016  1.786340  ...  1.536850  0.528776  1.478037   \n",
       "2038  1.976239  1.480653  2.022584  ...  1.876485  1.214977  1.795080   \n",
       "2039  1.245331  0.258508  1.206112  ...  1.307891  0.691917  1.310004   \n",
       "2040  1.512205  1.012450  1.505105  ...  1.341166  0.598687  1.282644   \n",
       "2041  1.860347  0.527547  1.858452  ...  1.568499  0.980918  1.667971   \n",
       "\n",
       "           204       205       206       207       208       209           IDs  \n",
       "0     1.534612  1.803604  1.575800  1.869977  0.986272  1.825774  NDARAA075AMK  \n",
       "1     1.486611  1.755794  1.517099  1.845983  1.486650  1.888544  NDARAA112DMH  \n",
       "2     1.323095  1.838333  1.496008  1.895424  1.593155  2.095749  NDARAA117NEJ  \n",
       "3     0.199181  0.863242  0.246682  1.010393  0.703331  1.724831  NDARAA947ZG5  \n",
       "4     1.173287  1.773532  1.252168  1.878925  0.918020  1.749441  NDARAA948VFH  \n",
       "...        ...       ...       ...       ...       ...       ...           ...  \n",
       "2037  0.466827  1.767683  0.570274  1.664126  1.351549  1.996940  NDARZN277NR6  \n",
       "2038  1.456392  1.835807  1.399127  1.795906  1.380795  2.036327  NDARZN578YDP  \n",
       "2039  0.604437  1.283587  0.564744  1.273098  0.339229  1.050644  NDARZN610GTY  \n",
       "2040  0.697733  1.421177  0.753861  1.457204  0.781225  1.470061  NDARZN677EYE  \n",
       "2041  1.240605  1.815564  1.222354  1.859915  0.464107  1.664433  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 211 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data loading\n",
    "data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "foof = pd.read_csv(DATA_DIR+\"sensor_intercept_slope.csv\")\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 105, 79)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening\n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "df = np.array(df)\n",
    "df = df.reshape(data['x'].shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8286</th>\n",
       "      <th>8287</th>\n",
       "      <th>8288</th>\n",
       "      <th>8289</th>\n",
       "      <th>8290</th>\n",
       "      <th>8291</th>\n",
       "      <th>8292</th>\n",
       "      <th>8293</th>\n",
       "      <th>8294</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.707834e-12</td>\n",
       "      <td>1.512286e-10</td>\n",
       "      <td>2.475735e-09</td>\n",
       "      <td>3.453763e-08</td>\n",
       "      <td>4.554996e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>...</td>\n",
       "      <td>2.990881e-09</td>\n",
       "      <td>1.223086e-09</td>\n",
       "      <td>4.893694e-10</td>\n",
       "      <td>1.915752e-10</td>\n",
       "      <td>7.337775e-11</td>\n",
       "      <td>2.749867e-11</td>\n",
       "      <td>1.008282e-11</td>\n",
       "      <td>3.617107e-12</td>\n",
       "      <td>1.269651e-12</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.798713e-02</td>\n",
       "      <td>1.639433e-01</td>\n",
       "      <td>2.897591e-01</td>\n",
       "      <td>2.097609e-01</td>\n",
       "      <td>6.347556e-02</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.105298</td>\n",
       "      <td>0.184513</td>\n",
       "      <td>0.130638</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>...</td>\n",
       "      <td>5.835291e-06</td>\n",
       "      <td>1.856717e-06</td>\n",
       "      <td>5.922864e-07</td>\n",
       "      <td>1.928109e-07</td>\n",
       "      <td>6.449918e-08</td>\n",
       "      <td>2.204650e-08</td>\n",
       "      <td>7.598678e-09</td>\n",
       "      <td>2.604260e-09</td>\n",
       "      <td>8.780452e-10</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.104310e-06</td>\n",
       "      <td>4.299647e-05</td>\n",
       "      <td>5.644195e-04</td>\n",
       "      <td>4.760137e-03</td>\n",
       "      <td>2.579253e-02</td>\n",
       "      <td>0.089799</td>\n",
       "      <td>0.201005</td>\n",
       "      <td>0.290260</td>\n",
       "      <td>0.276177</td>\n",
       "      <td>0.196151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.332064e-07</td>\n",
       "      <td>5.270957e-08</td>\n",
       "      <td>2.026971e-08</td>\n",
       "      <td>7.575282e-09</td>\n",
       "      <td>2.751336e-09</td>\n",
       "      <td>9.711398e-10</td>\n",
       "      <td>3.331297e-10</td>\n",
       "      <td>1.110552e-10</td>\n",
       "      <td>3.597966e-11</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.692639e-01</td>\n",
       "      <td>2.021357e-01</td>\n",
       "      <td>2.273063e-01</td>\n",
       "      <td>2.406964e-01</td>\n",
       "      <td>2.400039e-01</td>\n",
       "      <td>0.225430</td>\n",
       "      <td>0.202278</td>\n",
       "      <td>0.198154</td>\n",
       "      <td>0.228356</td>\n",
       "      <td>0.181836</td>\n",
       "      <td>...</td>\n",
       "      <td>8.323825e-02</td>\n",
       "      <td>7.759521e-02</td>\n",
       "      <td>7.183415e-02</td>\n",
       "      <td>6.604061e-02</td>\n",
       "      <td>6.029416e-02</td>\n",
       "      <td>5.466678e-02</td>\n",
       "      <td>4.922161e-02</td>\n",
       "      <td>4.401211e-02</td>\n",
       "      <td>3.908162e-02</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.332328e-06</td>\n",
       "      <td>1.552379e-04</td>\n",
       "      <td>1.804338e-03</td>\n",
       "      <td>1.287033e-02</td>\n",
       "      <td>5.615280e-02</td>\n",
       "      <td>0.149809</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>0.247738</td>\n",
       "      <td>0.163687</td>\n",
       "      <td>0.094061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>8.241315e-06</td>\n",
       "      <td>2.938160e-04</td>\n",
       "      <td>4.641777e-03</td>\n",
       "      <td>3.249546e-02</td>\n",
       "      <td>1.008094e-01</td>\n",
       "      <td>0.138615</td>\n",
       "      <td>0.084707</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>...</td>\n",
       "      <td>5.852474e-03</td>\n",
       "      <td>4.262113e-03</td>\n",
       "      <td>3.068545e-03</td>\n",
       "      <td>2.184048e-03</td>\n",
       "      <td>1.536788e-03</td>\n",
       "      <td>1.069025e-03</td>\n",
       "      <td>7.351630e-04</td>\n",
       "      <td>4.998062e-04</td>\n",
       "      <td>3.359246e-04</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>8.113400e-03</td>\n",
       "      <td>1.005675e-02</td>\n",
       "      <td>1.237930e-02</td>\n",
       "      <td>1.513279e-02</td>\n",
       "      <td>1.837070e-02</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.037230</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>...</td>\n",
       "      <td>5.855173e-04</td>\n",
       "      <td>3.933072e-04</td>\n",
       "      <td>2.601868e-04</td>\n",
       "      <td>1.695084e-04</td>\n",
       "      <td>1.087534e-04</td>\n",
       "      <td>6.871244e-05</td>\n",
       "      <td>4.275280e-05</td>\n",
       "      <td>2.619553e-05</td>\n",
       "      <td>1.580597e-05</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>5.472767e-03</td>\n",
       "      <td>8.816325e-03</td>\n",
       "      <td>1.629356e-02</td>\n",
       "      <td>3.226822e-02</td>\n",
       "      <td>6.212373e-02</td>\n",
       "      <td>0.108594</td>\n",
       "      <td>0.166461</td>\n",
       "      <td>0.220594</td>\n",
       "      <td>0.252412</td>\n",
       "      <td>0.252807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>2.658455e-03</td>\n",
       "      <td>5.749806e-03</td>\n",
       "      <td>1.180538e-02</td>\n",
       "      <td>2.300961e-02</td>\n",
       "      <td>4.257369e-02</td>\n",
       "      <td>0.074778</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.197358</td>\n",
       "      <td>0.296551</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>...</td>\n",
       "      <td>3.676327e-04</td>\n",
       "      <td>1.925477e-04</td>\n",
       "      <td>9.805386e-05</td>\n",
       "      <td>4.855040e-05</td>\n",
       "      <td>2.337344e-05</td>\n",
       "      <td>1.094093e-05</td>\n",
       "      <td>4.979521e-06</td>\n",
       "      <td>2.203549e-06</td>\n",
       "      <td>9.481114e-07</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>4.856385e-04</td>\n",
       "      <td>3.048976e-03</td>\n",
       "      <td>1.546836e-02</td>\n",
       "      <td>5.645783e-02</td>\n",
       "      <td>1.419824e-01</td>\n",
       "      <td>0.245335</td>\n",
       "      <td>0.301591</td>\n",
       "      <td>0.291822</td>\n",
       "      <td>0.267454</td>\n",
       "      <td>0.265932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 8296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4  \\\n",
       "0     7.707834e-12  1.512286e-10  2.475735e-09  3.453763e-08  4.554996e-07   \n",
       "1     3.798713e-02  1.639433e-01  2.897591e-01  2.097609e-01  6.347556e-02   \n",
       "2     2.104310e-06  4.299647e-05  5.644195e-04  4.760137e-03  2.579253e-02   \n",
       "3     1.692639e-01  2.021357e-01  2.273063e-01  2.406964e-01  2.400039e-01   \n",
       "4     8.332328e-06  1.552379e-04  1.804338e-03  1.287033e-02  5.615280e-02   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2037  8.241315e-06  2.938160e-04  4.641777e-03  3.249546e-02  1.008094e-01   \n",
       "2038  8.113400e-03  1.005675e-02  1.237930e-02  1.513279e-02  1.837070e-02   \n",
       "2039  5.472767e-03  8.816325e-03  1.629356e-02  3.226822e-02  6.212373e-02   \n",
       "2040  2.658455e-03  5.749806e-03  1.180538e-02  2.300961e-02  4.257369e-02   \n",
       "2041  4.856385e-04  3.048976e-03  1.546836e-02  5.645783e-02  1.419824e-01   \n",
       "\n",
       "             5         6         7         8         9  ...          8286  \\\n",
       "0     0.000007  0.000109  0.001314  0.009992  0.045200  ...  2.990881e-09   \n",
       "1     0.027758  0.105298  0.184513  0.130638  0.163258  ...  5.835291e-06   \n",
       "2     0.089799  0.201005  0.290260  0.276177  0.196151  ...  1.332064e-07   \n",
       "3     0.225430  0.202278  0.198154  0.228356  0.181836  ...  8.323825e-02   \n",
       "4     0.149809  0.244887  0.247738  0.163687  0.094061  ...  0.000000e+00   \n",
       "...        ...       ...       ...       ...       ...  ...           ...   \n",
       "2037  0.138615  0.084707  0.024339  0.009157  0.021386  ...  5.852474e-03   \n",
       "2038  0.022147  0.026515  0.031525  0.037230  0.043721  ...  5.855173e-04   \n",
       "2039  0.108594  0.166461  0.220594  0.252412  0.252807  ...  0.000000e+00   \n",
       "2040  0.074778  0.124685  0.197358  0.296551  0.423009  ...  3.676327e-04   \n",
       "2041  0.245335  0.301591  0.291822  0.267454  0.265932  ...  0.000000e+00   \n",
       "\n",
       "              8287          8288          8289          8290          8291  \\\n",
       "0     1.223086e-09  4.893694e-10  1.915752e-10  7.337775e-11  2.749867e-11   \n",
       "1     1.856717e-06  5.922864e-07  1.928109e-07  6.449918e-08  2.204650e-08   \n",
       "2     5.270957e-08  2.026971e-08  7.575282e-09  2.751336e-09  9.711398e-10   \n",
       "3     7.759521e-02  7.183415e-02  6.604061e-02  6.029416e-02  5.466678e-02   \n",
       "4     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2037  4.262113e-03  3.068545e-03  2.184048e-03  1.536788e-03  1.069025e-03   \n",
       "2038  3.933072e-04  2.601868e-04  1.695084e-04  1.087534e-04  6.871244e-05   \n",
       "2039  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2040  1.925477e-04  9.805386e-05  4.855040e-05  2.337344e-05  1.094093e-05   \n",
       "2041  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "              8292          8293          8294           IDs  \n",
       "0     1.008282e-11  3.617107e-12  1.269651e-12  NDARAA075AMK  \n",
       "1     7.598678e-09  2.604260e-09  8.780452e-10  NDARAA112DMH  \n",
       "2     3.331297e-10  1.110552e-10  3.597966e-11  NDARAA117NEJ  \n",
       "3     4.922161e-02  4.401211e-02  3.908162e-02  NDARAA947ZG5  \n",
       "4     0.000000e+00  0.000000e+00  0.000000e+00  NDARAA948VFH  \n",
       "...            ...           ...           ...           ...  \n",
       "2037  7.351630e-04  4.998062e-04  3.359246e-04  NDARZN277NR6  \n",
       "2038  4.275280e-05  2.619553e-05  1.580597e-05  NDARZN578YDP  \n",
       "2039  0.000000e+00  0.000000e+00  0.000000e+00  NDARZN610GTY  \n",
       "2040  4.979521e-06  2.203549e-06  9.481114e-07  NDARZN677EYE  \n",
       "2041  0.000000e+00  0.000000e+00  0.000000e+00  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 8296 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YjKzrOY5dKO"
   },
   "source": [
    "## Behavioral Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bFK75cJgWc2G",
    "outputId": "c35c8bfc-2242-43be-aada-379d1ccb4c7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
       "       'SWAN_Avg', 'SCARED_SR_GD', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
       "       'WISC_VCI_Sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_data = pd.read_csv(DATA_DIR+'AllData.csv')\n",
    "behaviour_data = behaviour_data.rename(columns = {'EID': 'IDs'}, inplace = False)\n",
    "behaviour_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2579, 8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviour_data = behaviour_data[['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    " 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "       'WISC_VCI_Sum']]\n",
    "behaviour_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 8 columns (with column 'IDs').\n",
      "There are 7 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WISC_WMI_Sum</th>\n",
       "      <td>712</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WISC_VCI_Sum</th>\n",
       "      <td>702</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCARED_P_GD</th>\n",
       "      <td>576</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRS_SCI_T</th>\n",
       "      <td>448</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRS_RRB_T</th>\n",
       "      <td>447</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWAN_IN_Avg</th>\n",
       "      <td>385</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWAN_HY_Avg</th>\n",
       "      <td>385</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  % of Total Values\n",
       "WISC_WMI_Sum             712               27.6\n",
       "WISC_VCI_Sum             702               27.2\n",
       "SCARED_P_GD              576               22.3\n",
       "SRS_SCI_T                448               17.4\n",
       "SRS_RRB_T                447               17.3\n",
       "SWAN_IN_Avg              385               14.9\n",
       "SWAN_HY_Avg              385               14.9"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns (with column 'IDs').\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_values_table(behaviour_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge EEG and foof data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2042, 8506)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(df, foof, on='IDs', how='inner')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and then with the behaviorals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 8513)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(data, behaviour_data, on='IDs', how='inner')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features and labels preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 8513)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing NaNs\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1075, 8511)\n"
     ]
    }
   ],
   "source": [
    "#labels_list = ['WISC_VCI_Sum']#gowno\n",
    "labels_list = ['WISC_WMI_Sum']#gowno\n",
    "#labels_list = ['SWAN_HY_Avg'] #ok\n",
    "#labels_list = ['SWAN_IN_Avg'] #ok\n",
    "#labels_list = [ 'SRS_SCI_T'] #ok\n",
    "#labels_list = ['SCARED_P_GD'] #gowno so soo\n",
    "#labels_list = [ 'SRS_RRB_T'] #ok\n",
    "X = df[df.columns.difference(['IDs']+labels_list)]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1075, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = df[labels_list]\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806, 8511) (269, 8511)\n",
      "Applying PCA...\n",
      "(806, 206) (269, 206)\n"
     ]
    }
   ],
   "source": [
    "# scaling x\n",
    "norm = preprocessing.MinMaxScaler().fit(xtrain)\n",
    "\n",
    "# transform training data\n",
    "xtrain = norm.transform(xtrain)\n",
    "xtest = norm.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "\n",
    "print('Applying PCA...')\n",
    "pca = PCA(.95) # 95% variance retained\n",
    "pca.fit(xtrain)\n",
    "\n",
    "# transform data\n",
    "xtrain = pca.transform(xtrain)\n",
    "xtest = pca.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(806, 1) (269, 1)\n"
     ]
    }
   ],
   "source": [
    "# scaling y\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(ytrain)\n",
    "ytrain = min_max_scaler.transform(ytrain)\n",
    "ytest = min_max_scaler.transform(ytest)\n",
    "\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46978308])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMMY BASELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy regressors (to obtain the random baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (dummy): 0.03\n",
      "Mean abs error (dummy): 0.13\n",
      "Median absolute error (dummy): 0.10\n",
      "r2_score (dummy mean): -0.00\n",
      "r2_score (dummy median): -0.02\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(xtrain, ytrain)\n",
    "lm_dummy_median = DummyRegressor(strategy = 'median').fit(xtrain, ytrain)\n",
    "ypred_dummy_mean = lm_dummy_mean.predict(xtest)\n",
    "ypred_dummy_median = lm_dummy_median.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
    "\n",
    "\n",
    "print(\"Mean abs error (dummy): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
    "\n",
    "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_median)))\n",
    "\n",
    "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(ytest, ypred_dummy_mean)))\n",
    "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(ytest, ypred_dummy_median)))\n",
    "\n",
    "#print(ytest[:10])\n",
    "#print(ytest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.DataFrame(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1516420/3646136744.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(xtrain.values, ytrain)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (raandfor): 0.03\n",
      "Mean absolute error (randfor): 0.13\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 200, got 206",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1516420/3646136744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m print(\"Mean absolute error (randfor): {:.2f}\".format(mean_absolute_error(ytest,\n\u001b[1;32m     12\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R2 score (randfor): {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m    882\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2016\u001b[0m                 )\n\u001b[1;32m   2017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2019\u001b[0m                     \u001b[0;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m                     \u001b[0;34mf\"got {data.shape[1]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 200, got 206"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "# fit the model on the whole dataset\n",
    "rf.fit(xtrain.values, ytrain)\n",
    "ypred = rf.predict(xtest)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean squared error (raandfor): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (randfor): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (randfor): {:.2f}\".format(xgb.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (xgb): 0.03\n",
      "Mean absolute error (xgb): 0.14\n",
      "R2 score (xgb): -0.17\n"
     ]
    }
   ],
   "source": [
    "# gradient xgboost for making predictions for regression\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "# define dataset\n",
    "# define the model\n",
    "xgb = XGBRegressor()\n",
    "# fit the model on the whole dataset\n",
    "xgb.fit(xtrain.values, ytrain)\n",
    "ypred = xgb.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (xgb): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (xgb): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (xgb): {:.2f}\".format(xgb.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (ada): 0.03\n",
      "Mean absolute error (ada): 0.13\n",
      "R2 score (ada): -0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "regr.fit(xtrain,ytrain)\n",
    "AdaBoostRegressor(n_estimators=100, random_state=0)\n",
    "ypred = regr.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (ada): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (ada): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (ada): {:.2f}\".format(regr.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (elastic): 0.03\n",
      "Mean absolute error (elastic): 0.13\n",
      "R2 score (elastic): -0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "regr = ElasticNet(random_state=0)\n",
    "regr.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = regr.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (elastic): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (elastic): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (elastic): {:.2f}\".format(regr.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## robust regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (ransac)): 0.03\n",
      "Mean absolute error (ransac): 0.13\n",
      "R2 score (ransac): -0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "# Set RANSAC hyperparameters\n",
    "ransac = RANSACRegressor(LinearRegression(),\n",
    "\t\tmax_trials=4, \t\t# Number of Iterations\n",
    "\t\tmin_samples=2, \t\t# Minimum size of the sample\n",
    "\t\tloss='absolute_loss', \t# Metrics for loss\n",
    "\t\tresidual_threshold=10 \t# Threshold\n",
    "\t\t)\n",
    "\n",
    "# Train model\n",
    "ransac.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = ransac.predict(xtest)\n",
    "\n",
    "print(\"Mean squared error (ransac)): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (ransac): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (ransac): {:.2f}\".format(ransac.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (svr): 0.03\n",
      "Mean absolute error (svr): 0.13\n",
      "R2 score (svr): -0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Create the SVR regressor\n",
    "svr = SVR(epsilon=0.1)\n",
    "#Create the Multioutput Regressor\n",
    "mor = MultiOutputRegressor(svr)\n",
    "# Train the regressor\n",
    "mor = mor.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = mor.predict(xtest)\n",
    "print(\"Mean squared error (svr): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (svr): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (svr): {:.2f}\".format(mor.score(xtest, ytest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (linreg): 0.03\n",
      "Mean absolute error (linreg): 0.13\n",
      "R2 score (linreg): -0.13\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "# Generate predictions for testing data\n",
    "ypred = model.predict(xtest)\n",
    "print(\"Mean squared error (linreg): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "print(\"Mean absolute error (linreg): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "print(\"R2 score (linreg): {:.2f}\".format(model.score(xtest, ytest)))\t\t\t\t\t\t\t\t\t\t\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DataScienceLab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
