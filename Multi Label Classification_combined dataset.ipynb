{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Electrode 105 - 31/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 32/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 33/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 34/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 35/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 36/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 37/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 38/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 39/2 Hz,)</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.333844e-07</td>\n",
       "      <td>9.373567e-08</td>\n",
       "      <td>1.616373e-08</td>\n",
       "      <td>3.256580e-09</td>\n",
       "      <td>4.986456e-10</td>\n",
       "      <td>7.457518e-11</td>\n",
       "      <td>1.130004e-11</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>2.352137e-03</td>\n",
       "      <td>4.122513e-04</td>\n",
       "      <td>4.825197e-05</td>\n",
       "      <td>5.944433e-06</td>\n",
       "      <td>5.749150e-07</td>\n",
       "      <td>6.398086e-08</td>\n",
       "      <td>8.415637e-09</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.045964e-05</td>\n",
       "      <td>4.443460e-06</td>\n",
       "      <td>7.491343e-07</td>\n",
       "      <td>1.436770e-07</td>\n",
       "      <td>2.039047e-08</td>\n",
       "      <td>2.751924e-09</td>\n",
       "      <td>3.663748e-10</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>1.580043e-01</td>\n",
       "      <td>1.518115e-01</td>\n",
       "      <td>1.233778e-01</td>\n",
       "      <td>1.242931e-01</td>\n",
       "      <td>1.009636e-01</td>\n",
       "      <td>8.498748e-02</td>\n",
       "      <td>7.690149e-02</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093399</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>4.012462e-02</td>\n",
       "      <td>2.464919e-02</td>\n",
       "      <td>1.257993e-02</td>\n",
       "      <td>7.816617e-03</td>\n",
       "      <td>3.846395e-03</td>\n",
       "      <td>1.926406e-03</td>\n",
       "      <td>1.018633e-03</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.385606e-02</td>\n",
       "      <td>2.124126e-02</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.222227</td>\n",
       "      <td>0.444972</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>5.877454e-03</td>\n",
       "      <td>3.190797e-03</td>\n",
       "      <td>1.418509e-03</td>\n",
       "      <td>7.564419e-04</td>\n",
       "      <td>3.146594e-04</td>\n",
       "      <td>1.311957e-04</td>\n",
       "      <td>5.687030e-05</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1.089647e-02</td>\n",
       "      <td>3.749309e-02</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>0.413368</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>1.169173e-02</td>\n",
       "      <td>4.410850e-03</td>\n",
       "      <td>1.294309e-03</td>\n",
       "      <td>4.329110e-04</td>\n",
       "      <td>1.073561e-04</td>\n",
       "      <td>2.536768e-05</td>\n",
       "      <td>5.924775e-06</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2.695401e-03</td>\n",
       "      <td>5.553206e-02</td>\n",
       "      <td>0.315364</td>\n",
       "      <td>0.444302</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.232912</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "2037             2.303407e-04             2.867255e-02   \n",
       "2038             1.385606e-02             2.124126e-02   \n",
       "2039             1.089647e-02             3.749309e-02   \n",
       "2040             6.411911e-03             2.687961e-02   \n",
       "2041             2.695401e-03             5.553206e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                    0.000006                 0.001066   \n",
       "1                    0.074284                 0.216988   \n",
       "2                    0.094118                 0.367821   \n",
       "3                    0.378969                 0.299813   \n",
       "4                    0.167700                 0.368840   \n",
       "...                       ...                      ...   \n",
       "2037                 0.194945                 0.081646   \n",
       "2038                 0.032991                 0.043456   \n",
       "2039                 0.139003                 0.289797   \n",
       "2040                 0.095551                 0.241121   \n",
       "2041                 0.315364                 0.444302   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "2037                 0.018422                 0.076959   \n",
       "2038                 0.048827                 0.049759   \n",
       "2039                 0.304728                 0.196113   \n",
       "2040                 0.434011                 0.574767   \n",
       "2041                 0.321718                 0.232912   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "2037                 0.179779                 0.300051   \n",
       "2038                 0.074988                 0.222227   \n",
       "2039                 0.191950                 0.342653   \n",
       "2040                 0.694741                 0.815939   \n",
       "2041                 0.152557                 0.178452   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
       "0                    0.593581                  0.401686  ...   \n",
       "1                    0.049898                  0.004720  ...   \n",
       "2                    0.526883                  0.511715  ...   \n",
       "3                    0.003988                  0.061608  ...   \n",
       "4                    0.233210                  0.125520  ...   \n",
       "...                       ...                       ...  ...   \n",
       "2037                 0.417245                  0.459853  ...   \n",
       "2038                 0.444972                  0.464653  ...   \n",
       "2039                 0.413368                  0.344024  ...   \n",
       "2040                 0.678021                  0.490314  ...   \n",
       "2041                 0.289553                  0.280580  ...   \n",
       "\n",
       "      (Electrode 105 - 31/2 Hz,)  (Electrode 105 - 32/2 Hz,)  \\\n",
       "0                       0.000007                    0.000002   \n",
       "1                       0.031636                    0.009416   \n",
       "2                       0.000311                    0.000079   \n",
       "3                       0.158691                    0.150551   \n",
       "4                       0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "2037                    0.093399                    0.058729   \n",
       "2038                    0.016832                    0.009602   \n",
       "2039                    0.000000                    0.000000   \n",
       "2040                    0.059230                    0.026090   \n",
       "2041                    0.000000                    0.000000   \n",
       "\n",
       "      (Electrode 105 - 33/2 Hz,)  (Electrode 105 - 34/2 Hz,)  \\\n",
       "0                   4.333844e-07                9.373567e-08   \n",
       "1                   2.352137e-03                4.122513e-04   \n",
       "2                   2.045964e-05                4.443460e-06   \n",
       "3                   1.580043e-01                1.518115e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                4.012462e-02                2.464919e-02   \n",
       "2038                5.877454e-03                3.190797e-03   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.169173e-02                4.410850e-03   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 35/2 Hz,)  (Electrode 105 - 36/2 Hz,)  \\\n",
       "0                   1.616373e-08                3.256580e-09   \n",
       "1                   4.825197e-05                5.944433e-06   \n",
       "2                   7.491343e-07                1.436770e-07   \n",
       "3                   1.233778e-01                1.242931e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                1.257993e-02                7.816617e-03   \n",
       "2038                1.418509e-03                7.564419e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.294309e-03                4.329110e-04   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 37/2 Hz,)  (Electrode 105 - 38/2 Hz,)  \\\n",
       "0                   4.986456e-10                7.457518e-11   \n",
       "1                   5.749150e-07                6.398086e-08   \n",
       "2                   2.039047e-08                2.751924e-09   \n",
       "3                   1.009636e-01                8.498748e-02   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                3.846395e-03                1.926406e-03   \n",
       "2038                3.146594e-04                1.311957e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.073561e-04                2.536768e-05   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 39/2 Hz,)           IDs  \n",
       "0                   1.130004e-11  NDARAA075AMK  \n",
       "1                   8.415637e-09  NDARAA112DMH  \n",
       "2                   3.663748e-10  NDARAA117NEJ  \n",
       "3                   7.690149e-02  NDARAA947ZG5  \n",
       "4                   0.000000e+00  NDARAA948VFH  \n",
       "...                          ...           ...  \n",
       "2037                1.018633e-03  NDARZN277NR6  \n",
       "2038                5.687030e-05  NDARZN578YDP  \n",
       "2039                0.000000e+00  NDARZN610GTY  \n",
       "2040                5.924775e-06  NDARZN677EYE  \n",
       "2041                0.000000e+00  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 4096 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df = np.array(df).reshape(data['x'].shape)\n",
    "df_sparsed = np.concatenate([np.expand_dims(df[:,:,i:i+2].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-2, 2)], axis = 2)\n",
    "df = pd.DataFrame(df_sparsed.reshape((df_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df)\n",
    "df = norm.transform(df)\n",
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(df_sparsed.shape[1]) for j in range(df_sparsed.shape[2])])\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "      <th>2646</th>\n",
       "      <th>2647</th>\n",
       "      <th>2648</th>\n",
       "      <th>2649</th>\n",
       "      <th>2650</th>\n",
       "      <th>2651</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.497571e-01</td>\n",
       "      <td>4.585819e-01</td>\n",
       "      <td>2.938905e-01</td>\n",
       "      <td>3.770603e-01</td>\n",
       "      <td>0.327764</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.462017</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.642190</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337358</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.364673</td>\n",
       "      <td>0.405482</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.428504</td>\n",
       "      <td>0.250803</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.464767e-01</td>\n",
       "      <td>9.048637e-01</td>\n",
       "      <td>5.054438e-01</td>\n",
       "      <td>7.021925e-01</td>\n",
       "      <td>0.498947</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.321952</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.478879</td>\n",
       "      <td>0.304577</td>\n",
       "      <td>0.360859</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.204578e-01</td>\n",
       "      <td>3.562272e-01</td>\n",
       "      <td>3.895027e-01</td>\n",
       "      <td>4.181956e-01</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446757</td>\n",
       "      <td>0.528172</td>\n",
       "      <td>0.409405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404292</td>\n",
       "      <td>0.339923</td>\n",
       "      <td>0.505282</td>\n",
       "      <td>0.340129</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.341549</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.346560e-02</td>\n",
       "      <td>1.204557e-01</td>\n",
       "      <td>1.650503e-01</td>\n",
       "      <td>7.631559e-01</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>0.399243</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.111156</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.758219e-01</td>\n",
       "      <td>2.255777e-01</td>\n",
       "      <td>4.828928e-01</td>\n",
       "      <td>4.704279e-01</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.284202</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164094</td>\n",
       "      <td>0.161737</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>3.394601e-01</td>\n",
       "      <td>4.781692e-01</td>\n",
       "      <td>5.423877e-01</td>\n",
       "      <td>4.137127e-01</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.538537</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268739</td>\n",
       "      <td>0.328251</td>\n",
       "      <td>0.327389</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.367808</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>NDARZN148PMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1.072605e-01</td>\n",
       "      <td>2.045245e-01</td>\n",
       "      <td>2.610531e-01</td>\n",
       "      <td>3.236518e-01</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.432447</td>\n",
       "      <td>0.412152</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451919</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.125819</td>\n",
       "      <td>0.083812</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.378008</td>\n",
       "      <td>0.264043</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2.801818e-01</td>\n",
       "      <td>3.838379e-01</td>\n",
       "      <td>3.575040e-01</td>\n",
       "      <td>3.295642e-01</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.263007</td>\n",
       "      <td>0.204378</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>0.319891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>0.543971</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>0.544979</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>0.589517</td>\n",
       "      <td>0.634712</td>\n",
       "      <td>0.549726</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>3.260273e-15</td>\n",
       "      <td>3.373362e-14</td>\n",
       "      <td>2.304057e-13</td>\n",
       "      <td>1.498324e-12</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.142998</td>\n",
       "      <td>0.689837</td>\n",
       "      <td>0.800874</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.132429</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>3.945258e-01</td>\n",
       "      <td>4.017071e-01</td>\n",
       "      <td>2.867999e-01</td>\n",
       "      <td>3.721533e-01</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299387</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.404021</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.437301</td>\n",
       "      <td>0.412550</td>\n",
       "      <td>0.745395</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows Ã— 2653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3         4  \\\n",
       "0     3.497571e-01  4.585819e-01  2.938905e-01  3.770603e-01  0.327764   \n",
       "1     7.464767e-01  9.048637e-01  5.054438e-01  7.021925e-01  0.498947   \n",
       "2     2.204578e-01  3.562272e-01  3.895027e-01  4.181956e-01  0.495129   \n",
       "3     6.346560e-02  1.204557e-01  1.650503e-01  7.631559e-01  0.523793   \n",
       "4     2.758219e-01  2.255777e-01  4.828928e-01  4.704279e-01  0.330692   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "2036  3.394601e-01  4.781692e-01  5.423877e-01  4.137127e-01  0.379793   \n",
       "2037  1.072605e-01  2.045245e-01  2.610531e-01  3.236518e-01  0.437417   \n",
       "2038  2.801818e-01  3.838379e-01  3.575040e-01  3.295642e-01  0.339077   \n",
       "2039  3.260273e-15  3.373362e-14  2.304057e-13  1.498324e-12  0.000009   \n",
       "2040  3.945258e-01  4.017071e-01  2.867999e-01  3.721533e-01  0.583645   \n",
       "\n",
       "             5         6         7         8         9  ...      2643  \\\n",
       "0     0.552059  0.462017  0.695207  0.642190  0.584085  ...  0.337358   \n",
       "1     0.342338  0.283478  0.221679  0.178758  0.178338  ...  0.430404   \n",
       "2     0.436858  0.392300  0.446757  0.528172  0.409405  ...  0.404292   \n",
       "3     0.399243  0.267432  0.301397  0.283535  0.363612  ...  0.108138   \n",
       "4     0.310594  0.284202  0.298111  0.245370  0.250187  ...  0.164094   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2036  0.413474  0.538537  0.457002  0.286496  0.222562  ...  0.268739   \n",
       "2037  0.432447  0.412152  0.445771  0.374603  0.386189  ...  0.451919   \n",
       "2038  0.263007  0.204378  0.308062  0.413562  0.319891  ...  0.386920   \n",
       "2039  0.142998  0.689837  0.800874  0.499946  0.248208  ...  0.213887   \n",
       "2040  0.497248  0.302516  0.193872  0.343920  0.500556  ...  0.299387   \n",
       "\n",
       "          2644      2645      2646      2647      2648      2649      2650  \\\n",
       "0     0.439658  0.437051  0.364673  0.405482  0.326733  0.428504  0.250803   \n",
       "1     0.296341  0.321952  0.131375  0.579138  0.478879  0.304577  0.360859   \n",
       "2     0.339923  0.505282  0.340129  0.203517  0.174711  0.341549  0.693619   \n",
       "3     0.049740  0.033945  0.304668  0.111156  0.008791  0.005297  0.266759   \n",
       "4     0.161737  0.123381  0.079693  0.069366  0.043857  0.029212  0.021894   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2036  0.328251  0.327389  0.292491  0.367808  0.346005  0.348895  0.399141   \n",
       "2037  0.240030  0.125819  0.083812  0.289439  0.378008  0.264043  0.502426   \n",
       "2038  0.543971  0.590438  0.544979  0.679570  0.616411  0.589517  0.634712   \n",
       "2039  0.230102  0.189709  0.132429  0.124579  0.085125  0.061278  0.049636   \n",
       "2040  0.416947  0.446031  0.404021  0.493188  0.437301  0.412550  0.745395   \n",
       "\n",
       "          2651           IDs  \n",
       "0     0.179322  NDARAA075AMK  \n",
       "1     0.448476  NDARAA112DMH  \n",
       "2     0.545169  NDARAA117NEJ  \n",
       "3     0.339304  NDARAA947ZG5  \n",
       "4     0.013197  NDARAA948VFH  \n",
       "...        ...           ...  \n",
       "2036  0.367943  NDARZN148PMN  \n",
       "2037  0.008403  NDARZN277NR6  \n",
       "2038  0.549726  NDARZN578YDP  \n",
       "2039  0.032335  NDARZN610GTY  \n",
       "2040  0.373653  NDARZN677EYE  \n",
       "\n",
       "[2041 rows x 2653 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mat73.loadmat(DATA_DIR+'x_source.mat')  \n",
    "df2 = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df2 = np.array(df2).reshape(data['x'].shape) \n",
    "df2_sparsed = np.concatenate([np.expand_dims(df2[:,:,i:i+10].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-10, 10)], axis = 2)\n",
    "df2 = pd.DataFrame(df2_sparsed.reshape((df2_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df2)\n",
    "df2 = norm.transform(df2)\n",
    "df2 = pd.DataFrame(df2.reshape((df2.shape[0], -1)))\n",
    "\n",
    "df2['IDs'] = foof['IDs']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2813, 177)\n",
      "Removing 263 patients as their diagnoses were very uncommon.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'No Diagnosis Given', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "# most_common_disorders = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# find users that have no diagnosis within these top diseases\n",
    "# filtering should cahnge anything as this should also happen at a later stage\n",
    "mask = None\n",
    "for col in category_columns:\n",
    "    mask_col = beh[col].isin(most_common_disorders)\n",
    "    if mask is None:\n",
    "        mask = mask_col\n",
    "    else:\n",
    "        mask = mask | mask_col\n",
    "\n",
    "initial_size = beh.shape[0]\n",
    "beh = beh[mask]\n",
    "beh = beh.reset_index(drop=True)\n",
    "new_size = beh.shape[0]\n",
    "print('After:'+str(beh.shape))\n",
    "print('Removing', initial_size - new_size,\n",
    "      'patients as their diagnoses were very uncommon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "if no_diagnosis_given in most_common_disorders:\n",
    "    no_diag_index = most_common_disorders.index(no_diagnosis_given)\n",
    "    most_common_disorders = most_common_disorders[:no_diag_index] + \\\n",
    "        most_common_disorders[no_diag_index + 1:]\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while disorder != no_diagnosis_given and not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "    order_of_disorders.append(disorders_patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2813 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2808  NDARZZ007YMP                                         0   \n",
       "2809  NDARZZ740MLM                                         1   \n",
       "2810  NDARZZ810LVF                                         0   \n",
       "2811  NDARZZ830JM7                                         0   \n",
       "2812  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2808                  0                           0                         1   \n",
       "2809                  0                           0                         0   \n",
       "2810                  0                           0                         1   \n",
       "2811                  0                           0                         1   \n",
       "2812                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       1                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "2808           0                       0                     0  \n",
       "2809           0                       0                     0  \n",
       "2810           0                       1                     0  \n",
       "2811           0                       0                     0  \n",
       "2812           0                       0                     0  \n",
       "\n",
       "[2813 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=behaviour_data[[\"IDs\"]+list(most_common_disorders)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>2651</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>5.960983e-06</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>7.428434e-02</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>9.411772e-02</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>3.789685e-01</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>1.676998e-01</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>8.206176e-11</td>\n",
       "      <td>1.191276e-08</td>\n",
       "      <td>9.842314e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.155558</td>\n",
       "      <td>0.287815</td>\n",
       "      <td>0.314661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.788340</td>\n",
       "      <td>1.573205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>3.062358e-04</td>\n",
       "      <td>1.130883e-03</td>\n",
       "      <td>3.834623e-03</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.032255</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.108455</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333760</td>\n",
       "      <td>1.423824</td>\n",
       "      <td>1.381199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1.556547e-05</td>\n",
       "      <td>2.900630e-04</td>\n",
       "      <td>3.548476e-03</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.189421</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.445277</td>\n",
       "      <td>0.644915</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>1.949453e-01</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>9.555112e-02</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows Ã— 6757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "1830             8.206176e-11             1.191276e-08   \n",
       "1831             3.062358e-04             1.130883e-03   \n",
       "1832             1.556547e-05             2.900630e-04   \n",
       "1833             2.303407e-04             2.867255e-02   \n",
       "1834             6.411911e-03             2.687961e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                5.960983e-06                 0.001066   \n",
       "1                7.428434e-02                 0.216988   \n",
       "2                9.411772e-02                 0.367821   \n",
       "3                3.789685e-01                 0.299813   \n",
       "4                1.676998e-01                 0.368840   \n",
       "...                       ...                      ...   \n",
       "1830             9.842314e-07                 0.000039   \n",
       "1831             3.834623e-03                 0.009994   \n",
       "1832             3.548476e-03                 0.023882   \n",
       "1833             1.949453e-01                 0.081646   \n",
       "1834             9.555112e-02                 0.241121   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "1830                 0.000736                 0.006939   \n",
       "1831                 0.020117                 0.032255   \n",
       "1832                 0.088943                 0.189421   \n",
       "1833                 0.018422                 0.076959   \n",
       "1834                 0.434011                 0.574767   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "1830                 0.040446                 0.155558   \n",
       "1831                 0.051099                 0.085125   \n",
       "1832                 0.293481                 0.445277   \n",
       "1833                 0.179779                 0.300051   \n",
       "1834                 0.694741                 0.815939   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...      2651  \\\n",
       "0                    0.593581                  0.401686  ...  0.179322   \n",
       "1                    0.049898                  0.004720  ...  0.448476   \n",
       "2                    0.526883                  0.511715  ...  0.545169   \n",
       "3                    0.003988                  0.061608  ...  0.339304   \n",
       "4                    0.233210                  0.125520  ...  0.013197   \n",
       "...                       ...                       ...  ...       ...   \n",
       "1830                 0.287815                  0.314661  ...  0.128389   \n",
       "1831                 0.108455                  0.129148  ...  0.333760   \n",
       "1832                 0.644915                  0.577096  ...  0.367943   \n",
       "1833                 0.417245                  0.459853  ...  0.008403   \n",
       "1834                 0.678021                  0.490314  ...  0.373653   \n",
       "\n",
       "      Intercept     Slope  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0      0.986272  1.825774                                         0   \n",
       "1      1.486650  1.888544                                         1   \n",
       "2      1.593155  2.095749                                         1   \n",
       "3      0.703331  1.724831                                         1   \n",
       "4      0.918020  1.749441                                         1   \n",
       "...         ...       ...                                       ...   \n",
       "1830   0.788340  1.573205                                         1   \n",
       "1831   1.423824  1.381199                                         0   \n",
       "1832   0.168009  0.205704                                         0   \n",
       "1833   1.351549  1.996940                                         1   \n",
       "1834   0.781225  1.470061                                         1   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     0                           1                         1   \n",
       "4                     0                           0                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "1830                  0                           0                         0   \n",
       "1831                  0                           0                         0   \n",
       "1832                  1                           0                         0   \n",
       "1833                  1                           0                         0   \n",
       "1834                  0                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       0                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "1830           0                       0                     0  \n",
       "1831           0                       0                     0  \n",
       "1832           0                       0                     0  \n",
       "1833           0                       0                     1  \n",
       "1834           0                       0                     0  \n",
       "\n",
       "[1835 rows x 6757 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df2, on='IDs', how='inner')\n",
    "df = pd.merge(df, foof, on='IDs', how='inner')\n",
    "df = pd.merge(df, labels, on='IDs', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1835, 6749) (1835, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_772859/3799954537.py:1: RuntimeWarning: '<' not supported between instances of 'int' and 'tuple', sort order is undefined for incomparable objects\n",
      "  x = df[df.columns.difference(['IDs']+most_common_disorders)]\n"
     ]
    }
   ],
   "source": [
    "x = df[df.columns.difference(['IDs']+most_common_disorders)]\n",
    "y = df[most_common_disorders]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 17:41:45.509324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-22 17:41:45.538842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.539508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-22 17:41:45.539702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:41:45.540934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-22 17:41:45.542481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 17:41:45.542669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 17:41:45.543999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-22 17:41:45.544739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-22 17:41:45.547505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-22 17:41:45.547653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.548377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.548983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-22 17:41:45.549557: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-11-22 17:41:45.555692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-11-22 17:41:45.556196: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564578e4f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 17:41:45.556209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-22 17:41:45.556349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.557014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-22 17:41:45.557053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:41:45.557067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-22 17:41:45.557078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 17:41:45.557088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 17:41:45.557098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-22 17:41:45.557108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-22 17:41:45.557118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-22 17:41:45.557177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.557854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.558464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-22 17:41:45.558495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:41:45.625489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-22 17:41:45.625516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-22 17:41:45.625521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-22 17:41:45.625812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.626477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.627096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:41:45.627693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14109 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-11-22 17:41:45.629516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55645d6f8920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 17:41:45.629527: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 17:41:47.188458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 - 6s - loss: 35.7001\n",
      "Epoch 2/5\n",
      "81/81 - 6s - loss: 0.2268\n",
      "Epoch 3/5\n",
      "81/81 - 6s - loss: 0.2330\n",
      "Epoch 4/5\n",
      "81/81 - 6s - loss: 0.2287\n",
      "Epoch 5/5\n",
      "81/81 - 6s - loss: 0.2332\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "n_inputs = train_features.shape[1]\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "output = Dense(7, activation='linear')(d)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=5, batch_size=16, verbose=2)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "encoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "encoder= load_model('autoencoder.h5', compile=False)\n",
    "\n",
    "train_features = encoder.predict(train_features)\n",
    "test_features = encoder.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.17422867513611615\n",
      "Hamming Loss: 0.21545242416385793\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.76       344\n",
      "           1       0.60      0.07      0.12       176\n",
      "           2       1.00      0.00      0.00       135\n",
      "           3       1.00      0.01      0.02        90\n",
      "           4       1.00      0.00      0.00        79\n",
      "           5       1.00      0.00      0.00        88\n",
      "           6       1.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.63      0.35      0.45       969\n",
      "   macro avg       0.89      0.15      0.13       969\n",
      "weighted avg       0.79      0.35      0.29       969\n",
      " samples avg       0.65      0.46      0.43       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 12 195]\n",
      "  [ 16 328]]\n",
      "\n",
      " [[367   8]\n",
      "  [164  12]]\n",
      "\n",
      " [[416   0]\n",
      "  [135   0]]\n",
      "\n",
      " [[461   0]\n",
      "  [ 89   1]]\n",
      "\n",
      " [[472   0]\n",
      "  [ 79   0]]\n",
      "\n",
      " [[463   0]\n",
      "  [ 88   0]]\n",
      "\n",
      " [[494   0]\n",
      "  [ 57   0]]]\n",
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.1542649727767695\n",
      "Hamming Loss: 0.23074928701063002\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71       344\n",
      "           1       0.37      0.21      0.27       176\n",
      "           2       0.26      0.04      0.08       135\n",
      "           3       0.43      0.03      0.06        90\n",
      "           4       0.44      0.05      0.09        79\n",
      "           5       0.33      0.02      0.04        88\n",
      "           6       0.20      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.57      0.34      0.43       969\n",
      "   macro avg       0.38      0.17      0.18       969\n",
      "weighted avg       0.45      0.34      0.33       969\n",
      " samples avg       0.66      0.44      0.39       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 54 153]\n",
      "  [ 68 276]]\n",
      "\n",
      " [[312  63]\n",
      "  [139  37]]\n",
      "\n",
      " [[399  17]\n",
      "  [129   6]]\n",
      "\n",
      " [[457   4]\n",
      "  [ 87   3]]\n",
      "\n",
      " [[467   5]\n",
      "  [ 75   4]]\n",
      "\n",
      " [[459   4]\n",
      "  [ 86   2]]\n",
      "\n",
      " [[490   4]\n",
      "  [ 56   1]]]\n",
      "SVC():\n",
      "Accuracy: 0.17422867513611615\n",
      "Hamming Loss: 0.21571169302566762\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       344\n",
      "           1       1.00      0.00      0.00       176\n",
      "           2       1.00      0.00      0.00       135\n",
      "           3       1.00      0.00      0.00        90\n",
      "           4       1.00      0.00      0.00        79\n",
      "           5       1.00      0.00      0.00        88\n",
      "           6       1.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.62      0.36      0.45       969\n",
      "   macro avg       0.95      0.14      0.11       969\n",
      "weighted avg       0.87      0.36      0.27       969\n",
      " samples avg       0.62      0.46      0.43       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  0 207]\n",
      "  [  0 344]]\n",
      "\n",
      " [[375   0]\n",
      "  [176   0]]\n",
      "\n",
      " [[416   0]\n",
      "  [135   0]]\n",
      "\n",
      " [[461   0]\n",
      "  [ 90   0]]\n",
      "\n",
      " [[472   0]\n",
      "  [ 79   0]]\n",
      "\n",
      " [[463   0]\n",
      "  [ 88   0]]\n",
      "\n",
      " [[494   0]\n",
      "  [ 57   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 2.2689\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.1628\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.1432\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.9866\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.8837\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.8908\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.8976\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.7898\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.0018\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.8345\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.7910\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.7744\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.8517\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.8127\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7484\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.9305\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.8449\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.8248\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7060\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7034\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6297\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7030\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7201\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7096\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5796\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5630\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5508\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5462\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5415\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5389\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5349\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5336\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5293\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5270\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5245\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5219\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5201\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5185\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5164\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5153\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5140\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5119\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5105\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5089\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5080\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5075\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5070\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5055\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5064\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5038\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5029\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5034\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5031\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5018\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5017\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5007\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5003\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4998\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5003\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4994\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4988\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4988\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4981\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4984\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4977\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4974\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4979\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4973\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4970\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4967\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4968\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4970\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4964\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4962\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4964\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4962\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4963\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4964\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4959\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4962\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4961\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4955\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5010\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4975\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4956\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4958\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4967\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4973\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4957\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4964\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4956\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4957\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4966\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4959\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4959\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4954\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4954\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4960\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4960\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5e2f081c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = train_features.shape[1],train_labels.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17422867513611615\n",
      "Hamming Loss: 0.21571169302566762\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       344\n",
      "           1       1.00      0.00      0.00       176\n",
      "           2       1.00      0.00      0.00       135\n",
      "           3       1.00      0.00      0.00        90\n",
      "           4       1.00      0.00      0.00        79\n",
      "           5       1.00      0.00      0.00        88\n",
      "           6       1.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.62      0.36      0.45       969\n",
      "   macro avg       0.95      0.14      0.11       969\n",
      "weighted avg       0.87      0.36      0.27       969\n",
      " samples avg       0.62      0.46      0.43       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  0 207]\n",
      "  [  0 344]]\n",
      "\n",
      " [[375   0]\n",
      "  [176   0]]\n",
      "\n",
      " [[416   0]\n",
      "  [135   0]]\n",
      "\n",
      " [[461   0]\n",
      "  [ 90   0]]\n",
      "\n",
      " [[472   0]\n",
      "  [ 79   0]]\n",
      "\n",
      " [[463   0]\n",
      "  [ 88   0]]\n",
      "\n",
      " [[494   0]\n",
      "  [ 57   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0018148820326678765\n",
      "Hamming Loss: 0.4493129375162043\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       344\n",
      "           1       0.34      0.60      0.43       176\n",
      "           2       0.27      0.73      0.39       135\n",
      "           3       0.21      0.39      0.28        90\n",
      "           4       0.17      0.53      0.26        79\n",
      "           5       0.20      0.51      0.28        88\n",
      "           6       0.15      0.65      0.25        57\n",
      "\n",
      "   micro avg       0.29      0.54      0.38       969\n",
      "   macro avg       0.28      0.55      0.35       969\n",
      "weighted avg       0.39      0.54      0.41       969\n",
      " samples avg       0.29      0.60      0.33       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[117  90]\n",
      "  [183 161]]\n",
      "\n",
      " [[170 205]\n",
      "  [ 71 105]]\n",
      "\n",
      " [[147 269]\n",
      "  [ 36  99]]\n",
      "\n",
      " [[333 128]\n",
      "  [ 55  35]]\n",
      "\n",
      " [[266 206]\n",
      "  [ 37  42]]\n",
      "\n",
      " [[280 183]\n",
      "  [ 43  45]]\n",
      "\n",
      " [[287 207]\n",
      "  [ 20  37]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17604355716878403\n",
      "Hamming Loss: 0.21545242416385793\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.76       344\n",
      "           1       0.67      0.06      0.10       176\n",
      "           2       1.00      0.01      0.01       135\n",
      "           3       0.00      0.00      0.00        90\n",
      "           4       1.00      0.00      0.00        79\n",
      "           5       1.00      0.00      0.00        88\n",
      "           6       1.00      0.00      0.00        57\n",
      "\n",
      "   micro avg       0.63      0.35      0.45       969\n",
      "   macro avg       0.76      0.15      0.13       969\n",
      "weighted avg       0.71      0.35      0.29       969\n",
      " samples avg       0.65      0.46      0.43       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 12 195]\n",
      "  [ 16 328]]\n",
      "\n",
      " [[370   5]\n",
      "  [166  10]]\n",
      "\n",
      " [[416   0]\n",
      "  [134   1]]\n",
      "\n",
      " [[460   1]\n",
      "  [ 90   0]]\n",
      "\n",
      " [[472   0]\n",
      "  [ 79   0]]\n",
      "\n",
      " [[463   0]\n",
      "  [ 88   0]]\n",
      "\n",
      " [[494   0]\n",
      "  [ 57   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.15789473684210525\n",
      "Hamming Loss: 0.22660098522167488\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       344\n",
      "           1       0.29      0.02      0.04       176\n",
      "           2       0.33      0.01      0.01       135\n",
      "           3       0.50      0.01      0.02        90\n",
      "           4       0.20      0.04      0.06        79\n",
      "           5       0.14      0.01      0.02        88\n",
      "           6       0.50      0.02      0.03        57\n",
      "\n",
      "   micro avg       0.59      0.31      0.41       969\n",
      "   macro avg       0.37      0.14      0.13       969\n",
      "weighted avg       0.42      0.31      0.28       969\n",
      " samples avg       0.66      0.42      0.39       969\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 31 176]\n",
      "  [ 52 292]]\n",
      "\n",
      " [[365  10]\n",
      "  [172   4]]\n",
      "\n",
      " [[414   2]\n",
      "  [134   1]]\n",
      "\n",
      " [[460   1]\n",
      "  [ 89   1]]\n",
      "\n",
      " [[460  12]\n",
      "  [ 76   3]]\n",
      "\n",
      " [[457   6]\n",
      "  [ 87   1]]\n",
      "\n",
      " [[493   1]\n",
      "  [ 56   1]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_772859/3010096247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_772859/2384122163.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_test, y_pred)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hamming Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhamming_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification Report:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "\n",
    "classifier = MLkNN(k=3)\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "evaluate(x_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
