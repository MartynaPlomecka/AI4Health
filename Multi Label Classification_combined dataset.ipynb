{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Electrode 105 - 31/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 32/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 33/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 34/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 35/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 36/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 37/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 38/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 39/2 Hz,)</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.333844e-07</td>\n",
       "      <td>9.373567e-08</td>\n",
       "      <td>1.616373e-08</td>\n",
       "      <td>3.256580e-09</td>\n",
       "      <td>4.986456e-10</td>\n",
       "      <td>7.457518e-11</td>\n",
       "      <td>1.130004e-11</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>2.352137e-03</td>\n",
       "      <td>4.122513e-04</td>\n",
       "      <td>4.825197e-05</td>\n",
       "      <td>5.944433e-06</td>\n",
       "      <td>5.749150e-07</td>\n",
       "      <td>6.398086e-08</td>\n",
       "      <td>8.415637e-09</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.045964e-05</td>\n",
       "      <td>4.443460e-06</td>\n",
       "      <td>7.491343e-07</td>\n",
       "      <td>1.436770e-07</td>\n",
       "      <td>2.039047e-08</td>\n",
       "      <td>2.751924e-09</td>\n",
       "      <td>3.663748e-10</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>1.580043e-01</td>\n",
       "      <td>1.518115e-01</td>\n",
       "      <td>1.233778e-01</td>\n",
       "      <td>1.242931e-01</td>\n",
       "      <td>1.009636e-01</td>\n",
       "      <td>8.498748e-02</td>\n",
       "      <td>7.690149e-02</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093399</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>4.012462e-02</td>\n",
       "      <td>2.464919e-02</td>\n",
       "      <td>1.257993e-02</td>\n",
       "      <td>7.816617e-03</td>\n",
       "      <td>3.846395e-03</td>\n",
       "      <td>1.926406e-03</td>\n",
       "      <td>1.018633e-03</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.385606e-02</td>\n",
       "      <td>2.124126e-02</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.222227</td>\n",
       "      <td>0.444972</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>5.877454e-03</td>\n",
       "      <td>3.190797e-03</td>\n",
       "      <td>1.418509e-03</td>\n",
       "      <td>7.564419e-04</td>\n",
       "      <td>3.146594e-04</td>\n",
       "      <td>1.311957e-04</td>\n",
       "      <td>5.687030e-05</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1.089647e-02</td>\n",
       "      <td>3.749309e-02</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>0.413368</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>1.169173e-02</td>\n",
       "      <td>4.410850e-03</td>\n",
       "      <td>1.294309e-03</td>\n",
       "      <td>4.329110e-04</td>\n",
       "      <td>1.073561e-04</td>\n",
       "      <td>2.536768e-05</td>\n",
       "      <td>5.924775e-06</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2.695401e-03</td>\n",
       "      <td>5.553206e-02</td>\n",
       "      <td>0.315364</td>\n",
       "      <td>0.444302</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.232912</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "2037             2.303407e-04             2.867255e-02   \n",
       "2038             1.385606e-02             2.124126e-02   \n",
       "2039             1.089647e-02             3.749309e-02   \n",
       "2040             6.411911e-03             2.687961e-02   \n",
       "2041             2.695401e-03             5.553206e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                    0.000006                 0.001066   \n",
       "1                    0.074284                 0.216988   \n",
       "2                    0.094118                 0.367821   \n",
       "3                    0.378969                 0.299813   \n",
       "4                    0.167700                 0.368840   \n",
       "...                       ...                      ...   \n",
       "2037                 0.194945                 0.081646   \n",
       "2038                 0.032991                 0.043456   \n",
       "2039                 0.139003                 0.289797   \n",
       "2040                 0.095551                 0.241121   \n",
       "2041                 0.315364                 0.444302   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "2037                 0.018422                 0.076959   \n",
       "2038                 0.048827                 0.049759   \n",
       "2039                 0.304728                 0.196113   \n",
       "2040                 0.434011                 0.574767   \n",
       "2041                 0.321718                 0.232912   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "2037                 0.179779                 0.300051   \n",
       "2038                 0.074988                 0.222227   \n",
       "2039                 0.191950                 0.342653   \n",
       "2040                 0.694741                 0.815939   \n",
       "2041                 0.152557                 0.178452   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
       "0                    0.593581                  0.401686  ...   \n",
       "1                    0.049898                  0.004720  ...   \n",
       "2                    0.526883                  0.511715  ...   \n",
       "3                    0.003988                  0.061608  ...   \n",
       "4                    0.233210                  0.125520  ...   \n",
       "...                       ...                       ...  ...   \n",
       "2037                 0.417245                  0.459853  ...   \n",
       "2038                 0.444972                  0.464653  ...   \n",
       "2039                 0.413368                  0.344024  ...   \n",
       "2040                 0.678021                  0.490314  ...   \n",
       "2041                 0.289553                  0.280580  ...   \n",
       "\n",
       "      (Electrode 105 - 31/2 Hz,)  (Electrode 105 - 32/2 Hz,)  \\\n",
       "0                       0.000007                    0.000002   \n",
       "1                       0.031636                    0.009416   \n",
       "2                       0.000311                    0.000079   \n",
       "3                       0.158691                    0.150551   \n",
       "4                       0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "2037                    0.093399                    0.058729   \n",
       "2038                    0.016832                    0.009602   \n",
       "2039                    0.000000                    0.000000   \n",
       "2040                    0.059230                    0.026090   \n",
       "2041                    0.000000                    0.000000   \n",
       "\n",
       "      (Electrode 105 - 33/2 Hz,)  (Electrode 105 - 34/2 Hz,)  \\\n",
       "0                   4.333844e-07                9.373567e-08   \n",
       "1                   2.352137e-03                4.122513e-04   \n",
       "2                   2.045964e-05                4.443460e-06   \n",
       "3                   1.580043e-01                1.518115e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                4.012462e-02                2.464919e-02   \n",
       "2038                5.877454e-03                3.190797e-03   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.169173e-02                4.410850e-03   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 35/2 Hz,)  (Electrode 105 - 36/2 Hz,)  \\\n",
       "0                   1.616373e-08                3.256580e-09   \n",
       "1                   4.825197e-05                5.944433e-06   \n",
       "2                   7.491343e-07                1.436770e-07   \n",
       "3                   1.233778e-01                1.242931e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                1.257993e-02                7.816617e-03   \n",
       "2038                1.418509e-03                7.564419e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.294309e-03                4.329110e-04   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 37/2 Hz,)  (Electrode 105 - 38/2 Hz,)  \\\n",
       "0                   4.986456e-10                7.457518e-11   \n",
       "1                   5.749150e-07                6.398086e-08   \n",
       "2                   2.039047e-08                2.751924e-09   \n",
       "3                   1.009636e-01                8.498748e-02   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                3.846395e-03                1.926406e-03   \n",
       "2038                3.146594e-04                1.311957e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.073561e-04                2.536768e-05   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 39/2 Hz,)           IDs  \n",
       "0                   1.130004e-11  NDARAA075AMK  \n",
       "1                   8.415637e-09  NDARAA112DMH  \n",
       "2                   3.663748e-10  NDARAA117NEJ  \n",
       "3                   7.690149e-02  NDARAA947ZG5  \n",
       "4                   0.000000e+00  NDARAA948VFH  \n",
       "...                          ...           ...  \n",
       "2037                1.018633e-03  NDARZN277NR6  \n",
       "2038                5.687030e-05  NDARZN578YDP  \n",
       "2039                0.000000e+00  NDARZN610GTY  \n",
       "2040                5.924775e-06  NDARZN677EYE  \n",
       "2041                0.000000e+00  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 4096 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df = np.array(df).reshape(data['x'].shape)\n",
    "df_sparsed = np.concatenate([np.expand_dims(df[:,:,i:i+2].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-2, 2)], axis = 2)\n",
    "df = pd.DataFrame(df_sparsed.reshape((df_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df)\n",
    "df = norm.transform(df)\n",
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(df_sparsed.shape[1]) for j in range(df_sparsed.shape[2])])\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "      <th>2646</th>\n",
       "      <th>2647</th>\n",
       "      <th>2648</th>\n",
       "      <th>2649</th>\n",
       "      <th>2650</th>\n",
       "      <th>2651</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.497571e-01</td>\n",
       "      <td>4.585819e-01</td>\n",
       "      <td>2.938905e-01</td>\n",
       "      <td>3.770603e-01</td>\n",
       "      <td>0.327764</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.462017</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.642190</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337358</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.364673</td>\n",
       "      <td>0.405482</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.428504</td>\n",
       "      <td>0.250803</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.464767e-01</td>\n",
       "      <td>9.048637e-01</td>\n",
       "      <td>5.054438e-01</td>\n",
       "      <td>7.021925e-01</td>\n",
       "      <td>0.498947</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.321952</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.478879</td>\n",
       "      <td>0.304577</td>\n",
       "      <td>0.360859</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.204578e-01</td>\n",
       "      <td>3.562272e-01</td>\n",
       "      <td>3.895027e-01</td>\n",
       "      <td>4.181956e-01</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446757</td>\n",
       "      <td>0.528172</td>\n",
       "      <td>0.409405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404292</td>\n",
       "      <td>0.339923</td>\n",
       "      <td>0.505282</td>\n",
       "      <td>0.340129</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.341549</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.346560e-02</td>\n",
       "      <td>1.204557e-01</td>\n",
       "      <td>1.650503e-01</td>\n",
       "      <td>7.631559e-01</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>0.399243</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.111156</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.758219e-01</td>\n",
       "      <td>2.255777e-01</td>\n",
       "      <td>4.828928e-01</td>\n",
       "      <td>4.704279e-01</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.284202</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164094</td>\n",
       "      <td>0.161737</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>3.394601e-01</td>\n",
       "      <td>4.781692e-01</td>\n",
       "      <td>5.423877e-01</td>\n",
       "      <td>4.137127e-01</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.538537</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268739</td>\n",
       "      <td>0.328251</td>\n",
       "      <td>0.327389</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.367808</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>NDARZN148PMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1.072605e-01</td>\n",
       "      <td>2.045245e-01</td>\n",
       "      <td>2.610531e-01</td>\n",
       "      <td>3.236518e-01</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.432447</td>\n",
       "      <td>0.412152</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451919</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.125819</td>\n",
       "      <td>0.083812</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.378008</td>\n",
       "      <td>0.264043</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2.801818e-01</td>\n",
       "      <td>3.838379e-01</td>\n",
       "      <td>3.575040e-01</td>\n",
       "      <td>3.295642e-01</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.263007</td>\n",
       "      <td>0.204378</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>0.319891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>0.543971</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>0.544979</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>0.589517</td>\n",
       "      <td>0.634712</td>\n",
       "      <td>0.549726</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>3.260273e-15</td>\n",
       "      <td>3.373362e-14</td>\n",
       "      <td>2.304057e-13</td>\n",
       "      <td>1.498324e-12</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.142998</td>\n",
       "      <td>0.689837</td>\n",
       "      <td>0.800874</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.132429</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>3.945258e-01</td>\n",
       "      <td>4.017071e-01</td>\n",
       "      <td>2.867999e-01</td>\n",
       "      <td>3.721533e-01</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299387</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.404021</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.437301</td>\n",
       "      <td>0.412550</td>\n",
       "      <td>0.745395</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows × 2653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3         4  \\\n",
       "0     3.497571e-01  4.585819e-01  2.938905e-01  3.770603e-01  0.327764   \n",
       "1     7.464767e-01  9.048637e-01  5.054438e-01  7.021925e-01  0.498947   \n",
       "2     2.204578e-01  3.562272e-01  3.895027e-01  4.181956e-01  0.495129   \n",
       "3     6.346560e-02  1.204557e-01  1.650503e-01  7.631559e-01  0.523793   \n",
       "4     2.758219e-01  2.255777e-01  4.828928e-01  4.704279e-01  0.330692   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "2036  3.394601e-01  4.781692e-01  5.423877e-01  4.137127e-01  0.379793   \n",
       "2037  1.072605e-01  2.045245e-01  2.610531e-01  3.236518e-01  0.437417   \n",
       "2038  2.801818e-01  3.838379e-01  3.575040e-01  3.295642e-01  0.339077   \n",
       "2039  3.260273e-15  3.373362e-14  2.304057e-13  1.498324e-12  0.000009   \n",
       "2040  3.945258e-01  4.017071e-01  2.867999e-01  3.721533e-01  0.583645   \n",
       "\n",
       "             5         6         7         8         9  ...      2643  \\\n",
       "0     0.552059  0.462017  0.695207  0.642190  0.584085  ...  0.337358   \n",
       "1     0.342338  0.283478  0.221679  0.178758  0.178338  ...  0.430404   \n",
       "2     0.436858  0.392300  0.446757  0.528172  0.409405  ...  0.404292   \n",
       "3     0.399243  0.267432  0.301397  0.283535  0.363612  ...  0.108138   \n",
       "4     0.310594  0.284202  0.298111  0.245370  0.250187  ...  0.164094   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2036  0.413474  0.538537  0.457002  0.286496  0.222562  ...  0.268739   \n",
       "2037  0.432447  0.412152  0.445771  0.374603  0.386189  ...  0.451919   \n",
       "2038  0.263007  0.204378  0.308062  0.413562  0.319891  ...  0.386920   \n",
       "2039  0.142998  0.689837  0.800874  0.499946  0.248208  ...  0.213887   \n",
       "2040  0.497248  0.302516  0.193872  0.343920  0.500556  ...  0.299387   \n",
       "\n",
       "          2644      2645      2646      2647      2648      2649      2650  \\\n",
       "0     0.439658  0.437051  0.364673  0.405482  0.326733  0.428504  0.250803   \n",
       "1     0.296341  0.321952  0.131375  0.579138  0.478879  0.304577  0.360859   \n",
       "2     0.339923  0.505282  0.340129  0.203517  0.174711  0.341549  0.693619   \n",
       "3     0.049740  0.033945  0.304668  0.111156  0.008791  0.005297  0.266759   \n",
       "4     0.161737  0.123381  0.079693  0.069366  0.043857  0.029212  0.021894   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2036  0.328251  0.327389  0.292491  0.367808  0.346005  0.348895  0.399141   \n",
       "2037  0.240030  0.125819  0.083812  0.289439  0.378008  0.264043  0.502426   \n",
       "2038  0.543971  0.590438  0.544979  0.679570  0.616411  0.589517  0.634712   \n",
       "2039  0.230102  0.189709  0.132429  0.124579  0.085125  0.061278  0.049636   \n",
       "2040  0.416947  0.446031  0.404021  0.493188  0.437301  0.412550  0.745395   \n",
       "\n",
       "          2651           IDs  \n",
       "0     0.179322  NDARAA075AMK  \n",
       "1     0.448476  NDARAA112DMH  \n",
       "2     0.545169  NDARAA117NEJ  \n",
       "3     0.339304  NDARAA947ZG5  \n",
       "4     0.013197  NDARAA948VFH  \n",
       "...        ...           ...  \n",
       "2036  0.367943  NDARZN148PMN  \n",
       "2037  0.008403  NDARZN277NR6  \n",
       "2038  0.549726  NDARZN578YDP  \n",
       "2039  0.032335  NDARZN610GTY  \n",
       "2040  0.373653  NDARZN677EYE  \n",
       "\n",
       "[2041 rows x 2653 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mat73.loadmat(DATA_DIR+'x_source.mat')  \n",
    "df2 = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df2 = np.array(df2).reshape(data['x'].shape) \n",
    "df2_sparsed = np.concatenate([np.expand_dims(df2[:,:,i:i+10].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-10, 10)], axis = 2)\n",
    "df2 = pd.DataFrame(df2_sparsed.reshape((df2_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df2)\n",
    "df2 = norm.transform(df2)\n",
    "df2 = pd.DataFrame(df2.reshape((df2.shape[0], -1)))\n",
    "\n",
    "df2['IDs'] = foof['IDs']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2813, 177)\n",
      "Removing 263 patients as their diagnoses were very uncommon.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'No Diagnosis Given', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "# most_common_disorders = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# find users that have no diagnosis within these top diseases\n",
    "# filtering should cahnge anything as this should also happen at a later stage\n",
    "mask = None\n",
    "for col in category_columns:\n",
    "    mask_col = beh[col].isin(most_common_disorders)\n",
    "    if mask is None:\n",
    "        mask = mask_col\n",
    "    else:\n",
    "        mask = mask | mask_col\n",
    "\n",
    "# undo removing patients\n",
    "# initial_size = beh.shape[0]\n",
    "# beh = beh[mask]\n",
    "# beh = beh.reset_index(drop=True)\n",
    "# new_size = beh.shape[0]\n",
    "# print('After:'+str(beh.shape))\n",
    "# print('Removing', initial_size - new_size,\n",
    "#       'patients as their diagnoses were very uncommon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "if no_diagnosis_given in most_common_disorders:\n",
    "    no_diag_index = most_common_disorders.index(no_diagnosis_given)\n",
    "    most_common_disorders = most_common_disorders[:no_diag_index] + \\\n",
    "        most_common_disorders[no_diag_index + 1:]\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while disorder != no_diagnosis_given and not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "    order_of_disorders.append(disorders_patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2813 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2808  NDARZZ007YMP                                         0   \n",
       "2809  NDARZZ740MLM                                         1   \n",
       "2810  NDARZZ810LVF                                         0   \n",
       "2811  NDARZZ830JM7                                         0   \n",
       "2812  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2808                  0                           0                         1   \n",
       "2809                  0                           0                         0   \n",
       "2810                  0                           0                         1   \n",
       "2811                  0                           0                         1   \n",
       "2812                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       1                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "2808           0                       0                     0  \n",
       "2809           0                       0                     0  \n",
       "2810           0                       1                     0  \n",
       "2811           0                       0                     0  \n",
       "2812           0                       0                     0  \n",
       "\n",
       "[2813 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=behaviour_data[[\"IDs\"]+list(most_common_disorders)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>2651</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>5.960983e-06</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>7.428434e-02</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>9.411772e-02</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>3.789685e-01</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>1.676998e-01</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>8.206176e-11</td>\n",
       "      <td>1.191276e-08</td>\n",
       "      <td>9.842314e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.155558</td>\n",
       "      <td>0.287815</td>\n",
       "      <td>0.314661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.788340</td>\n",
       "      <td>1.573205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>3.062358e-04</td>\n",
       "      <td>1.130883e-03</td>\n",
       "      <td>3.834623e-03</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.032255</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.108455</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333760</td>\n",
       "      <td>1.423824</td>\n",
       "      <td>1.381199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1.556547e-05</td>\n",
       "      <td>2.900630e-04</td>\n",
       "      <td>3.548476e-03</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.189421</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.445277</td>\n",
       "      <td>0.644915</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>1.949453e-01</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>9.555112e-02</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows × 6757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "1830             8.206176e-11             1.191276e-08   \n",
       "1831             3.062358e-04             1.130883e-03   \n",
       "1832             1.556547e-05             2.900630e-04   \n",
       "1833             2.303407e-04             2.867255e-02   \n",
       "1834             6.411911e-03             2.687961e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                5.960983e-06                 0.001066   \n",
       "1                7.428434e-02                 0.216988   \n",
       "2                9.411772e-02                 0.367821   \n",
       "3                3.789685e-01                 0.299813   \n",
       "4                1.676998e-01                 0.368840   \n",
       "...                       ...                      ...   \n",
       "1830             9.842314e-07                 0.000039   \n",
       "1831             3.834623e-03                 0.009994   \n",
       "1832             3.548476e-03                 0.023882   \n",
       "1833             1.949453e-01                 0.081646   \n",
       "1834             9.555112e-02                 0.241121   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "1830                 0.000736                 0.006939   \n",
       "1831                 0.020117                 0.032255   \n",
       "1832                 0.088943                 0.189421   \n",
       "1833                 0.018422                 0.076959   \n",
       "1834                 0.434011                 0.574767   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "1830                 0.040446                 0.155558   \n",
       "1831                 0.051099                 0.085125   \n",
       "1832                 0.293481                 0.445277   \n",
       "1833                 0.179779                 0.300051   \n",
       "1834                 0.694741                 0.815939   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...      2651  \\\n",
       "0                    0.593581                  0.401686  ...  0.179322   \n",
       "1                    0.049898                  0.004720  ...  0.448476   \n",
       "2                    0.526883                  0.511715  ...  0.545169   \n",
       "3                    0.003988                  0.061608  ...  0.339304   \n",
       "4                    0.233210                  0.125520  ...  0.013197   \n",
       "...                       ...                       ...  ...       ...   \n",
       "1830                 0.287815                  0.314661  ...  0.128389   \n",
       "1831                 0.108455                  0.129148  ...  0.333760   \n",
       "1832                 0.644915                  0.577096  ...  0.367943   \n",
       "1833                 0.417245                  0.459853  ...  0.008403   \n",
       "1834                 0.678021                  0.490314  ...  0.373653   \n",
       "\n",
       "      Intercept     Slope  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0      0.986272  1.825774                                         0   \n",
       "1      1.486650  1.888544                                         1   \n",
       "2      1.593155  2.095749                                         1   \n",
       "3      0.703331  1.724831                                         1   \n",
       "4      0.918020  1.749441                                         1   \n",
       "...         ...       ...                                       ...   \n",
       "1830   0.788340  1.573205                                         1   \n",
       "1831   1.423824  1.381199                                         0   \n",
       "1832   0.168009  0.205704                                         0   \n",
       "1833   1.351549  1.996940                                         1   \n",
       "1834   0.781225  1.470061                                         1   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     0                           1                         1   \n",
       "4                     0                           0                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "1830                  0                           0                         0   \n",
       "1831                  0                           0                         0   \n",
       "1832                  1                           0                         0   \n",
       "1833                  1                           0                         0   \n",
       "1834                  0                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       0                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "1830           0                       0                     0  \n",
       "1831           0                       0                     0  \n",
       "1832           0                       0                     0  \n",
       "1833           0                       0                     1  \n",
       "1834           0                       0                     0  \n",
       "\n",
       "[1835 rows x 6757 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df2, on='IDs', how='inner')\n",
    "df = pd.merge(df, foof, on='IDs', how='inner')\n",
    "df = pd.merge(df, labels, on='IDs', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1835, 6749) (1835, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_789994/3799954537.py:1: RuntimeWarning: '<' not supported between instances of 'int' and 'tuple', sort order is undefined for incomparable objects\n",
      "  x = df[df.columns.difference(['IDs']+most_common_disorders)]\n"
     ]
    }
   ],
   "source": [
    "x = df[df.columns.difference(['IDs']+most_common_disorders)]\n",
    "y = df[most_common_disorders]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 12:22:24.468538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-23 12:22:24.491217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.491881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-23 12:22:24.492086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-23 12:22:24.493435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-23 12:22:24.494860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-23 12:22:24.495071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-23 12:22:24.496434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-23 12:22:24.497189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-23 12:22:24.500079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-23 12:22:24.500238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.500952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.501584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-23 12:22:24.502578: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-11-23 12:22:24.508370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-11-23 12:22:24.508864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ac04e15f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-23 12:22:24.508874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-23 12:22:24.509038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.509706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-23 12:22:24.509751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-23 12:22:24.509765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-23 12:22:24.509776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-23 12:22:24.509787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-23 12:22:24.509797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-23 12:22:24.509807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-23 12:22:24.509817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-23 12:22:24.509873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.510523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.511121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-23 12:22:24.511149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-23 12:22:24.588755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-23 12:22:24.588784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-23 12:22:24.588789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-23 12:22:24.589059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.589740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.590358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 12:22:24.590966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14109 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-11-23 12:22:24.592719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ac04e4cb50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-23 12:22:24.592730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 12:22:26.165863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 - 6s - loss: 31.3407\n",
      "Epoch 2/50\n",
      "81/81 - 6s - loss: 0.2466\n",
      "Epoch 3/50\n",
      "81/81 - 6s - loss: 0.3105\n",
      "Epoch 4/50\n",
      "81/81 - 6s - loss: 0.2562\n",
      "Epoch 5/50\n",
      "81/81 - 6s - loss: 0.2890\n",
      "Epoch 6/50\n",
      "81/81 - 6s - loss: 0.2629\n",
      "Epoch 7/50\n",
      "81/81 - 6s - loss: 0.2889\n",
      "Epoch 8/50\n",
      "81/81 - 6s - loss: 0.2498\n",
      "Epoch 9/50\n",
      "81/81 - 6s - loss: 0.2564\n",
      "Epoch 10/50\n",
      "81/81 - 6s - loss: 0.3122\n",
      "Epoch 11/50\n",
      "81/81 - 6s - loss: 0.2861\n",
      "Epoch 12/50\n",
      "81/81 - 6s - loss: 0.2934\n",
      "Epoch 13/50\n",
      "81/81 - 6s - loss: 0.3284\n",
      "Epoch 14/50\n",
      "81/81 - 6s - loss: 0.3032\n",
      "Epoch 15/50\n",
      "81/81 - 6s - loss: 0.3363\n",
      "Epoch 16/50\n",
      "81/81 - 6s - loss: 0.3467\n",
      "Epoch 17/50\n",
      "81/81 - 6s - loss: 0.3250\n",
      "Epoch 18/50\n",
      "81/81 - 6s - loss: 0.2956\n",
      "Epoch 19/50\n",
      "81/81 - 6s - loss: 0.4080\n",
      "Epoch 20/50\n",
      "81/81 - 6s - loss: 0.3013\n",
      "Epoch 21/50\n",
      "81/81 - 6s - loss: 0.3866\n",
      "Epoch 22/50\n",
      "81/81 - 6s - loss: 0.3271\n",
      "Epoch 23/50\n",
      "81/81 - 6s - loss: 0.3488\n",
      "Epoch 24/50\n",
      "81/81 - 6s - loss: 0.3972\n",
      "Epoch 25/50\n",
      "81/81 - 6s - loss: 0.2978\n",
      "Epoch 26/50\n",
      "81/81 - 6s - loss: 0.3203\n",
      "Epoch 27/50\n",
      "81/81 - 6s - loss: 0.3473\n",
      "Epoch 28/50\n",
      "81/81 - 6s - loss: 0.2910\n",
      "Epoch 29/50\n",
      "81/81 - 6s - loss: 0.3040\n",
      "Epoch 30/50\n",
      "81/81 - 6s - loss: 0.3094\n",
      "Epoch 31/50\n",
      "81/81 - 6s - loss: 0.3938\n",
      "Epoch 32/50\n",
      "81/81 - 6s - loss: 0.3779\n",
      "Epoch 33/50\n",
      "81/81 - 6s - loss: 0.3052\n",
      "Epoch 34/50\n",
      "81/81 - 6s - loss: 0.3280\n",
      "Epoch 35/50\n",
      "81/81 - 6s - loss: 0.3909\n",
      "Epoch 36/50\n",
      "81/81 - 6s - loss: 0.3326\n",
      "Epoch 37/50\n",
      "81/81 - 6s - loss: 0.3068\n",
      "Epoch 38/50\n",
      "81/81 - 6s - loss: 0.3586\n",
      "Epoch 39/50\n",
      "81/81 - 6s - loss: 0.3702\n",
      "Epoch 40/50\n",
      "81/81 - 6s - loss: 0.2996\n",
      "Epoch 41/50\n",
      "81/81 - 6s - loss: 0.3253\n",
      "Epoch 42/50\n",
      "81/81 - 6s - loss: 0.3230\n",
      "Epoch 43/50\n",
      "81/81 - 6s - loss: 0.2995\n",
      "Epoch 44/50\n",
      "81/81 - 6s - loss: 0.3331\n",
      "Epoch 45/50\n",
      "81/81 - 6s - loss: 0.3431\n",
      "Epoch 46/50\n",
      "81/81 - 6s - loss: 0.3163\n",
      "Epoch 47/50\n",
      "81/81 - 6s - loss: 0.3598\n",
      "Epoch 48/50\n",
      "81/81 - 6s - loss: 0.3199\n",
      "Epoch 49/50\n",
      "81/81 - 6s - loss: 0.3423\n",
      "Epoch 50/50\n",
      "81/81 - 6s - loss: 0.3555\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "n_inputs = train_features.shape[1]\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "output = Dense(7, activation='linear')(d)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=50, batch_size=16, verbose=2)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "encoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "encoder= load_model('autoencoder.h5', compile=False)\n",
    "\n",
    "train_features = encoder.predict(train_features)\n",
    "test_features = encoder.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))\n",
    "\n",
    "def evaluate(y_test, y_pred_prob, brier=True):\n",
    "    y_pred = y_pred_prob.round()\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    if brier:\n",
    "        print(\"Brier Score:\", brier_multi(y_test, y_pred_prob))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.10707803992740472\n",
      "Hamming Loss: 0.25200933367902517\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       358\n",
      "           1       0.39      0.21      0.27       186\n",
      "           2       0.25      0.16      0.19       128\n",
      "           3       0.10      0.02      0.04        83\n",
      "           4       0.08      0.02      0.04        81\n",
      "           5       0.00      0.00      0.00        75\n",
      "           6       0.33      0.03      0.06        61\n",
      "\n",
      "   micro avg       0.50      0.31      0.38       972\n",
      "   macro avg       0.26      0.16      0.18       972\n",
      "weighted avg       0.38      0.31      0.33       972\n",
      " samples avg       0.66      0.41      0.34       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 71 122]\n",
      "  [124 234]]\n",
      "\n",
      " [[303  62]\n",
      "  [147  39]]\n",
      "\n",
      " [[362  61]\n",
      "  [108  20]]\n",
      "\n",
      " [[449  19]\n",
      "  [ 81   2]]\n",
      "\n",
      " [[447  23]\n",
      "  [ 79   2]]\n",
      "\n",
      " [[468   8]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[486   4]\n",
      "  [ 59   2]]]\n",
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.11433756805807622\n",
      "Hamming Loss: 0.24630541871921183\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67       358\n",
      "           1       0.33      0.16      0.22       186\n",
      "           2       0.16      0.05      0.08       128\n",
      "           3       0.14      0.04      0.06        83\n",
      "           4       0.13      0.02      0.04        81\n",
      "           5       0.00      0.00      0.00        75\n",
      "           6       0.50      0.02      0.03        61\n",
      "\n",
      "   micro avg       0.52      0.30      0.38       972\n",
      "   macro avg       0.27      0.14      0.16       972\n",
      "weighted avg       0.38      0.30      0.31       972\n",
      " samples avg       0.67      0.40      0.33       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 60 133]\n",
      "  [113 245]]\n",
      "\n",
      " [[305  60]\n",
      "  [156  30]]\n",
      "\n",
      " [[387  36]\n",
      "  [121   7]]\n",
      "\n",
      " [[450  18]\n",
      "  [ 80   3]]\n",
      "\n",
      " [[457  13]\n",
      "  [ 79   2]]\n",
      "\n",
      " [[471   5]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[489   1]\n",
      "  [ 60   1]]]\n",
      "SVC():\n",
      "Accuracy: 0.15245009074410162\n",
      "Hamming Loss: 0.21960072595281308\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71       358\n",
      "           1       1.00      0.00      0.00       186\n",
      "           2       1.00      0.00      0.00       128\n",
      "           3       1.00      0.00      0.00        83\n",
      "           4       1.00      0.00      0.00        81\n",
      "           5       1.00      0.00      0.00        75\n",
      "           6       1.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.64      0.29      0.40       972\n",
      "   macro avg       0.95      0.11      0.10       972\n",
      "weighted avg       0.87      0.29      0.26       972\n",
      " samples avg       0.71      0.40      0.37       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 35 158]\n",
      "  [ 75 283]]\n",
      "\n",
      " [[365   0]\n",
      "  [186   0]]\n",
      "\n",
      " [[423   0]\n",
      "  [128   0]]\n",
      "\n",
      " [[468   0]\n",
      "  [ 83   0]]\n",
      "\n",
      " [[470   0]\n",
      "  [ 81   0]]\n",
      "\n",
      " [[476   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[490   0]\n",
      "  [ 61   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels, brier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.5943\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.0490\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 1.4105\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.8031\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6950\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7385\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7728\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5479\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6067\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6473\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7784\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6970\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6073\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6596\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6521\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6948\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6674\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5897\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5947\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7460\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7012\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6468\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.5768\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5191\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5028\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6512\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5670\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5698\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5344\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5897\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5417\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6159\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6587\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5942\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4827\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5318\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4620\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.6302\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5536\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5170\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7283\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5099\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4865\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5145\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5431\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4776\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4203\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4728\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4352\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4772\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4502\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4628\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4602\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4983\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4435\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4464\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5011\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4647\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4381\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4313\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4122\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4136\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4656\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4475\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5397\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4227\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4248\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4400\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4153\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4139\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4697\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4367\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4176\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5683\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.5004\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3993\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4551\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4033\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4098\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4048\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4011\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4199\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4688\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3910\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4468\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.7772\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4315\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3937\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3800\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4041\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3977\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4081\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3898\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4003\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3809\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3807\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3931\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.4706\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e97e04430>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = train_features.shape[1],train_labels.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12159709618874773\n",
      "Hamming Loss: 0.2556390977443609\n",
      "Brier Score: 1.4376173605522033\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.67       358\n",
      "           1       0.39      0.20      0.26       186\n",
      "           2       0.26      0.14      0.18       128\n",
      "           3       0.07      0.01      0.02        83\n",
      "           4       0.16      0.14      0.15        81\n",
      "           5       0.20      0.03      0.05        75\n",
      "           6       0.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.49      0.33      0.40       972\n",
      "   macro avg       0.25      0.18      0.19       972\n",
      "weighted avg       0.38      0.33      0.34       972\n",
      " samples avg       0.61      0.44      0.36       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 48 145]\n",
      "  [102 256]]\n",
      "\n",
      " [[307  58]\n",
      "  [149  37]]\n",
      "\n",
      " [[372  51]\n",
      "  [110  18]]\n",
      "\n",
      " [[454  14]\n",
      "  [ 82   1]]\n",
      "\n",
      " [[413  57]\n",
      "  [ 70  11]]\n",
      "\n",
      " [[468   8]\n",
      "  [ 73   2]]\n",
      "\n",
      " [[484   6]\n",
      "  [ 61   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.007259528130671506\n",
      "Hamming Loss: 0.5346123930515945\n",
      "Brier Score: 3.7355384675448953\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.17      0.28       358\n",
      "           1       0.34      0.82      0.48       186\n",
      "           2       0.25      0.79      0.38       128\n",
      "           3       0.17      0.19      0.18        83\n",
      "           4       0.17      0.85      0.28        81\n",
      "           5       0.14      0.25      0.18        75\n",
      "           6       0.11      0.84      0.20        61\n",
      "\n",
      "   micro avg       0.23      0.48      0.31       972\n",
      "   macro avg       0.27      0.56      0.28       972\n",
      "weighted avg       0.41      0.48      0.31       972\n",
      " samples avg       0.24      0.52      0.28       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[169  24]\n",
      "  [296  62]]\n",
      "\n",
      " [[ 68 297]\n",
      "  [ 34 152]]\n",
      "\n",
      " [[124 299]\n",
      "  [ 27 101]]\n",
      "\n",
      " [[388  80]\n",
      "  [ 67  16]]\n",
      "\n",
      " [[125 345]\n",
      "  [ 12  69]]\n",
      "\n",
      " [[362 114]\n",
      "  [ 56  19]]\n",
      "\n",
      " [[ 89 401]\n",
      "  [ 10  51]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_br.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11252268602540835\n",
      "Hamming Loss: 0.2470832253046409\n",
      "Brier Score: 1.416820954076066\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       358\n",
      "           1       0.44      0.22      0.29       186\n",
      "           2       0.25      0.16      0.19       128\n",
      "           3       0.22      0.07      0.11        83\n",
      "           4       0.10      0.02      0.04        81\n",
      "           5       0.00      0.00      0.00        75\n",
      "           6       0.36      0.07      0.11        61\n",
      "\n",
      "   micro avg       0.52      0.31      0.39       972\n",
      "   macro avg       0.29      0.17      0.20       972\n",
      "weighted avg       0.41      0.31      0.34       972\n",
      " samples avg       0.66      0.41      0.35       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 71 122]\n",
      "  [124 234]]\n",
      "\n",
      " [[315  50]\n",
      "  [146  40]]\n",
      "\n",
      " [[362  61]\n",
      "  [108  20]]\n",
      "\n",
      " [[447  21]\n",
      "  [ 77   6]]\n",
      "\n",
      " [[452  18]\n",
      "  [ 79   2]]\n",
      "\n",
      " [[468   8]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[483   7]\n",
      "  [ 57   4]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12704174228675136\n",
      "Hamming Loss: 0.24423126782473426\n",
      "Brier Score: 1.2630929109134257\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       358\n",
      "           1       0.32      0.23      0.27       186\n",
      "           2       0.23      0.09      0.13       128\n",
      "           3       0.25      0.02      0.04        83\n",
      "           4       0.40      0.02      0.05        81\n",
      "           5       0.00      0.00      0.00        75\n",
      "           6       1.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       0.53      0.31      0.39       972\n",
      "   macro avg       0.41      0.15      0.16       972\n",
      "weighted avg       0.45      0.31      0.32       972\n",
      " samples avg       0.64      0.42      0.35       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 57 136]\n",
      "  [112 246]]\n",
      "\n",
      " [[277  88]\n",
      "  [144  42]]\n",
      "\n",
      " [[383  40]\n",
      "  [116  12]]\n",
      "\n",
      " [[462   6]\n",
      "  [ 81   2]]\n",
      "\n",
      " [[467   3]\n",
      "  [ 79   2]]\n",
      "\n",
      " [[475   1]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[490   0]\n",
      "  [ 61   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ai4halth/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLkNN()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "mlknn = MLkNN(k=10)\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "\n",
    "mlknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1088929219600726\n",
      "Hamming Loss: 0.25200933367902517\n",
      "Brier Score: 1.5887864326092693\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       358\n",
      "           1       1.00      0.00      0.00       186\n",
      "           2       1.00      0.00      0.00       128\n",
      "           3       1.00      0.00      0.00        83\n",
      "           4       1.00      0.00      0.00        81\n",
      "           5       1.00      0.00      0.00        75\n",
      "           6       1.00      0.00      0.00        61\n",
      "\n",
      "   micro avg       1.00      0.00      0.00       972\n",
      "   macro avg       1.00      0.00      0.00       972\n",
      "weighted avg       1.00      0.00      0.00       972\n",
      " samples avg       1.00      0.11      0.11       972\n",
      "\n",
      "Confusion matrix:\n",
      " [[[193   0]\n",
      "  [358   0]]\n",
      "\n",
      " [[365   0]\n",
      "  [186   0]]\n",
      "\n",
      " [[423   0]\n",
      "  [128   0]]\n",
      "\n",
      " [[468   0]\n",
      "  [ 83   0]]\n",
      "\n",
      " [[470   0]\n",
      "  [ 81   0]]\n",
      "\n",
      " [[476   0]\n",
      "  [ 75   0]]\n",
      "\n",
      " [[490   0]\n",
      "  [ 61   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlknn = mlknn.predict_proba(x_test)\n",
    "evaluate(test_labels, predicted_labels_mlknn.todense())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
