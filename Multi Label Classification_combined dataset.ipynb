{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()) and \"anuja\" in os.environ.get('USER'):\n",
    "    DATA_DIR = 'data/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA948VFH</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>NDARZN277NR6</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>NDARZN578YDP</td>\n",
       "      <td>1.380795</td>\n",
       "      <td>2.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>NDARZN610GTY</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>1.050644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>NDARZN677EYE</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>NDARZN899JCM</td>\n",
       "      <td>0.464107</td>\n",
       "      <td>1.664433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Intercept     Slope\n",
       "0     NDARAA075AMK   0.986272  1.825774\n",
       "1     NDARAA112DMH   1.486650  1.888544\n",
       "2     NDARAA117NEJ   1.593155  2.095749\n",
       "3     NDARAA947ZG5   0.703331  1.724831\n",
       "4     NDARAA948VFH   0.918020  1.749441\n",
       "...            ...        ...       ...\n",
       "2037  NDARZN277NR6   1.351549  1.996940\n",
       "2038  NDARZN578YDP   1.380795  2.036327\n",
       "2039  NDARZN610GTY   0.339229  1.050644\n",
       "2040  NDARZN677EYE   0.781225  1.470061\n",
       "2041  NDARZN899JCM   0.464107  1.664433\n",
       "\n",
       "[2042 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foof = pd.read_csv(DATA_DIR+\"foof2features.csv\")\n",
    "foof = foof.rename(columns={\"C1\": \"IDs\" ,\"C2\": \"Intercept\", \"C3\": \"Slope\"})\n",
    "foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Electrode 105 - 31/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 32/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 33/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 34/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 35/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 36/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 37/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 38/2 Hz,)</th>\n",
       "      <th>(Electrode 105 - 39/2 Hz,)</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.333844e-07</td>\n",
       "      <td>9.373567e-08</td>\n",
       "      <td>1.616373e-08</td>\n",
       "      <td>3.256580e-09</td>\n",
       "      <td>4.986456e-10</td>\n",
       "      <td>7.457518e-11</td>\n",
       "      <td>1.130004e-11</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>0.074284</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>2.352137e-03</td>\n",
       "      <td>4.122513e-04</td>\n",
       "      <td>4.825197e-05</td>\n",
       "      <td>5.944433e-06</td>\n",
       "      <td>5.749150e-07</td>\n",
       "      <td>6.398086e-08</td>\n",
       "      <td>8.415637e-09</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.045964e-05</td>\n",
       "      <td>4.443460e-06</td>\n",
       "      <td>7.491343e-07</td>\n",
       "      <td>1.436770e-07</td>\n",
       "      <td>2.039047e-08</td>\n",
       "      <td>2.751924e-09</td>\n",
       "      <td>3.663748e-10</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.150551</td>\n",
       "      <td>1.580043e-01</td>\n",
       "      <td>1.518115e-01</td>\n",
       "      <td>1.233778e-01</td>\n",
       "      <td>1.242931e-01</td>\n",
       "      <td>1.009636e-01</td>\n",
       "      <td>8.498748e-02</td>\n",
       "      <td>7.690149e-02</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093399</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>4.012462e-02</td>\n",
       "      <td>2.464919e-02</td>\n",
       "      <td>1.257993e-02</td>\n",
       "      <td>7.816617e-03</td>\n",
       "      <td>3.846395e-03</td>\n",
       "      <td>1.926406e-03</td>\n",
       "      <td>1.018633e-03</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>1.385606e-02</td>\n",
       "      <td>2.124126e-02</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.048827</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.222227</td>\n",
       "      <td>0.444972</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>5.877454e-03</td>\n",
       "      <td>3.190797e-03</td>\n",
       "      <td>1.418509e-03</td>\n",
       "      <td>7.564419e-04</td>\n",
       "      <td>3.146594e-04</td>\n",
       "      <td>1.311957e-04</td>\n",
       "      <td>5.687030e-05</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1.089647e-02</td>\n",
       "      <td>3.749309e-02</td>\n",
       "      <td>0.139003</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.304728</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.342653</td>\n",
       "      <td>0.413368</td>\n",
       "      <td>0.344024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>1.169173e-02</td>\n",
       "      <td>4.410850e-03</td>\n",
       "      <td>1.294309e-03</td>\n",
       "      <td>4.329110e-04</td>\n",
       "      <td>1.073561e-04</td>\n",
       "      <td>2.536768e-05</td>\n",
       "      <td>5.924775e-06</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2.695401e-03</td>\n",
       "      <td>5.553206e-02</td>\n",
       "      <td>0.315364</td>\n",
       "      <td>0.444302</td>\n",
       "      <td>0.321718</td>\n",
       "      <td>0.232912</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.178452</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.280580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NDARZN899JCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "2037             2.303407e-04             2.867255e-02   \n",
       "2038             1.385606e-02             2.124126e-02   \n",
       "2039             1.089647e-02             3.749309e-02   \n",
       "2040             6.411911e-03             2.687961e-02   \n",
       "2041             2.695401e-03             5.553206e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                    0.000006                 0.001066   \n",
       "1                    0.074284                 0.216988   \n",
       "2                    0.094118                 0.367821   \n",
       "3                    0.378969                 0.299813   \n",
       "4                    0.167700                 0.368840   \n",
       "...                       ...                      ...   \n",
       "2037                 0.194945                 0.081646   \n",
       "2038                 0.032991                 0.043456   \n",
       "2039                 0.139003                 0.289797   \n",
       "2040                 0.095551                 0.241121   \n",
       "2041                 0.315364                 0.444302   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "2037                 0.018422                 0.076959   \n",
       "2038                 0.048827                 0.049759   \n",
       "2039                 0.304728                 0.196113   \n",
       "2040                 0.434011                 0.574767   \n",
       "2041                 0.321718                 0.232912   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "2037                 0.179779                 0.300051   \n",
       "2038                 0.074988                 0.222227   \n",
       "2039                 0.191950                 0.342653   \n",
       "2040                 0.694741                 0.815939   \n",
       "2041                 0.152557                 0.178452   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...  \\\n",
       "0                    0.593581                  0.401686  ...   \n",
       "1                    0.049898                  0.004720  ...   \n",
       "2                    0.526883                  0.511715  ...   \n",
       "3                    0.003988                  0.061608  ...   \n",
       "4                    0.233210                  0.125520  ...   \n",
       "...                       ...                       ...  ...   \n",
       "2037                 0.417245                  0.459853  ...   \n",
       "2038                 0.444972                  0.464653  ...   \n",
       "2039                 0.413368                  0.344024  ...   \n",
       "2040                 0.678021                  0.490314  ...   \n",
       "2041                 0.289553                  0.280580  ...   \n",
       "\n",
       "      (Electrode 105 - 31/2 Hz,)  (Electrode 105 - 32/2 Hz,)  \\\n",
       "0                       0.000007                    0.000002   \n",
       "1                       0.031636                    0.009416   \n",
       "2                       0.000311                    0.000079   \n",
       "3                       0.158691                    0.150551   \n",
       "4                       0.000000                    0.000000   \n",
       "...                          ...                         ...   \n",
       "2037                    0.093399                    0.058729   \n",
       "2038                    0.016832                    0.009602   \n",
       "2039                    0.000000                    0.000000   \n",
       "2040                    0.059230                    0.026090   \n",
       "2041                    0.000000                    0.000000   \n",
       "\n",
       "      (Electrode 105 - 33/2 Hz,)  (Electrode 105 - 34/2 Hz,)  \\\n",
       "0                   4.333844e-07                9.373567e-08   \n",
       "1                   2.352137e-03                4.122513e-04   \n",
       "2                   2.045964e-05                4.443460e-06   \n",
       "3                   1.580043e-01                1.518115e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                4.012462e-02                2.464919e-02   \n",
       "2038                5.877454e-03                3.190797e-03   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.169173e-02                4.410850e-03   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 35/2 Hz,)  (Electrode 105 - 36/2 Hz,)  \\\n",
       "0                   1.616373e-08                3.256580e-09   \n",
       "1                   4.825197e-05                5.944433e-06   \n",
       "2                   7.491343e-07                1.436770e-07   \n",
       "3                   1.233778e-01                1.242931e-01   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                1.257993e-02                7.816617e-03   \n",
       "2038                1.418509e-03                7.564419e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.294309e-03                4.329110e-04   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 37/2 Hz,)  (Electrode 105 - 38/2 Hz,)  \\\n",
       "0                   4.986456e-10                7.457518e-11   \n",
       "1                   5.749150e-07                6.398086e-08   \n",
       "2                   2.039047e-08                2.751924e-09   \n",
       "3                   1.009636e-01                8.498748e-02   \n",
       "4                   0.000000e+00                0.000000e+00   \n",
       "...                          ...                         ...   \n",
       "2037                3.846395e-03                1.926406e-03   \n",
       "2038                3.146594e-04                1.311957e-04   \n",
       "2039                0.000000e+00                0.000000e+00   \n",
       "2040                1.073561e-04                2.536768e-05   \n",
       "2041                0.000000e+00                0.000000e+00   \n",
       "\n",
       "      (Electrode 105 - 39/2 Hz,)           IDs  \n",
       "0                   1.130004e-11  NDARAA075AMK  \n",
       "1                   8.415637e-09  NDARAA112DMH  \n",
       "2                   3.663748e-10  NDARAA117NEJ  \n",
       "3                   7.690149e-02  NDARAA947ZG5  \n",
       "4                   0.000000e+00  NDARAA948VFH  \n",
       "...                          ...           ...  \n",
       "2037                1.018633e-03  NDARZN277NR6  \n",
       "2038                5.687030e-05  NDARZN578YDP  \n",
       "2039                0.000000e+00  NDARZN610GTY  \n",
       "2040                5.924775e-06  NDARZN677EYE  \n",
       "2041                0.000000e+00  NDARZN899JCM  \n",
       "\n",
       "[2042 rows x 4096 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df = np.array(df).reshape(data['x'].shape)\n",
    "df_sparsed = np.concatenate([np.expand_dims(df[:,:,i:i+2].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-2, 2)], axis = 2)\n",
    "df = pd.DataFrame(df_sparsed.reshape((df_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df)\n",
    "df = norm.transform(df)\n",
    "df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "\n",
    "columns = np.asarray([['Electrode %d - %d/2 Hz'%(i+1, j+1)] for i in range(df_sparsed.shape[1]) for j in range(df_sparsed.shape[2])])\n",
    "df.columns = columns\n",
    "df['IDs'] = foof['IDs']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2643</th>\n",
       "      <th>2644</th>\n",
       "      <th>2645</th>\n",
       "      <th>2646</th>\n",
       "      <th>2647</th>\n",
       "      <th>2648</th>\n",
       "      <th>2649</th>\n",
       "      <th>2650</th>\n",
       "      <th>2651</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.497571e-01</td>\n",
       "      <td>4.585819e-01</td>\n",
       "      <td>2.938905e-01</td>\n",
       "      <td>3.770603e-01</td>\n",
       "      <td>0.327764</td>\n",
       "      <td>0.552059</td>\n",
       "      <td>0.462017</td>\n",
       "      <td>0.695207</td>\n",
       "      <td>0.642190</td>\n",
       "      <td>0.584085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337358</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.364673</td>\n",
       "      <td>0.405482</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.428504</td>\n",
       "      <td>0.250803</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>NDARAA075AMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.464767e-01</td>\n",
       "      <td>9.048637e-01</td>\n",
       "      <td>5.054438e-01</td>\n",
       "      <td>7.021925e-01</td>\n",
       "      <td>0.498947</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.321952</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.478879</td>\n",
       "      <td>0.304577</td>\n",
       "      <td>0.360859</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>NDARAA112DMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.204578e-01</td>\n",
       "      <td>3.562272e-01</td>\n",
       "      <td>3.895027e-01</td>\n",
       "      <td>4.181956e-01</td>\n",
       "      <td>0.495129</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446757</td>\n",
       "      <td>0.528172</td>\n",
       "      <td>0.409405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404292</td>\n",
       "      <td>0.339923</td>\n",
       "      <td>0.505282</td>\n",
       "      <td>0.340129</td>\n",
       "      <td>0.203517</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.341549</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.346560e-02</td>\n",
       "      <td>1.204557e-01</td>\n",
       "      <td>1.650503e-01</td>\n",
       "      <td>7.631559e-01</td>\n",
       "      <td>0.523793</td>\n",
       "      <td>0.399243</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.301397</td>\n",
       "      <td>0.283535</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.111156</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>NDARAA947ZG5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.758219e-01</td>\n",
       "      <td>2.255777e-01</td>\n",
       "      <td>4.828928e-01</td>\n",
       "      <td>4.704279e-01</td>\n",
       "      <td>0.330692</td>\n",
       "      <td>0.310594</td>\n",
       "      <td>0.284202</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164094</td>\n",
       "      <td>0.161737</td>\n",
       "      <td>0.123381</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.043857</td>\n",
       "      <td>0.029212</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>NDARAA948VFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>3.394601e-01</td>\n",
       "      <td>4.781692e-01</td>\n",
       "      <td>5.423877e-01</td>\n",
       "      <td>4.137127e-01</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.538537</td>\n",
       "      <td>0.457002</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>0.222562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268739</td>\n",
       "      <td>0.328251</td>\n",
       "      <td>0.327389</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.367808</td>\n",
       "      <td>0.346005</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>NDARZN148PMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1.072605e-01</td>\n",
       "      <td>2.045245e-01</td>\n",
       "      <td>2.610531e-01</td>\n",
       "      <td>3.236518e-01</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.432447</td>\n",
       "      <td>0.412152</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.374603</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451919</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.125819</td>\n",
       "      <td>0.083812</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>0.378008</td>\n",
       "      <td>0.264043</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NDARZN277NR6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>2.801818e-01</td>\n",
       "      <td>3.838379e-01</td>\n",
       "      <td>3.575040e-01</td>\n",
       "      <td>3.295642e-01</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.263007</td>\n",
       "      <td>0.204378</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>0.319891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>0.543971</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>0.544979</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>0.589517</td>\n",
       "      <td>0.634712</td>\n",
       "      <td>0.549726</td>\n",
       "      <td>NDARZN578YDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>3.260273e-15</td>\n",
       "      <td>3.373362e-14</td>\n",
       "      <td>2.304057e-13</td>\n",
       "      <td>1.498324e-12</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.142998</td>\n",
       "      <td>0.689837</td>\n",
       "      <td>0.800874</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.132429</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.061278</td>\n",
       "      <td>0.049636</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>NDARZN610GTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>3.945258e-01</td>\n",
       "      <td>4.017071e-01</td>\n",
       "      <td>2.867999e-01</td>\n",
       "      <td>3.721533e-01</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.302516</td>\n",
       "      <td>0.193872</td>\n",
       "      <td>0.343920</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299387</td>\n",
       "      <td>0.416947</td>\n",
       "      <td>0.446031</td>\n",
       "      <td>0.404021</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.437301</td>\n",
       "      <td>0.412550</td>\n",
       "      <td>0.745395</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>NDARZN677EYE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2041 rows × 2653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3         4  \\\n",
       "0     3.497571e-01  4.585819e-01  2.938905e-01  3.770603e-01  0.327764   \n",
       "1     7.464767e-01  9.048637e-01  5.054438e-01  7.021925e-01  0.498947   \n",
       "2     2.204578e-01  3.562272e-01  3.895027e-01  4.181956e-01  0.495129   \n",
       "3     6.346560e-02  1.204557e-01  1.650503e-01  7.631559e-01  0.523793   \n",
       "4     2.758219e-01  2.255777e-01  4.828928e-01  4.704279e-01  0.330692   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "2036  3.394601e-01  4.781692e-01  5.423877e-01  4.137127e-01  0.379793   \n",
       "2037  1.072605e-01  2.045245e-01  2.610531e-01  3.236518e-01  0.437417   \n",
       "2038  2.801818e-01  3.838379e-01  3.575040e-01  3.295642e-01  0.339077   \n",
       "2039  3.260273e-15  3.373362e-14  2.304057e-13  1.498324e-12  0.000009   \n",
       "2040  3.945258e-01  4.017071e-01  2.867999e-01  3.721533e-01  0.583645   \n",
       "\n",
       "             5         6         7         8         9  ...      2643  \\\n",
       "0     0.552059  0.462017  0.695207  0.642190  0.584085  ...  0.337358   \n",
       "1     0.342338  0.283478  0.221679  0.178758  0.178338  ...  0.430404   \n",
       "2     0.436858  0.392300  0.446757  0.528172  0.409405  ...  0.404292   \n",
       "3     0.399243  0.267432  0.301397  0.283535  0.363612  ...  0.108138   \n",
       "4     0.310594  0.284202  0.298111  0.245370  0.250187  ...  0.164094   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2036  0.413474  0.538537  0.457002  0.286496  0.222562  ...  0.268739   \n",
       "2037  0.432447  0.412152  0.445771  0.374603  0.386189  ...  0.451919   \n",
       "2038  0.263007  0.204378  0.308062  0.413562  0.319891  ...  0.386920   \n",
       "2039  0.142998  0.689837  0.800874  0.499946  0.248208  ...  0.213887   \n",
       "2040  0.497248  0.302516  0.193872  0.343920  0.500556  ...  0.299387   \n",
       "\n",
       "          2644      2645      2646      2647      2648      2649      2650  \\\n",
       "0     0.439658  0.437051  0.364673  0.405482  0.326733  0.428504  0.250803   \n",
       "1     0.296341  0.321952  0.131375  0.579138  0.478879  0.304577  0.360859   \n",
       "2     0.339923  0.505282  0.340129  0.203517  0.174711  0.341549  0.693619   \n",
       "3     0.049740  0.033945  0.304668  0.111156  0.008791  0.005297  0.266759   \n",
       "4     0.161737  0.123381  0.079693  0.069366  0.043857  0.029212  0.021894   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2036  0.328251  0.327389  0.292491  0.367808  0.346005  0.348895  0.399141   \n",
       "2037  0.240030  0.125819  0.083812  0.289439  0.378008  0.264043  0.502426   \n",
       "2038  0.543971  0.590438  0.544979  0.679570  0.616411  0.589517  0.634712   \n",
       "2039  0.230102  0.189709  0.132429  0.124579  0.085125  0.061278  0.049636   \n",
       "2040  0.416947  0.446031  0.404021  0.493188  0.437301  0.412550  0.745395   \n",
       "\n",
       "          2651           IDs  \n",
       "0     0.179322  NDARAA075AMK  \n",
       "1     0.448476  NDARAA112DMH  \n",
       "2     0.545169  NDARAA117NEJ  \n",
       "3     0.339304  NDARAA947ZG5  \n",
       "4     0.013197  NDARAA948VFH  \n",
       "...        ...           ...  \n",
       "2036  0.367943  NDARZN148PMN  \n",
       "2037  0.008403  NDARZN277NR6  \n",
       "2038  0.549726  NDARZN578YDP  \n",
       "2039  0.032335  NDARZN610GTY  \n",
       "2040  0.373653  NDARZN677EYE  \n",
       "\n",
       "[2041 rows x 2653 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mat73.loadmat(DATA_DIR+'x_source.mat')  \n",
    "df2 = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "\n",
    "# sparsing\n",
    "df2 = np.array(df2).reshape(data['x'].shape) \n",
    "df2_sparsed = np.concatenate([np.expand_dims(df2[:,:,i:i+10].mean(axis = 2), axis = 2) for i in range(0, data['x'].shape[2]-10, 10)], axis = 2)\n",
    "df2 = pd.DataFrame(df2_sparsed.reshape((df2_sparsed.shape[0], -1)))\n",
    "\n",
    "#scaling\n",
    "norm = MinMaxScaler().fit(df2)\n",
    "df2 = norm.transform(df2)\n",
    "df2 = pd.DataFrame(df2.reshape((df2.shape[0], -1)))\n",
    "\n",
    "df2['IDs'] = foof['IDs']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:(3076, 177)\n",
      "After:(2813, 177)\n",
      "Removing 263 patients as their diagnoses were very uncommon.\n"
     ]
    }
   ],
   "source": [
    "beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "print('Before:'+str(beh.shape))\n",
    "\n",
    "most_common_disorders = ['Attention-Deficit/Hyperactivity Disorder', 'Anxiety Disorders', 'Specific Learning Disorder',\n",
    "                         'Autism Spectrum Disorder', 'Disruptive', 'No Diagnosis Given', 'Communication Disorder',\n",
    "                         'Depressive Disorders']\n",
    "\n",
    "# most_common_disorders = ['Other Neurodevelopmental Disorders', 'ADHD-Inattentive Type', 'ADHD-Combined Type', 'Anxiety Disorders', 'No Diagnosis Given', 'Depressive Disorders']\n",
    "\n",
    "category_columns = ['DX_' + str(i).zfill(2) + '_Cat' for i in range(1, 11)] +\\\n",
    "                   ['DX_' + str(i).zfill(2) + '_Sub' for i in range(1, 11)]\n",
    "\n",
    "# find users that have no diagnosis within these top diseases\n",
    "# filtering should cahnge anything as this should also happen at a later stage\n",
    "mask = None\n",
    "for col in category_columns:\n",
    "    mask_col = beh[col].isin(most_common_disorders)\n",
    "    if mask is None:\n",
    "        mask = mask_col\n",
    "    else:\n",
    "        mask = mask | mask_col\n",
    "\n",
    "initial_size = beh.shape[0]\n",
    "beh = beh[mask]\n",
    "beh = beh.reset_index(drop=True)\n",
    "new_size = beh.shape[0]\n",
    "print('After:'+str(beh.shape))\n",
    "print('Removing', initial_size - new_size,\n",
    "      'patients as their diagnoses were very uncommon.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attention-Deficit/Hyperactivity Disorder': 0,\n",
       " 'Anxiety Disorders': 1,\n",
       " 'Specific Learning Disorder': 2,\n",
       " 'Autism Spectrum Disorder': 3,\n",
       " 'Disruptive': 4,\n",
       " 'Communication Disorder': 5,\n",
       " 'Depressive Disorders': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_diagnosis_given = 'No Diagnosis Given'\n",
    "\n",
    "if no_diagnosis_given in most_common_disorders:\n",
    "    no_diag_index = most_common_disorders.index(no_diagnosis_given)\n",
    "    most_common_disorders = most_common_disorders[:no_diag_index] + \\\n",
    "        most_common_disorders[no_diag_index + 1:]\n",
    "\n",
    "diagnoses_to_ids = {disorder: i for i, disorder in enumerate(most_common_disorders)}\n",
    "diagnoses_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disorder(data, row, index):\n",
    "    disorder = data.iloc[row][category_columns[index]]\n",
    "\n",
    "    if disorder == 'Neurodevelopmental Disorders':\n",
    "        disorder = data.iloc[row][category_columns[index + 10]]\n",
    "\n",
    "    return disorder\n",
    "\n",
    "order_of_disorders = []\n",
    "for k in range(beh.shape[0]):\n",
    "    i = 0\n",
    "    disorder = get_disorder(beh, k, i)\n",
    "    disorders_patient = []\n",
    "    while disorder != no_diagnosis_given and not pd.isnull(disorder):\n",
    "        if disorder in diagnoses_to_ids:\n",
    "            if diagnoses_to_ids[disorder] not in disorders_patient:\n",
    "                disorders_patient.append(diagnoses_to_ids[disorder])\n",
    "        i += 1\n",
    "        if i == len(category_columns):\n",
    "            break\n",
    "        disorder = get_disorder(beh, k, i)\n",
    "\n",
    "    order_of_disorders.append(disorders_patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-48b714085ca7>:25: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  behaviour_data_columns = beh.columns.values.astype(np.str)\n"
     ]
    }
   ],
   "source": [
    "max_len_order = np.max([len(x) for x in order_of_disorders])\n",
    "\n",
    "# pad with a new token denoting the pad token\n",
    "pad_token = len(most_common_disorders)\n",
    "bod_token = len(most_common_disorders) + 1\n",
    "eod_token = len(most_common_disorders) + 2\n",
    "\n",
    "order_of_disorders = [[bod_token] + x + [eod_token] + [pad_token] * (max_len_order - len(x)) for x in order_of_disorders]\n",
    "\n",
    "order_of_disorders = np.array(order_of_disorders)\n",
    "\n",
    "classes = np.zeros((len(most_common_disorders),\n",
    "                    beh.shape[0]), dtype=np.int32)\n",
    "\n",
    "df_disorders = beh[category_columns]\n",
    "\n",
    "for i, disorder in enumerate(most_common_disorders):\n",
    "    mask = df_disorders.select_dtypes(include=[object]). \\\n",
    "        applymap(lambda x: disorder in x if pd.notnull(x) else False)\n",
    "\n",
    "    disorder_df = df_disorders[mask.any(axis=1)]\n",
    "\n",
    "    np.add.at(classes[i], disorder_df.index.values, 1)\n",
    "\n",
    "behaviour_data_columns = beh.columns.values.astype(np.str)\n",
    "\n",
    "columns_to_drop = behaviour_data_columns[\n",
    "    np.flatnonzero(np.core.defchararray.find(behaviour_data_columns, 'DX') != -1)]\n",
    "\n",
    "behaviour_data = beh.drop(columns=columns_to_drop)\n",
    "\n",
    "for disorder, classification in zip(most_common_disorders, classes):\n",
    "    behaviour_data[disorder] = classification\n",
    "\n",
    "behaviour_data['order_diagnoses'] = list(order_of_disorders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAA075AMK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAA112DMH</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAA117NEJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAA306NT2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAA504CRN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>NDARZZ007YMP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>NDARZZ740MLM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>NDARZZ810LVF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>NDARZZ830JM7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>NDARZZ993CEV</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2813 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0     NDARAA075AMK                                         0   \n",
       "1     NDARAA112DMH                                         1   \n",
       "2     NDARAA117NEJ                                         1   \n",
       "3     NDARAA306NT2                                         1   \n",
       "4     NDARAA504CRN                                         1   \n",
       "...            ...                                       ...   \n",
       "2808  NDARZZ007YMP                                         0   \n",
       "2809  NDARZZ740MLM                                         1   \n",
       "2810  NDARZZ810LVF                                         0   \n",
       "2811  NDARZZ830JM7                                         0   \n",
       "2812  NDARZZ993CEV                                         0   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     1                           1                         0   \n",
       "4                     1                           1                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "2808                  0                           0                         1   \n",
       "2809                  0                           0                         0   \n",
       "2810                  0                           0                         1   \n",
       "2811                  0                           0                         1   \n",
       "2812                  1                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       1                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "2808           0                       0                     0  \n",
       "2809           0                       0                     0  \n",
       "2810           0                       1                     0  \n",
       "2811           0                       0                     0  \n",
       "2812           0                       0                     0  \n",
       "\n",
       "[2813 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=behaviour_data[[\"IDs\"]+list(most_common_disorders)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Electrode 1 - 1/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 2/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 3/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 4/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 5/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 6/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 7/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 8/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 9/2 Hz,)</th>\n",
       "      <th>(Electrode 1 - 10/2 Hz,)</th>\n",
       "      <th>...</th>\n",
       "      <th>2651</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Attention-Deficit/Hyperactivity Disorder</th>\n",
       "      <th>Anxiety Disorders</th>\n",
       "      <th>Specific Learning Disorder</th>\n",
       "      <th>Autism Spectrum Disorder</th>\n",
       "      <th>Disruptive</th>\n",
       "      <th>Communication Disorder</th>\n",
       "      <th>Depressive Disorders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.212006e-10</td>\n",
       "      <td>2.857691e-08</td>\n",
       "      <td>5.960983e-06</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.033290</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.221608</td>\n",
       "      <td>0.467715</td>\n",
       "      <td>0.593581</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>0.986272</td>\n",
       "      <td>1.825774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.539866e-01</td>\n",
       "      <td>3.856645e-01</td>\n",
       "      <td>7.428434e-02</td>\n",
       "      <td>0.216988</td>\n",
       "      <td>0.177267</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448476</td>\n",
       "      <td>1.486650</td>\n",
       "      <td>1.888544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.439263e-05</td>\n",
       "      <td>4.110931e-03</td>\n",
       "      <td>9.411772e-02</td>\n",
       "      <td>0.367821</td>\n",
       "      <td>0.284890</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.333176</td>\n",
       "      <td>0.526883</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545169</td>\n",
       "      <td>1.593155</td>\n",
       "      <td>2.095749</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.832192e-01</td>\n",
       "      <td>3.613309e-01</td>\n",
       "      <td>3.789685e-01</td>\n",
       "      <td>0.299813</td>\n",
       "      <td>0.247412</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339304</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>1.724831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.247342e-04</td>\n",
       "      <td>1.132987e-02</td>\n",
       "      <td>1.676998e-01</td>\n",
       "      <td>0.368840</td>\n",
       "      <td>0.155464</td>\n",
       "      <td>0.104191</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>0.233210</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.918020</td>\n",
       "      <td>1.749441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>8.206176e-11</td>\n",
       "      <td>1.191276e-08</td>\n",
       "      <td>9.842314e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.155558</td>\n",
       "      <td>0.287815</td>\n",
       "      <td>0.314661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128389</td>\n",
       "      <td>0.788340</td>\n",
       "      <td>1.573205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>3.062358e-04</td>\n",
       "      <td>1.130883e-03</td>\n",
       "      <td>3.834623e-03</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.032255</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>0.085125</td>\n",
       "      <td>0.108455</td>\n",
       "      <td>0.129148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333760</td>\n",
       "      <td>1.423824</td>\n",
       "      <td>1.381199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1.556547e-05</td>\n",
       "      <td>2.900630e-04</td>\n",
       "      <td>3.548476e-03</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.189421</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.445277</td>\n",
       "      <td>0.644915</td>\n",
       "      <td>0.577096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.205704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2.303407e-04</td>\n",
       "      <td>2.867255e-02</td>\n",
       "      <td>1.949453e-01</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.179779</td>\n",
       "      <td>0.300051</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.459853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>1.351549</td>\n",
       "      <td>1.996940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>6.411911e-03</td>\n",
       "      <td>2.687961e-02</td>\n",
       "      <td>9.555112e-02</td>\n",
       "      <td>0.241121</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>0.574767</td>\n",
       "      <td>0.694741</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373653</td>\n",
       "      <td>0.781225</td>\n",
       "      <td>1.470061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows × 6757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (Electrode 1 - 1/2 Hz,)  (Electrode 1 - 2/2 Hz,)  \\\n",
       "0                1.212006e-10             2.857691e-08   \n",
       "1                1.539866e-01             3.856645e-01   \n",
       "2                3.439263e-05             4.110931e-03   \n",
       "3                2.832192e-01             3.613309e-01   \n",
       "4                1.247342e-04             1.132987e-02   \n",
       "...                       ...                      ...   \n",
       "1830             8.206176e-11             1.191276e-08   \n",
       "1831             3.062358e-04             1.130883e-03   \n",
       "1832             1.556547e-05             2.900630e-04   \n",
       "1833             2.303407e-04             2.867255e-02   \n",
       "1834             6.411911e-03             2.687961e-02   \n",
       "\n",
       "      (Electrode 1 - 3/2 Hz,)  (Electrode 1 - 4/2 Hz,)  \\\n",
       "0                5.960983e-06                 0.001066   \n",
       "1                7.428434e-02                 0.216988   \n",
       "2                9.411772e-02                 0.367821   \n",
       "3                3.789685e-01                 0.299813   \n",
       "4                1.676998e-01                 0.368840   \n",
       "...                       ...                      ...   \n",
       "1830             9.842314e-07                 0.000039   \n",
       "1831             3.834623e-03                 0.009994   \n",
       "1832             3.548476e-03                 0.023882   \n",
       "1833             1.949453e-01                 0.081646   \n",
       "1834             9.555112e-02                 0.241121   \n",
       "\n",
       "      (Electrode 1 - 5/2 Hz,)  (Electrode 1 - 6/2 Hz,)  \\\n",
       "0                    0.033290                 0.143816   \n",
       "1                    0.177267                 0.161251   \n",
       "2                    0.284890                 0.164614   \n",
       "3                    0.247412                 0.058588   \n",
       "4                    0.155464                 0.104191   \n",
       "...                       ...                      ...   \n",
       "1830                 0.000736                 0.006939   \n",
       "1831                 0.020117                 0.032255   \n",
       "1832                 0.088943                 0.189421   \n",
       "1833                 0.018422                 0.076959   \n",
       "1834                 0.434011                 0.574767   \n",
       "\n",
       "      (Electrode 1 - 7/2 Hz,)  (Electrode 1 - 8/2 Hz,)  \\\n",
       "0                    0.221608                 0.467715   \n",
       "1                    0.117761                 0.132384   \n",
       "2                    0.216934                 0.333176   \n",
       "3                    0.015256                 0.004514   \n",
       "4                    0.194459                 0.288490   \n",
       "...                       ...                      ...   \n",
       "1830                 0.040446                 0.155558   \n",
       "1831                 0.051099                 0.085125   \n",
       "1832                 0.293481                 0.445277   \n",
       "1833                 0.179779                 0.300051   \n",
       "1834                 0.694741                 0.815939   \n",
       "\n",
       "      (Electrode 1 - 9/2 Hz,)  (Electrode 1 - 10/2 Hz,)  ...      2651  \\\n",
       "0                    0.593581                  0.401686  ...  0.179322   \n",
       "1                    0.049898                  0.004720  ...  0.448476   \n",
       "2                    0.526883                  0.511715  ...  0.545169   \n",
       "3                    0.003988                  0.061608  ...  0.339304   \n",
       "4                    0.233210                  0.125520  ...  0.013197   \n",
       "...                       ...                       ...  ...       ...   \n",
       "1830                 0.287815                  0.314661  ...  0.128389   \n",
       "1831                 0.108455                  0.129148  ...  0.333760   \n",
       "1832                 0.644915                  0.577096  ...  0.367943   \n",
       "1833                 0.417245                  0.459853  ...  0.008403   \n",
       "1834                 0.678021                  0.490314  ...  0.373653   \n",
       "\n",
       "      Intercept     Slope  Attention-Deficit/Hyperactivity Disorder  \\\n",
       "0      0.986272  1.825774                                         0   \n",
       "1      1.486650  1.888544                                         1   \n",
       "2      1.593155  2.095749                                         1   \n",
       "3      0.703331  1.724831                                         1   \n",
       "4      0.918020  1.749441                                         1   \n",
       "...         ...       ...                                       ...   \n",
       "1830   0.788340  1.573205                                         1   \n",
       "1831   1.423824  1.381199                                         0   \n",
       "1832   0.168009  0.205704                                         0   \n",
       "1833   1.351549  1.996940                                         1   \n",
       "1834   0.781225  1.470061                                         1   \n",
       "\n",
       "      Anxiety Disorders  Specific Learning Disorder  Autism Spectrum Disorder  \\\n",
       "0                     0                           0                         0   \n",
       "1                     0                           0                         0   \n",
       "2                     0                           0                         0   \n",
       "3                     0                           1                         1   \n",
       "4                     0                           0                         0   \n",
       "...                 ...                         ...                       ...   \n",
       "1830                  0                           0                         0   \n",
       "1831                  0                           0                         0   \n",
       "1832                  1                           0                         0   \n",
       "1833                  1                           0                         0   \n",
       "1834                  0                           0                         0   \n",
       "\n",
       "      Disruptive  Communication Disorder  Depressive Disorders  \n",
       "0              0                       0                     0  \n",
       "1              1                       0                     0  \n",
       "2              1                       0                     0  \n",
       "3              0                       0                     0  \n",
       "4              0                       0                     0  \n",
       "...          ...                     ...                   ...  \n",
       "1830           0                       0                     0  \n",
       "1831           0                       0                     0  \n",
       "1832           0                       0                     0  \n",
       "1833           0                       0                     1  \n",
       "1834           0                       0                     0  \n",
       "\n",
       "[1835 rows x 6757 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df2, on='IDs', how='inner')\n",
    "df = pd.merge(df, foof, on='IDs', how='inner')\n",
    "df = pd.merge(df, labels, on='IDs', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1835, 6749) (1835, 7)\n"
     ]
    }
   ],
   "source": [
    "x = df[df.columns.difference(['IDs']+most_common_disorders)]\n",
    "y = df[most_common_disorders]\n",
    "\n",
    "# summarize dataset shape\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 17:57:32.338503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-22 17:57:32.369415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.370113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-22 17:57:32.370336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:57:32.371567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-22 17:57:32.372921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 17:57:32.373109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 17:57:32.374397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-22 17:57:32.375123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-22 17:57:32.377895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-22 17:57:32.378046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.378778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.379380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-22 17:57:32.381236: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-11-22 17:57:32.387444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-11-22 17:57:32.388037: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55823c822f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 17:57:32.388050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-22 17:57:32.388192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.388822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-22 17:57:32.388860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:57:32.388873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-22 17:57:32.388884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 17:57:32.388894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 17:57:32.388905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-22 17:57:32.388915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-22 17:57:32.388925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-22 17:57:32.388980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.389653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.390262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-11-22 17:57:32.390293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-22 17:57:32.464509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-22 17:57:32.464536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-11-22 17:57:32.464541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-11-22 17:57:32.464820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.465489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.466119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 17:57:32.466714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14109 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-11-22 17:57:32.468518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5582424b70a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-22 17:57:32.468529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 17:57:34.039013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 - 6s - loss: 34.2378\n",
      "Epoch 2/50\n",
      "81/81 - 6s - loss: 0.2265\n",
      "Epoch 3/50\n",
      "81/81 - 6s - loss: 0.2321\n",
      "Epoch 4/50\n",
      "81/81 - 6s - loss: 0.2620\n",
      "Epoch 5/50\n",
      "81/81 - 6s - loss: 0.2528\n",
      "Epoch 6/50\n",
      "81/81 - 6s - loss: 0.2676\n",
      "Epoch 7/50\n",
      "81/81 - 6s - loss: 0.2821\n",
      "Epoch 8/50\n",
      "81/81 - 6s - loss: 0.2815\n",
      "Epoch 9/50\n",
      "81/81 - 6s - loss: 0.2712\n",
      "Epoch 10/50\n",
      "81/81 - 6s - loss: 0.3251\n",
      "Epoch 11/50\n",
      "81/81 - 6s - loss: 0.3141\n",
      "Epoch 12/50\n",
      "81/81 - 6s - loss: 0.3357\n",
      "Epoch 13/50\n",
      "81/81 - 6s - loss: 0.3129\n",
      "Epoch 14/50\n",
      "81/81 - 6s - loss: 0.3603\n",
      "Epoch 15/50\n",
      "81/81 - 6s - loss: 0.4269\n",
      "Epoch 16/50\n",
      "81/81 - 6s - loss: 0.3723\n",
      "Epoch 17/50\n",
      "81/81 - 6s - loss: 0.3712\n",
      "Epoch 18/50\n",
      "81/81 - 6s - loss: 0.3746\n",
      "Epoch 19/50\n",
      "81/81 - 6s - loss: 0.3587\n",
      "Epoch 20/50\n",
      "81/81 - 6s - loss: 0.3850\n",
      "Epoch 21/50\n",
      "81/81 - 6s - loss: 0.3521\n",
      "Epoch 22/50\n",
      "81/81 - 6s - loss: 0.3773\n",
      "Epoch 23/50\n",
      "81/81 - 6s - loss: 0.3591\n",
      "Epoch 24/50\n",
      "81/81 - 6s - loss: 0.4133\n",
      "Epoch 25/50\n",
      "81/81 - 6s - loss: 0.3518\n",
      "Epoch 26/50\n",
      "81/81 - 6s - loss: 0.3600\n",
      "Epoch 27/50\n",
      "81/81 - 6s - loss: 0.3858\n",
      "Epoch 28/50\n",
      "81/81 - 6s - loss: 0.4203\n",
      "Epoch 29/50\n",
      "81/81 - 6s - loss: 0.4302\n",
      "Epoch 30/50\n",
      "81/81 - 6s - loss: 0.4079\n",
      "Epoch 31/50\n",
      "81/81 - 6s - loss: 0.3979\n",
      "Epoch 32/50\n",
      "81/81 - 6s - loss: 0.4589\n",
      "Epoch 33/50\n",
      "81/81 - 6s - loss: 0.3688\n",
      "Epoch 34/50\n",
      "81/81 - 6s - loss: 0.3899\n",
      "Epoch 35/50\n",
      "81/81 - 6s - loss: 0.3721\n",
      "Epoch 36/50\n",
      "81/81 - 6s - loss: 0.4456\n",
      "Epoch 37/50\n",
      "81/81 - 6s - loss: 0.4491\n",
      "Epoch 38/50\n",
      "81/81 - 6s - loss: 0.4506\n",
      "Epoch 39/50\n",
      "81/81 - 6s - loss: 0.4238\n",
      "Epoch 40/50\n",
      "81/81 - 6s - loss: 0.3236\n",
      "Epoch 41/50\n",
      "81/81 - 6s - loss: 0.3985\n",
      "Epoch 42/50\n",
      "81/81 - 6s - loss: 0.3393\n",
      "Epoch 43/50\n",
      "81/81 - 6s - loss: 0.3863\n",
      "Epoch 44/50\n",
      "81/81 - 6s - loss: 0.4306\n",
      "Epoch 45/50\n",
      "81/81 - 6s - loss: 0.4015\n",
      "Epoch 46/50\n",
      "81/81 - 6s - loss: 0.4076\n",
      "Epoch 47/50\n",
      "81/81 - 6s - loss: 0.3331\n",
      "Epoch 48/50\n",
      "81/81 - 6s - loss: 0.3202\n",
      "Epoch 49/50\n",
      "81/81 - 6s - loss: 0.3450\n",
      "Epoch 50/50\n",
      "81/81 - 6s - loss: 0.3449\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "n_inputs = train_features.shape[1]\n",
    "\n",
    "visible = Input(shape=(n_inputs,))\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "n_bottleneck = round(float(n_inputs) / 2.0)\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "d = Dense(n_inputs)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "output = Dense(7, activation='linear')(d)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=50, batch_size=16, verbose=2)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
    "encoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "encoder= load_model('autoencoder.h5', compile=False)\n",
    "\n",
    "train_features = encoder.predict(train_features)\n",
    "test_features = encoder.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))\n",
    "\n",
    "def evaluate(y_test, y_pred_prob, brier=True):\n",
    "    y_pred = y_pred_prob.round()\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))\n",
    "    if brier:\n",
    "        print(\"Brier Score:\", brier_multi(y_test, y_pred_prob))\n",
    "    print(\"Classification Report:\\n\", skm.classification_report(y_test,y_pred, zero_division=1))\n",
    "    print(\"Confusion matrix:\\n\", skm.multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression():\n",
      "Accuracy: 0.10344827586206896\n",
      "Hamming Loss: 0.2756028001037075\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       369\n",
      "           1       0.40      0.30      0.34       203\n",
      "           2       0.27      0.15      0.19       140\n",
      "           3       0.22      0.06      0.10        94\n",
      "           4       0.10      0.03      0.05        92\n",
      "           5       0.16      0.09      0.12        76\n",
      "           6       0.26      0.09      0.13        58\n",
      "\n",
      "   micro avg       0.48      0.33      0.39      1032\n",
      "   macro avg       0.30      0.19      0.23      1032\n",
      "weighted avg       0.41      0.33      0.35      1032\n",
      " samples avg       0.59      0.43      0.36      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 58 124]\n",
      "  [134 235]]\n",
      "\n",
      " [[258  90]\n",
      "  [142  61]]\n",
      "\n",
      " [[353  58]\n",
      "  [119  21]]\n",
      "\n",
      " [[436  21]\n",
      "  [ 88   6]]\n",
      "\n",
      " [[433  26]\n",
      "  [ 89   3]]\n",
      "\n",
      " [[439  36]\n",
      "  [ 69   7]]\n",
      "\n",
      " [[479  14]\n",
      "  [ 53   5]]]\n",
      "RandomForestClassifier(random_state=1):\n",
      "Accuracy: 0.15789473684210525\n",
      "Hamming Loss: 0.22011926367643245\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79       369\n",
      "           1       0.43      0.03      0.06       203\n",
      "           2       0.50      0.01      0.01       140\n",
      "           3       0.00      0.00      0.00        94\n",
      "           4       1.00      0.01      0.02        92\n",
      "           5       1.00      0.00      0.00        76\n",
      "           6       1.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       0.67      0.35      0.46      1032\n",
      "   macro avg       0.66      0.14      0.13      1032\n",
      "weighted avg       0.61      0.35      0.30      1032\n",
      " samples avg       0.69      0.47      0.44      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 12 170]\n",
      "  [ 14 355]]\n",
      "\n",
      " [[340   8]\n",
      "  [197   6]]\n",
      "\n",
      " [[410   1]\n",
      "  [139   1]]\n",
      "\n",
      " [[456   1]\n",
      "  [ 94   0]]\n",
      "\n",
      " [[459   0]\n",
      "  [ 91   1]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 76   0]]\n",
      "\n",
      " [[493   0]\n",
      "  [ 58   0]]]\n",
      "SVC():\n",
      "Accuracy: 0.16333938294010888\n",
      "Hamming Loss: 0.21908218822919368\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80       369\n",
      "           1       1.00      0.00      0.00       203\n",
      "           2       1.00      0.00      0.00       140\n",
      "           3       1.00      0.00      0.00        94\n",
      "           4       1.00      0.00      0.00        92\n",
      "           5       1.00      0.00      0.00        76\n",
      "           6       1.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       0.67      0.36      0.47      1032\n",
      "   macro avg       0.95      0.14      0.11      1032\n",
      "weighted avg       0.88      0.36      0.29      1032\n",
      " samples avg       0.67      0.47      0.45      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  0 182]\n",
      "  [  0 369]]\n",
      "\n",
      " [[348   0]\n",
      "  [203   0]]\n",
      "\n",
      " [[411   0]\n",
      "  [140   0]]\n",
      "\n",
      " [[457   0]\n",
      "  [ 94   0]]\n",
      "\n",
      " [[459   0]\n",
      "  [ 92   0]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 76   0]]\n",
      "\n",
      " [[493   0]\n",
      "  [ 58   0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "lg = LogisticRegression()\n",
    "svm = svm()\n",
    "models = [lg, forest, svm]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    multi_output_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    multi_output_model.fit(train_features, train_labels)\n",
    "    predicted_labels = multi_output_model.predict(test_features)\n",
    "    print(str(model)+':')\n",
    "    evaluate(test_labels, predicted_labels, brier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 0.5245\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.4947\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.4898\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4830\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4798\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4808\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4730\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4670\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4660\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4645\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4564\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4537\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4523\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4453\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4468\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4408\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4384\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4297\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4319\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4254\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4192\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4175\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.4212\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4155\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4083\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4085\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.4062\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3964\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3940\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3940\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3924\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.3811\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3819\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3775\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3746\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3746\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3679\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3581\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3616\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3574\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3529\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3582\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3518\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3435\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3351\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3306\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3299\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3303\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3295\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3307\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3225\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3226\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.3146\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3099\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3062\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.3099\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.3048\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3000\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2951\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2940\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2894\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2867\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2850\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2851\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2829\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2737\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2747\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2710\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2736\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2639\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2688\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2602\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2634\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2600\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2509\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2489\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2466\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2449\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2391\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2352\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2343\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2402\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2313\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2267\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2220\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2317\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2195\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2164\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2160\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2157\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2071\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2060\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2077\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2123\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2038\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.1996\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 0.2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f29a0050070>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def get_mlp(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "n_inputs, n_outputs = train_features.shape[1],train_labels.shape[1]\n",
    "mlp = get_mlp(n_inputs, n_outputs)\n",
    "mlp.fit(train_features, train_labels, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0780399274047187\n",
      "Hamming Loss: 0.29038112522686027\n",
      "Brier Score: 1.5445178994569044\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       369\n",
      "           1       0.39      0.38      0.39       203\n",
      "           2       0.21      0.03      0.05       140\n",
      "           3       0.17      0.28      0.21        94\n",
      "           4       0.19      0.09      0.12        92\n",
      "           5       0.10      0.05      0.07        76\n",
      "           6       0.22      0.09      0.12        58\n",
      "\n",
      "   micro avg       0.45      0.38      0.41      1032\n",
      "   macro avg       0.28      0.24      0.24      1032\n",
      "weighted avg       0.40      0.38      0.38      1032\n",
      " samples avg       0.56      0.48      0.38      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 50 132]\n",
      "  [ 99 270]]\n",
      "\n",
      " [[225 123]\n",
      "  [125  78]]\n",
      "\n",
      " [[396  15]\n",
      "  [136   4]]\n",
      "\n",
      " [[332 125]\n",
      "  [ 68  26]]\n",
      "\n",
      " [[424  35]\n",
      "  [ 84   8]]\n",
      "\n",
      " [[440  35]\n",
      "  [ 72   4]]\n",
      "\n",
      " [[475  18]\n",
      "  [ 53   5]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlp = mlp.predict(test_features)\n",
    "evaluate(test_labels, predicted_labels_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "ignores the possible correlations between class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "classifier.fit(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07622504537205081\n",
      "Hamming Loss: 0.3411978221415608\n",
      "Brier Score: 2.380635109465426\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       369\n",
      "           1       0.46      0.82      0.59       203\n",
      "           2       0.35      0.82      0.49       140\n",
      "           3       0.41      0.64      0.50        94\n",
      "           4       0.25      0.92      0.40        92\n",
      "           5       0.28      0.74      0.41        76\n",
      "           6       0.26      0.74      0.39        58\n",
      "\n",
      "   micro avg       0.43      0.80      0.56      1032\n",
      "   macro avg       0.40      0.78      0.51      1032\n",
      "weighted avg       0.51      0.80      0.59      1032\n",
      " samples avg       0.44      0.82      0.50      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 89  93]\n",
      "  [ 74 295]]\n",
      "\n",
      " [[153 195]\n",
      "  [ 36 167]]\n",
      "\n",
      " [[193 218]\n",
      "  [ 25 115]]\n",
      "\n",
      " [[372  85]\n",
      "  [ 34  60]]\n",
      "\n",
      " [[209 250]\n",
      "  [  7  85]]\n",
      "\n",
      " [[332 143]\n",
      "  [ 20  56]]\n",
      "\n",
      " [[372 121]\n",
      "  [ 15  43]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_br = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_br.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classfier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)\n",
    "# we should optimise this a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10163339382940109\n",
      "Hamming Loss: 0.27586206896551724\n",
      "Brier Score: 1.5202853169271076\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       369\n",
      "           1       0.40      0.30      0.34       203\n",
      "           2       0.27      0.15      0.19       140\n",
      "           3       0.23      0.07      0.11        94\n",
      "           4       0.07      0.02      0.03        92\n",
      "           5       0.18      0.08      0.11        76\n",
      "           6       0.30      0.12      0.17        58\n",
      "\n",
      "   micro avg       0.48      0.33      0.39      1032\n",
      "   macro avg       0.30      0.20      0.23      1032\n",
      "weighted avg       0.41      0.33      0.35      1032\n",
      " samples avg       0.59      0.43      0.36      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[ 58 124]\n",
      "  [137 232]]\n",
      "\n",
      " [[256  92]\n",
      "  [142  61]]\n",
      "\n",
      " [[354  57]\n",
      "  [119  21]]\n",
      "\n",
      " [[434  23]\n",
      "  [ 87   7]]\n",
      "\n",
      " [[431  28]\n",
      "  [ 90   2]]\n",
      "\n",
      " [[447  28]\n",
      "  [ 70   6]]\n",
      "\n",
      " [[477  16]\n",
      "  [ 51   7]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_cc = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_cc.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "takes correlations into account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=LogisticRegression(), require_dense=[True, True])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16333938294010888\n",
      "Hamming Loss: 0.21908218822919368\n",
      "Brier Score: 1.1430201072638624\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80       369\n",
      "           1       1.00      0.00      0.00       203\n",
      "           2       1.00      0.00      0.00       140\n",
      "           3       1.00      0.00      0.00        94\n",
      "           4       1.00      0.00      0.00        92\n",
      "           5       1.00      0.00      0.00        76\n",
      "           6       1.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       0.67      0.36      0.47      1032\n",
      "   macro avg       0.95      0.14      0.11      1032\n",
      "weighted avg       0.88      0.36      0.29      1032\n",
      " samples avg       0.67      0.47      0.45      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[  0 182]\n",
      "  [  0 369]]\n",
      "\n",
      " [[348   0]\n",
      "  [203   0]]\n",
      "\n",
      " [[411   0]\n",
      "  [140   0]]\n",
      "\n",
      " [[457   0]\n",
      "  [ 94   0]]\n",
      "\n",
      " [[459   0]\n",
      "  [ 92   0]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 76   0]]\n",
      "\n",
      " [[493   0]\n",
      "  [ 58   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_lp = classifier.predict_proba(test_features)\n",
    "evaluate(test_labels, predicted_labels_lp.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anujanegi/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLkNN()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "mlknn = MLkNN(k=10)\n",
    "\n",
    "x_train = lil_matrix(train_features).toarray()\n",
    "y_train = lil_matrix(train_labels).toarray()\n",
    "x_test = lil_matrix(test_features).toarray()\n",
    "\n",
    "mlknn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10707803992740472\n",
      "Hamming Loss: 0.26756546538760695\n",
      "Brier Score: 1.649097527784518\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       369\n",
      "           1       1.00      0.00      0.00       203\n",
      "           2       1.00      0.00      0.00       140\n",
      "           3       1.00      0.00      0.00        94\n",
      "           4       1.00      0.00      0.00        92\n",
      "           5       1.00      0.00      0.00        76\n",
      "           6       1.00      0.00      0.00        58\n",
      "\n",
      "   micro avg       1.00      0.00      0.00      1032\n",
      "   macro avg       1.00      0.00      0.00      1032\n",
      "weighted avg       1.00      0.00      0.00      1032\n",
      " samples avg       1.00      0.11      0.11      1032\n",
      "\n",
      "Confusion matrix:\n",
      " [[[182   0]\n",
      "  [369   0]]\n",
      "\n",
      " [[348   0]\n",
      "  [203   0]]\n",
      "\n",
      " [[411   0]\n",
      "  [140   0]]\n",
      "\n",
      " [[457   0]\n",
      "  [ 94   0]]\n",
      "\n",
      " [[459   0]\n",
      "  [ 92   0]]\n",
      "\n",
      " [[475   0]\n",
      "  [ 76   0]]\n",
      "\n",
      " [[493   0]\n",
      "  [ 58   0]]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_mlknn = mlknn.predict_proba(x_test)\n",
    "evaluate(test_labels, predicted_labels_mlknn.todense())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
