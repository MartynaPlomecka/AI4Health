{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YxOz-zNNlyy"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import uniform\n",
    "from numpy import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter,filterwarnings\n",
    "\n",
    "# ignore all future warnings1\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "    if \"anuja\" in os.environ.get('USER'):\n",
    "        DATA_DIR = 'data/'\n",
    "    elif 'ubuntu' in os.environ.get('USER'):\n",
    "        DATA_DIR = '/home/ubuntu/Martyna/repo/AI4Health/DATAfoof/'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG data and foof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## data loading\n",
    "# data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "# foof = pd.read_csv(DATA_DIR+\"sensor_intercept_slope.csv\")\n",
    "# foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flattening\n",
    "# df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "# df = np.array(df)\n",
    "# df = df.reshape(data['x'].shape)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "# df['IDs'] = foof['IDs']\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YjKzrOY5dKO"
   },
   "source": [
    "## Behavioral Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bFK75cJgWc2G",
    "outputId": "c35c8bfc-2242-43be-aada-379d1ccb4c7e"
   },
   "outputs": [],
   "source": [
    "# behaviour_data = pd.read_csv(DATA_DIR+'AllData.csv')\n",
    "# behaviour_data = behaviour_data.rename(columns = {'EID': 'IDs'}, inplace = False)\n",
    "# behaviour_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "# add_features = beh[['Sex', 'Age','IDs']]\n",
    "# add_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour_data = behaviour_data[['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "#        'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "#        'WISC_VCI_Sum']]\n",
    "# behaviour_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def missing_values_table(df):\n",
    "#     mis_val = df.isnull().sum()\n",
    "#     mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "#     mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "#     mis_val_table_ren_columns = mis_val_table.rename(\n",
    "#     columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "#     mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "#         mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "#     '% of Total Values', ascending=False).round(1)\n",
    "#     print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns (with column 'IDs').\\n\"      \n",
    "#         \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "#             \" columns that have missing values.\")\n",
    "#     return mis_val_table_ren_columns\n",
    "\n",
    "# missing_values_table(behaviour_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge EEG and foof data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(df, foof, on='IDs', how='inner')\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and then with the behaviorals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(data, behaviour_data, on='IDs', how='inner')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add age and gender\n",
    "# df = pd.merge(df, add_features, on='IDs', how='inner')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features and labels preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #removing NaNs\n",
    "# df = df.dropna()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_list = [ 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "#    'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "#    'WISC_VCI_Sum']\n",
    "\n",
    "# X = df[df.columns.difference(['IDs']+labels_list)]\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = df[labels_list]\n",
    "# print(Y.shape)a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, shuffle=True)\n",
    "\n",
    "path = os.path.join(DATA_DIR, 'multilabel_regression_sensor_level')\n",
    "\n",
    "# #saving\n",
    "# if not(os.path.exists(path)):\n",
    "#     os.mkdir(path)\n",
    "# np.save(os.path.join(path, 'xtrain.npy'), xtrain)\n",
    "# np.save(os.path.join(path, 'xtest.npy'), xtest)\n",
    "# np.save(os.path.join(path, 'ytrain.npy'), ytrain)\n",
    "# np.save(os.path.join(path, 'ytest.npy'), ytest)\n",
    "\n",
    "\n",
    "#loading\n",
    "xtrain = np.load(os.path.join(path, 'xtrain.npy'))\n",
    "xtest = np.load(os.path.join(path, 'xtest.npy'))\n",
    "ytrain = np.load(os.path.join(path, 'ytrain.npy'))\n",
    "ytest = np.load(os.path.join(path, 'ytest.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender = True\n",
    "if age_gender:\n",
    "    train_age_gender = xtrain[:,-2:]\n",
    "    test_age_gender = xtest[:,-2:]\n",
    "    xtrain = xtrain[:,:-2]\n",
    "    xtest = xtest[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 8505) (268, 8505)\n",
      "Applying PCA...\n",
      "(804, 194) (268, 194)\n"
     ]
    }
   ],
   "source": [
    "# scaling x\n",
    "norm = preprocessing.MinMaxScaler().fit(xtrain)\n",
    "\n",
    "# transform training data\n",
    "xtrain = norm.transform(xtrain)\n",
    "xtest = norm.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "\n",
    "print('Applying PCA...')\n",
    "pca = PCA(.95) # 95% variance retained\n",
    "pca.fit(xtrain)\n",
    "\n",
    "# transform data\n",
    "xtrain = pca.transform(xtrain)\n",
    "xtest = pca.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "if age_gender:\n",
    "    xtrain = np.concatenate([xtrain, train_age_gender], axis = 1)\n",
    "    xtest = np.concatenate([xtest, test_age_gender], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 8) (268, 8)\n"
     ]
    }
   ],
   "source": [
    "# scaling y\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(ytrain)\n",
    "ytrain = min_max_scaler.transform(ytrain)\n",
    "ytest = min_max_scaler.transform(ytest)\n",
    "\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41457067, 0.3350594 , 0.61818219, 0.54341715, 0.58079966,\n",
       "       0.25725539, 0.44997668, 0.49228124])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy regressors (to obtain the random baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (dummy): 0.04\n",
      "Median absolute error (dummy): 0.13\n",
      "r2_score (dummy mean): -0.00\n",
      "r2_score (dummy median): -0.02\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(xtrain, ytrain)\n",
    "lm_dummy_median = DummyRegressor(strategy = 'median').fit(xtrain, ytrain)\n",
    "ypred_dummy_mean = lm_dummy_mean.predict(xtest)\n",
    "ypred_dummy_median = lm_dummy_median.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
    "\n",
    "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_median)))\n",
    "\n",
    "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(ytest, ypred_dummy_mean)))\n",
    "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(ytest, ypred_dummy_median)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOR regressor with base SVR regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (SVR): 0.04 [0.04, 0.05]\n",
      "Mean abs error (SVR) 0.16 [0.16, 0.17]\n",
      "R2 score (SVR): -0.05 [-0.09, -0.01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Create the SVR regressor\n",
    "svr = SVR(epsilon=0.2)\n",
    "#Create the Multioutput Regressor\n",
    "model = MultiOutputRegressor(svr)\n",
    "# Train the regressor\n",
    "model = model.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (SVR): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (SVR) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (SVR): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (RanFor): 0.04 [0.04, 0.05]\n",
      "Mean abs error (RanFor) 0.16 [0.15, 0.17]\n",
      "R2 score (RanFor): -0.01 [-0.03, 0.00]\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "# define model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (RanFor) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (LinReg): 0.05 [0.04, 0.05]\n",
      "Mean abs error (LinReg) 0.17 [0.16, 0.18]\n",
      "R2 score (LinReg): -0.12 [-0.17, -0.08]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (LinReg): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (LinReg) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (LinReg): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "#print(\"Mean squared error (LinReg): {:.2f}\".format(mean_squared_error(ytest,\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "#print(\"Mean abs error (LinReg): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#print(\"R2 score (LinReg): {:.2f}\".format(model.score(xtest, ytest)))\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (RanFor): 0.04 [0.04, 0.05]\n",
      "Mean abs error (RanFor) 0.16 [0.15, 0.17]\n",
      "R2 score (RanFor): 0.00 [-0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    ")\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (RanFor) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.2296\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1911 - val_loss: 0.1541\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1599 - val_loss: 0.1496\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1584 - val_loss: 0.1495\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1583 - val_loss: 0.1496\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1583 - val_loss: 0.1495\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1584 - val_loss: 0.1496\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1583 - val_loss: 0.1497\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1583 - val_loss: 0.1501\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1583 - val_loss: 0.1497\n",
      "0.15913759\n",
      "0.042378098\n"
     ]
    }
   ],
   "source": [
    "in_dim = xtrain.shape[1]\n",
    "out_dim = ytrain.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(4, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(3, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(2, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(1, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=2, validation_split = 0.2, verbose=1)\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "score = tf.keras.metrics.mean_absolute_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score= np.array(score)\n",
    "print(score.mean())\n",
    "\n",
    "score_mse = tf.keras.metrics.mean_squared_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score_mse =  np.array(score_mse)\n",
    "print(score_mse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.2542\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2126 - val_loss: 0.2099\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1932\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1834\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1625 - val_loss: 0.1800\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1583 - val_loss: 0.1791\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1558 - val_loss: 0.1779\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1539 - val_loss: 0.1797\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1519 - val_loss: 0.1783\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1501 - val_loss: 0.1795\n",
      "0.17023443\n",
      "0.0484823\n"
     ]
    }
   ],
   "source": [
    "in_dim = xtrain.shape[1]\n",
    "out_dim = ytrain.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=2, validation_split = 0.2, verbose=1)\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "score = tf.keras.metrics.mean_absolute_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score= np.array(score)\n",
    "print(score.mean())\n",
    "\n",
    "score_mse = tf.keras.metrics.mean_squared_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score_mse =  np.array(score_mse)\n",
    "print(score_mse.mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DataScienceLab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
