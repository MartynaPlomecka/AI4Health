{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YxOz-zNNlyy"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mat73\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy.random import uniform\n",
    "from numpy import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.svm import SVC as svm\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,balanced_accuracy_score,f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter,filterwarnings\n",
    "\n",
    "# ignore all future warnings1\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = ''\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "    if \"anuja\" in os.environ.get('USER'):\n",
    "        DATA_DIR = 'data/'\n",
    "    elif 'ubuntu' in os.environ.get('USER'):\n",
    "        DATA_DIR = '/home/ubuntu/Martyna/repo/AI4Health/DATAfoof/'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG data and foof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## data loading\n",
    "# data = scipy.io.loadmat(DATA_DIR+'x.mat')  \n",
    "# foof = pd.read_csv(DATA_DIR+\"sensor_intercept_slope.csv\")\n",
    "# foof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flattening\n",
    "# df = pd.DataFrame(data['x'].reshape((data['x'].shape[0], -1)))\n",
    "# df = np.array(df)\n",
    "# df = df.reshape(data['x'].shape)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(df.reshape((df.shape[0], -1)))\n",
    "# df['IDs'] = foof['IDs']\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YjKzrOY5dKO"
   },
   "source": [
    "## Behavioral Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bFK75cJgWc2G",
    "outputId": "c35c8bfc-2242-43be-aada-379d1ccb4c7e"
   },
   "outputs": [],
   "source": [
    "# behaviour_data = pd.read_csv(DATA_DIR+'AllData.csv')\n",
    "# behaviour_data = behaviour_data.rename(columns = {'EID': 'IDs'}, inplace = False)\n",
    "# behaviour_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beh = pd.read_csv(DATA_DIR+\"behaviorals.csv\")\n",
    "# add_features = beh[['Sex', 'Age','IDs']]\n",
    "# add_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# behaviour_data = behaviour_data[['IDs', 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "#        'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "#        'WISC_VCI_Sum']]\n",
    "# behaviour_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def missing_values_table(df):\n",
    "#     mis_val = df.isnull().sum()\n",
    "#     mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "#     mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "#     mis_val_table_ren_columns = mis_val_table.rename(\n",
    "#     columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "#     mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "#         mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "#     '% of Total Values', ascending=False).round(1)\n",
    "#     print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns (with column 'IDs').\\n\"      \n",
    "#         \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "#             \" columns that have missing values.\")\n",
    "#     return mis_val_table_ren_columns\n",
    "\n",
    "# missing_values_table(behaviour_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge EEG and foof data together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(df, foof, on='IDs', how='inner')\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and then with the behaviorals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(data, behaviour_data, on='IDs', how='inner')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add age and gender\n",
    "# df = pd.merge(df, add_features, on='IDs', how='inner')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features and labels preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #removing NaNs\n",
    "# df = df.dropna()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_list = [ 'SRS_SCI_T', 'SRS_RRB_T', 'SWAN_IN_Avg', 'SWAN_HY_Avg',\n",
    "#    'SWAN_Avg', 'SCARED_P_GD', 'WISC_WMI_Sum',\n",
    "#    'WISC_VCI_Sum']\n",
    "\n",
    "# X = df[df.columns.difference(['IDs']+labels_list)]\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = df[labels_list]\n",
    "# print(Y.shape)a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, shuffle=True)\n",
    "\n",
    "path = os.path.join(DATA_DIR, 'multilabel_regression_sensor_level')\n",
    "\n",
    "# #saving\n",
    "# if not(os.path.exists(path)):\n",
    "#     os.mkdir(path)\n",
    "# np.save(os.path.join(path, 'xtrain.npy'), xtrain)\n",
    "# np.save(os.path.join(path, 'xtest.npy'), xtest)\n",
    "# np.save(os.path.join(path, 'ytrain.npy'), ytrain)\n",
    "# np.save(os.path.join(path, 'ytest.npy'), ytest)\n",
    "\n",
    "\n",
    "#loading\n",
    "xtrain = np.load(os.path.join(path, 'xtrain.npy'))\n",
    "xtest = np.load(os.path.join(path, 'xtest.npy'))\n",
    "ytrain = np.load(os.path.join(path, 'ytrain.npy'))\n",
    "ytest = np.load(os.path.join(path, 'ytest.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(DATA_DIR, 'marius_multilabel_regression_sensor_level')\n",
    "\n",
    "# #saving\n",
    "if not(os.path.exists(path)):\n",
    "     os.mkdir(path)\n",
    "np.savetxt(os.path.join(path, 'xtrain.csv'), xtrain)\n",
    "np.savetxt(os.path.join(path, 'xtest.csv'), xtest)\n",
    "np.savetxt(os.path.join(path, 'ytrain.csv'), ytrain)\n",
    "np.savetxt(os.path.join(path, 'ytest.csv'), ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender = True\n",
    "if age_gender:\n",
    "    train_age_gender = xtrain[:,-2:]\n",
    "    test_age_gender = xtest[:,-2:]\n",
    "    xtrain = xtrain[:,:-2]\n",
    "    xtest = xtest[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 8505) (268, 8505)\n",
      "Applying PCA...\n",
      "(804, 194) (268, 194)\n"
     ]
    }
   ],
   "source": [
    "# scaling x\n",
    "norm = preprocessing.MinMaxScaler().fit(xtrain)\n",
    "\n",
    "# transform training data\n",
    "xtrain = norm.transform(xtrain)\n",
    "xtest = norm.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)\n",
    "\n",
    "print('Applying PCA...')\n",
    "pca = PCA(.95) # 95% variance retained\n",
    "pca.fit(xtrain)\n",
    "\n",
    "# transform data\n",
    "xtrain = pca.transform(xtrain)\n",
    "xtest = pca.transform(xtest)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if age_gender:\n",
    "    xtrain = np.concatenate([xtrain, train_age_gender], axis = 1)\n",
    "    xtest = np.concatenate([xtest, test_age_gender], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 8) (268, 8)\n"
     ]
    }
   ],
   "source": [
    "# scaling y\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(ytrain)\n",
    "ytrain = min_max_scaler.transform(ytrain)\n",
    "ytest = min_max_scaler.transform(ytest)\n",
    "\n",
    "print(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41457067, 0.3350594 , 0.61818219, 0.54341715, 0.58079966,\n",
       "       0.25725539, 0.44997668, 0.49228124])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy regressors (to obtain the random baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (dummy): 0.04\n",
      "Median absolute error (dummy): 0.13\n",
      "r2_score (dummy mean): -0.00\n",
      "r2_score (dummy median): -0.02\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(xtrain, ytrain)\n",
    "lm_dummy_median = DummyRegressor(strategy = 'median').fit(xtrain, ytrain)\n",
    "ypred_dummy_mean = lm_dummy_mean.predict(xtest)\n",
    "ypred_dummy_median = lm_dummy_median.predict(xtest)\n",
    "\n",
    "\n",
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_mean)))\n",
    "\n",
    "print(\"Median absolute error (dummy): {:.2f}\".format(median_absolute_error(ytest,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred_dummy_median)))\n",
    "\n",
    "print(\"r2_score (dummy mean): {:.2f}\".format(r2_score(ytest, ypred_dummy_mean)))\n",
    "print(\"r2_score (dummy median): {:.2f}\".format(r2_score(ytest, ypred_dummy_median)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOR regressor with base SVR regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (SVR): 0.04 [0.04, 0.05]\n",
      "Mean abs error (SVR) 0.16 [0.16, 0.17]\n",
      "R2 score (SVR): -0.05 [-0.09, -0.01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Create the SVR regressor\n",
    "svr = SVR(epsilon=0.2)\n",
    "#Create the Multioutput Regressor\n",
    "model = MultiOutputRegressor(svr)\n",
    "# Train the regressor\n",
    "model = model.fit(xtrain, ytrain)\n",
    "# Generate predictions for testing data\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (SVR): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (SVR) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (SVR): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (RanFor): 0.04 [0.04, 0.05]\n",
      "Mean abs error (RanFor) 0.16 [0.15, 0.17]\n",
      "R2 score (RanFor): -0.01 [-0.03, 0.00]\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "# define model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (RanFor) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (LinReg): 0.05 [0.04, 0.05]\n",
      "Mean abs error (LinReg) 0.17 [0.16, 0.18]\n",
      "R2 score (LinReg): -0.12 [-0.17, -0.08]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = LinearRegression()\n",
    "# fit model\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (LinReg): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (LinReg) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (LinReg): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))\n",
    "\n",
    "#print(\"Mean squared error (LinReg): {:.2f}\".format(mean_squared_error(ytest,\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\n",
    "#print(\"Mean abs error (LinReg): {:.2f}\".format(mean_absolute_error(ytest,\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\typred)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "#print(\"R2 score (LinReg): {:.2f}\".format(model.score(xtest, ytest)))\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (RanFor): 0.04 [0.04, 0.05]\n",
      "Mean abs error (RanFor) 0.16 [0.15, 0.17]\n",
      "R2 score (RanFor): 0.00 [-0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=7)\n",
    ")\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "mse = []\n",
    "r = []\n",
    "mae = []\n",
    "for i in range(n):\n",
    "# Generate predictions for testing data\n",
    "    # Resample\n",
    "\tresampled_xtest, resampled_ytest = resample(xtest, ytest, replace=True, n_samples=len(ytest), random_state=7+i)\n",
    "\typred = model.predict(resampled_xtest)\n",
    "\tmse.append(mean_squared_error(resampled_ytest,ypred))\n",
    "\tr.append(model.score(resampled_xtest, resampled_ytest))\n",
    "\tmae.append(mean_absolute_error(resampled_ytest,ypred))\n",
    "\n",
    "print(\"Mean squared error (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mse), np.percentile(mse, 5), np.percentile(mse, 95)))\n",
    "print(\"Mean abs error (RanFor) {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(mae), np.percentile(mae, 5), np.percentile(mae, 95)))\n",
    "print(\"R2 score (RanFor): {:.2f} [{:.2f}, {:.2f}]\".format(np.mean(r), np.percentile(r, 5), np.percentile(r, 95)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 11:41:50.576728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-12 11:41:50.584833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.585122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-12-12 11:41:50.585267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-12 11:41:50.586418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-12 11:41:50.587639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-12 11:41:50.587833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-12 11:41:50.588909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-12 11:41:50.589474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-12 11:41:50.591701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-12 11:41:50.591850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.592215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.592459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-12-12 11:41:50.592914: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-12 11:41:50.598564: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 1996245000 Hz\n",
      "2021-12-12 11:41:50.599152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a3a9fc81e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-12 11:41:50.599165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-12 11:41:50.599318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.599591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-12-12 11:41:50.599627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-12 11:41:50.599640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-12 11:41:50.599651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-12 11:41:50.599661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-12 11:41:50.599671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-12 11:41:50.599681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-12 11:41:50.599692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-12 11:41:50.599750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.600044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.600286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2021-12-12 11:41:50.600317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-12 11:41:50.657566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-12 11:41:50.657594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2021-12-12 11:41:50.657599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2021-12-12 11:41:50.657904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.658232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.658507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-12 11:41:50.658761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 379 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)\n",
      "2021-12-12 11:41:50.660650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a3a87b7600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-12 11:41:50.660661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/322 [..............................] - ETA: 0s - loss: 0.3885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 11:41:51.379928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.2027\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1713 - val_loss: 0.1573\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1570 - val_loss: 0.1576\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1564 - val_loss: 0.1561\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1555 - val_loss: 0.1561\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1549 - val_loss: 0.1566\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1547 - val_loss: 0.1561\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1537 - val_loss: 0.1584\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1526 - val_loss: 0.1568\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1532 - val_loss: 0.1575\n",
      "0.16186352\n",
      "0.044465963\n"
     ]
    }
   ],
   "source": [
    "in_dim = xtrain.shape[1]\n",
    "out_dim = ytrain.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(4, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(3, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(2, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(1, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=2, validation_split = 0.2, verbose=1)\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "score = tf.keras.metrics.mean_absolute_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score= np.array(score)\n",
    "print(score.mean())\n",
    "\n",
    "score_mse = tf.keras.metrics.mean_squared_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score_mse =  np.array(score_mse)\n",
    "print(score_mse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.3181\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2465 - val_loss: 0.2124\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - val_loss: 0.1914\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1799\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1629 - val_loss: 0.1774\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1591 - val_loss: 0.1728\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1571 - val_loss: 0.1713\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.1707\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1537 - val_loss: 0.1727\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1531 - val_loss: 0.1708\n",
      "0.17030153\n",
      "0.047515243\n"
     ]
    }
   ],
   "source": [
    "in_dim = xtrain.shape[1]\n",
    "out_dim = ytrain.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, input_dim=in_dim, kernel_initializer='he_uniform', activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(out_dim))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=2, validation_split = 0.2, verbose=1)\n",
    "ypred = model.predict(xtest)\n",
    "\n",
    "score = tf.keras.metrics.mean_absolute_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score= np.array(score)\n",
    "print(score.mean())\n",
    "\n",
    "score_mse = tf.keras.metrics.mean_squared_error(\n",
    "    ytest, ypred\n",
    ")\n",
    "score_mse =  np.array(score_mse)\n",
    "print(score_mse.mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DataScienceLab.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a9205b650ad9b26ded1fb73bba57cf404cfc03cd0c8186ebe669ad7e6a2a6143"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ai4halth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
